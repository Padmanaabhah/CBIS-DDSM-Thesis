{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xzc7BJKDBX3y"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L6wiaECOBX30"
      },
      "outputs": [],
      "source": [
        "#pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cXp-5N_yBX30"
      },
      "outputs": [],
      "source": [
        "from distutils import extension\n",
        "from logging import exception\n",
        "import os\n",
        "from datetime import datetime as dt\n",
        "from regex import E\n",
        "from sqlalchemy import intersect\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import numpy as np \n",
        "import pathlib\n",
        "from keras.callbacks import ModelCheckpoint   \n",
        "from keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iQkKItqB1-t",
        "outputId": "d9eb48d3-e464-4828-ae58-d49140a3cbe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQYE2sEYB-uE",
        "outputId": "a5ec5253-182f-4a66-f91f-989f27a52011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_output_full  Test_output_mask  Train_output_full  Train_output_mask\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/gdrive/MyDrive/cbisddsm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2foFHtBFB_U4"
      },
      "outputs": [],
      "source": [
        "# data_dir_train = pathlib.Path(\"/content/gdrive/MyDrive/Images/Train\")\n",
        "# data_dir_test = pathlib.Path('/content/gdrive/MyDrive/Images/Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zYVMXFDEBX31"
      },
      "outputs": [],
      "source": [
        "seed = 43\n",
        "encoder_input_width = 512\n",
        "encode_input_channels = 3\n",
        "encoder_input_shape = (encoder_input_width, encoder_input_width, encode_input_channels)\n",
        "\n",
        "kernsize = 3\n",
        "decoder_kernel_size = (kernsize, kernsize)\n",
        "stride = 2\n",
        "decoder_strides = (stride, stride)\n",
        "decoder_padding = \"same\"\n",
        "decoder_activation = None\n",
        "final_layer_filters = 1\n",
        "final_layer_activation = \"sigmoid\"\n",
        "\n",
        "train_full_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Train_output_full\"\n",
        "train_mask_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Train_output_mask\"\n",
        "\n",
        "test_full_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Test_output_full\"\n",
        "test_mask_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Test_output_mask\"\n",
        "results_dir = \"/content/results/fit\"\n",
        "extension = \".png\"\n",
        "\n",
        "target_size = (512, 512)\n",
        "\n",
        "brightness_delta = 0.3\n",
        "batch_size = 10\n",
        "\n",
        "weight_decay = 1e-5\n",
        "\n",
        "validate = False\n",
        "loss = \"binary_crossentropy\"\n",
        "learning_rate = 0.0001\n",
        "dropout = 0.5\n",
        "dropout_training = True\n",
        "num_epochs = 120\n",
        "callback_monitor = \"iouMetric\"\n",
        "callback_mode = \"max\"\n",
        "ckpt_save_weights_only = True\n",
        "ckpt_save_best_only = True\n",
        "earlystop_patience = 20\n",
        "restore_best_weights = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WiJw56KyBX32"
      },
      "outputs": [],
      "source": [
        "# x_paths_list = []\n",
        "# for full in os.listdir(train_full_img_dir):\n",
        "#   if full.endswith(extension):\n",
        "#     x_paths_list.append(os.path.join(train_full_img_dir, full))\n",
        "\n",
        "# print(len(x_paths_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B28GisyHBX32"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JGqSf0kQBX32"
      },
      "outputs": [],
      "source": [
        "def datasetPaths(full_img_dir, mask_img_dir):\n",
        "        try:\n",
        "            x_paths_list = []\n",
        "            y_paths_list = []\n",
        "\n",
        "            for full in os.listdir(full_img_dir):\n",
        "                if full.endswith(extension):\n",
        "                    x_paths_list.append(os.path.join(full_img_dir, full))\n",
        "            \n",
        "            for full in os.listdir(mask_img_dir):\n",
        "                if full.endswith(extension):\n",
        "                    y_paths_list.append(os.path.join(mask_img_dir, full))\n",
        "            \n",
        "            x_paths_list.sort()\n",
        "            y_paths_list.sort()\n",
        "\n",
        "            return x_paths_list, y_paths_list\n",
        "        except Exception as e:\n",
        "            print(f\"Error in datasetPaths {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7u3oVaRTBX33"
      },
      "outputs": [],
      "source": [
        "# def loadFullImg(path, dsize):\n",
        "#         try:\n",
        "#             if not isinstance(path, str):\n",
        "#                 path = path.decode()\n",
        "             \n",
        "            \n",
        "#             s3_client = boto3.resource('s3')\n",
        "#             obj = s3_client.get_object(Bucket='cbisddsm', Key=path)\n",
        "#             nparr = np.frombuffer(obj['Body'].read(), np.uint8)\n",
        "#             img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "#             print(f'type type{img}')\n",
        "#             #bucket = s3_resource.Bucket('cbisddsm')\n",
        "#             #print(f'bucket.Object(path) {bucket.Object(path)}')\n",
        "#             #img = bucket.Object(path).get().get('Body').read()\n",
        "#             #print(f'img {img}')\n",
        "#             #img = cv2.imdecode(np.asarray(bytearray(img)), cv2.IMREAD_COLOR)\n",
        "           \n",
        "            \n",
        "#             #img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "#             img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "#             norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "#             full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "#             print(f'done for path {path}')\n",
        "#             return full_img\n",
        "        \n",
        "#         except Exception as e:\n",
        "#             print(f\"There is an error in loadFullImg {e}\")\n",
        "            \n",
        "\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VQf1GqJeBX34"
      },
      "outputs": [],
      "source": [
        "def loadFullImg(path, dsize):\n",
        "        try:\n",
        "            if not isinstance(path, str):\n",
        "                path = path.decode()\n",
        "            \n",
        "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "            #print(type(img))\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "            #print(f'After norm_img')\n",
        "            #print(f'type {norm_img.shape}')\n",
        "            full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "            #print(f'After full_img')\n",
        "            #print(f'type {full_img.shape}')\n",
        "            #print(f'done for path {path} with shape {full_img.shape}')\n",
        "            return full_img\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"There is an error in loadFullImg {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Yfm6JA2rBX34"
      },
      "outputs": [],
      "source": [
        "# s3 = boto3.resource('s3')\n",
        "# my_bucket = s3.Bucket('cbisddsm')\n",
        "# i = 0\n",
        "# for object_summary in my_bucket.objects.filter(Prefix='Train_output_full'):    \n",
        "#     if i == 0:\n",
        "#         pass\n",
        "#     else:\n",
        "#         print(object_summary.key)\n",
        "#         img = loadFullImg(object_summary.key, target_size)\n",
        "#         print(img.shape)\n",
        "#         #break\n",
        "#     i += 1\n",
        "    \n",
        "    \n",
        "#             #print(object_summary.key)\n",
        "        \n",
        "#             #x_paths_list.append(object_summary.key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KYSP3bIaBX35"
      },
      "outputs": [],
      "source": [
        "def loadMaskImg(path, dsize):\n",
        "        try:\n",
        "            if not isinstance(path, str):\n",
        "                path=path.decode()\n",
        "            \n",
        "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "            mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "            #print(f'done for path {path} with shape {mask_img.shape}')\n",
        "            return mask_img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in loadMaskIMG {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Co4SIeY6BX35"
      },
      "outputs": [],
      "source": [
        "# def loadMaskImg(path, dsize):\n",
        "#         try:\n",
        "#             if not isinstance(path, str):\n",
        "#                 path=path.decode()\n",
        "             \n",
        "#             s3_resource = boto3.resource('s3')\n",
        "#             bucket = s3_resource.Bucket('cbisddsm')\n",
        "# #             bucket = s3_resource.Bucket('cbisddsm')\n",
        "#             img = bucket.Object(path).get().get('Body').read()\n",
        "#             img = cv2.imdecode(np.asarray(bytearray(img)), cv2.IMREAD_COLOR)\n",
        "#             print(f'type type(img)')\n",
        "#             #img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "#             img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "#             norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "#             mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "\n",
        "#             return mask_img\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(\"Error in loadMaskIMG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bawafpnnBX36"
      },
      "outputs": [],
      "source": [
        "def tfParse(x_path, y_path):\n",
        "        try:\n",
        "            def _parse(x_path, y_path):\n",
        "                x = loadFullImg(path=x_path, dsize=target_size)\n",
        "                y = loadMaskImg(path=y_path, dsize=target_size)\n",
        "                return x,y\n",
        "\n",
        "            x, y = tf.numpy_function(_parse, [x_path, y_path], [tf.float64, tf.float64])\n",
        "\n",
        "            x.set_shape([target_size[0], target_size[0], 3])\n",
        "            y.set_shape([target_size[0], target_size[1], 1])\n",
        "\n",
        "            return x,y\n",
        "            \n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in tfParse {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tkHDbxVGBX36"
      },
      "outputs": [],
      "source": [
        "def imgAugment(x_img, y_img):\n",
        "        try:\n",
        "            if tf.random.uniform(()) > 0.5:\n",
        "                x_img = tf.image.flip_up_down(image=x_img)\n",
        "                y_img = tf.image.flip_up_down(image=y_img)\n",
        "\n",
        "            x_img = tf.image.random_brightness(\n",
        "                image=x_img, max_delta=brightness_delta\n",
        "            )\n",
        "            x_img = tf.image.random_contrast(x_img, 0.2, 0.5)\n",
        "\n",
        "            return x_img, y_img\n",
        "\n",
        "        except:\n",
        "            print(\"Erro in imgAugument\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Mge3IsdLBX36"
      },
      "outputs": [],
      "source": [
        " def makeTFDataset( shuffle, augument, x_paths_list, y_paths_list, batch_size):\n",
        "        try:\n",
        "            ds = tf.data.Dataset.from_tensor_slices((x_paths_list, y_paths_list))\n",
        "            \n",
        "            if shuffle:\n",
        "                ds = ds.shuffle(buffer_size=len(x_paths_list))\n",
        "\n",
        "            ds = ds.map(tfParse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "            \n",
        "            if augument:\n",
        "                ds = ds.map(imgAugment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "            ds = ds.batch(batch_size=batch_size, drop_remainder=False)\n",
        "            ds = ds.repeat()\n",
        "\n",
        "            return ds\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in make TFDataset {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9RGLX5MnBX37"
      },
      "outputs": [],
      "source": [
        "def buildEncoder():\n",
        "        try:\n",
        "            VGG16_ = keras.applications.VGG16(\n",
        "                include_top=False, weights=\"imagenet\", input_shape=encoder_input_shape,\n",
        "            )\n",
        "\n",
        "            layer_names = [layer.name for layer in VGG16_.layers]\n",
        "\n",
        "            all_layer_outputs = [\n",
        "               VGG16_.get_layer(layer).output for layer in layer_names\n",
        "            ]\n",
        "\n",
        "            encoder_model = keras.Model(inputs=VGG16_.input, outputs=all_layer_outputs)\n",
        "\n",
        "            encoder_model.trainable = False\n",
        "\n",
        "            return encoder_model \n",
        "        \n",
        "        except Exception as e:\n",
        "            print(\"Error in buildEncoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eNHrykF9BX37"
      },
      "outputs": [],
      "source": [
        "# def buildUnet():\n",
        "#         try:\n",
        "#             unet_input = keras.Input(\n",
        "#                 shape= encoder_input_shape, name=\"unet_input_layer\"\n",
        "#             )\n",
        "\n",
        "#             x = unet_input\n",
        "#             encoder_model = buildEncoder()\n",
        "#             all_encoder_layer_outputs = encoder_model(x)\n",
        "\n",
        "#             encoded_img = all_encoder_layer_outputs[-1]\n",
        "\n",
        "#             skip_outputs = [all_encoder_layer_outputs[i] for i in [2, 5,9, 13, 17]]\n",
        "#             #skip_outputs = [all_encoder_layer_outputs[i] for i in [2, 4, 6, 12, 15]]\n",
        "            \n",
        "#             decoder_filters = int(encoded_img.shape[-1])\n",
        "\n",
        "#             # ------------------------------------------\n",
        "#             # Block 5: 7x7 -> 14x14\n",
        "#             #  - `encoded_img` as initial input for decoder\n",
        "#             x = keras.layers.Conv2DTranspose(\n",
        "#                 name=\"block5_up_convT\",\n",
        "#                 filters=decoder_filters,\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=decoder_strides,\n",
        "#                 padding=decoder_padding,\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=decoder_activation,\n",
        "#             )(encoded_img)\n",
        "\n",
        "#             x = keras.layers.Concatenate(name=\"block5_up_concat\", axis=-1)(\n",
        "#                 [x, skip_outputs[4]]\n",
        "#             )\n",
        "\n",
        "#             x = keras.layers.Dropout(\n",
        "#                 name=\"block5_up_dropout\", rate=dropout, seed=seed\n",
        "#             )(x, training=dropout_training)\n",
        "\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block5_up_conv3\",\n",
        "#                 filters=decoder_filters,\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 padding=\"same\",\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block5_up_conv2\",\n",
        "#                 filters=decoder_filters,\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 padding=\"same\",\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block5_up_conv1\",\n",
        "#                 filters=decoder_filters,\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 padding=\"same\",\n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "\n",
        "#             # ------------------------------------------\n",
        "#             # Block 4: 14x14 -> 28x28\n",
        "#             x = keras.layers.Conv2DTranspose(\n",
        "#                 name=\"block4_up_convT\",\n",
        "#                 filters=decoder_filters,\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=decoder_strides,\n",
        "#                 padding=decoder_padding,\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=decoder_activation,\n",
        "#             )(x)\n",
        "\n",
        "#             x = keras.layers.Concatenate(name=\"block4_up_concat\", axis=-1)(\n",
        "#                 [x, skip_outputs[3]]\n",
        "#             )\n",
        "\n",
        "#             x = keras.layers.Dropout(\n",
        "#                 name=\"block4_up_dropout\", rate=dropout, seed=seed\n",
        "#             )(x, training=dropout_training)\n",
        "\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block4_up_conv3\",\n",
        "#                 filters=decoder_filters,\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 padding=\"same\",\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block4_up_conv2\",\n",
        "#                 filters=decoder_filters,\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 padding=\"same\",\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block4_up_conv1\",\n",
        "#                 filters=decoder_filters,\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 padding=\"same\",\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "\n",
        "#             # ------------------------------------------\n",
        "#             # Block 3: 28x28 -> 56x56\n",
        "#             x = keras.layers.Conv2DTranspose(\n",
        "#                 name=\"block3_up_convT\",\n",
        "#                 filters=int(decoder_filters / 2),\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=decoder_strides,\n",
        "#                 padding=decoder_padding,\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=decoder_activation,\n",
        "#             )(x)\n",
        "\n",
        "#             x = keras.layers.Concatenate(name=\"block3_up_concat\", axis=-1)(\n",
        "#                 [x, skip_outputs[2]]\n",
        "#             )\n",
        "\n",
        "#             x = keras.layers.Dropout(\n",
        "#                 name=\"block3_up_dropout\", rate=dropout, seed=seed\n",
        "#             )(x, training=dropout_training)\n",
        "\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block3_up_conv3\",\n",
        "#                 filters=int(decoder_filters / 2),\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 padding=\"same\",\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block3_up_conv2\",\n",
        "#                 filters=int(decoder_filters / 2),\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 padding=\"same\",\n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block3_up_conv1\",\n",
        "#                 filters=int(decoder_filters / 2),\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 strides=(1, 1),\n",
        "#                 padding=\"same\",\n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "\n",
        "#             # ------------------------------------------\n",
        "#             # Block 2: 56x56 -> 112x112\n",
        "#             x = keras.layers.Conv2DTranspose(\n",
        "#                 name=\"block2_up_convT\",\n",
        "#                 filters=int(decoder_filters / 4),\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=decoder_strides,\n",
        "#                 padding=decoder_padding,\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=decoder_activation,\n",
        "#             )(x)\n",
        "\n",
        "#             x = keras.layers.Concatenate(name=\"block2_up_concat\", axis=-1)(\n",
        "#                 [x, skip_outputs[1]]\n",
        "#             )\n",
        "\n",
        "#             x = keras.layers.Dropout(\n",
        "#                 name=\"block2_up_dropout\", rate=dropout, seed=seed\n",
        "#             )(x, training=dropout_training)\n",
        "\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block2_up_conv2\",\n",
        "#                 filters=int(decoder_filters / 4),\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 padding=\"same\",\n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block2_up_conv1\",\n",
        "#                 filters=int(decoder_filters / 4),\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 padding=\"same\",\n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "\n",
        "#             # ------------------------------------------\n",
        "#             # Block 1: 112x112 -> 224x224\n",
        "#             x = keras.layers.Conv2DTranspose(\n",
        "#                 name=\"block1_up_convT\",\n",
        "#                 filters=int(decoder_filters / 8),\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=decoder_strides,\n",
        "#                 padding=decoder_padding,\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=decoder_activation,\n",
        "#             )(x)\n",
        "\n",
        "#             x = keras.layers.Concatenate(name=\"block1_up_concat\", axis=-1)(\n",
        "#                 [x, skip_outputs[0]]\n",
        "#             )\n",
        "\n",
        "#             x = keras.layers.Dropout(\n",
        "#                 name=\"block1_up_dropout\", rate=dropout, seed=seed\n",
        "#             )(x, training=dropout_training)\n",
        "\n",
        "#             x = keras.layers.Conv2D(\n",
        "#                 name=\"block1_up_conv2\",\n",
        "#                 filters=int(decoder_filters / 8),\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 padding=\"same\",\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "#             decoded_img = keras.layers.Conv2D(\n",
        "#                 name=\"block1_up_conv1\",\n",
        "#                 filters=int(decoder_filters / 8),\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 padding=\"same\",\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=\"relu\",\n",
        "#             )(x)\n",
        "\n",
        "#             # ------------------------------------------\n",
        "#             # Final conv layer\n",
        "#             final_img = keras.layers.Conv2D(\n",
        "#                 name=\"final_up_conv\",\n",
        "#                 filters=final_layer_filters,\n",
        "#                 kernel_size=decoder_kernel_size,\n",
        "#                 strides=(1, 1),\n",
        "#                 padding=\"same\",\n",
        "#                 kernel_regularizer=l2(weight_decay), \n",
        "#                 activation=final_layer_activation,\n",
        "#             )(decoded_img)\n",
        "\n",
        "#             # ======\n",
        "#             #  Unet\n",
        "#             # ======\n",
        "\n",
        "#             unet = keras.Model(inputs=unet_input, outputs=final_img, name=\"Unet_VGG16\")\n",
        "\n",
        "#             return unet\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error in Build Unet {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "9fta9rGKGYYx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "YEvS-LjLGZ85"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    #x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\",kernel_regularizer=l2(0.1))(x)\n",
        "    #x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = Dropout(rate=dropout, seed=seed)(x, training=dropout_training)\n",
        "\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_resnet50_unet(input_shape):\n",
        "    \"\"\" Input \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\" Pre-trained ResNet50 Model \"\"\"\n",
        "    resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1 = resnet50.get_layer(\"input_1\").output           ## (512 x 512)\n",
        "    s2 = resnet50.get_layer(\"conv1_relu\").output        ## (256 x 256)\n",
        "    s3 = resnet50.get_layer(\"conv2_block3_out\").output  ## (128 x 128)\n",
        "    s4 = resnet50.get_layer(\"conv3_block4_out\").output  ## (64 x 64)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    b1 = resnet50.get_layer(\"conv4_block6_out\").output  ## (32 x 32)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
        "    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
        "    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
        "    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
        "\n",
        "    \"\"\" Output \"\"\"\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"ResNet50_U-Net\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "Sr4O-OxiGbcv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3HWJwf9AGdmn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_sq8aqBYBX38"
      },
      "outputs": [],
      "source": [
        "def iouMetric( y_true, y_pred):\n",
        "        try:\n",
        "            def compute_iou(y_true, y_pred):\n",
        "                intersection = (y_true * y_pred).sum()\n",
        "                union = y_true.sum() + y_pred.sum() - intersection\n",
        "                x = (intersection + 1e-15) / (union + 1e-15)\n",
        "                x = x.astype(np.float32)\n",
        "                return x\n",
        "            \n",
        "            return tf.numpy_function(compute_iou, [y_true, y_pred], tf.float32)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error in iouMetric {E}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xCkCusvKBCuz"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "        try:\n",
        "            # def dice(true, pred, k = 1):\n",
        "            #     intersection = np.sum(pred[true==k]) * 2.0\n",
        "            #     dice = intersection / (np.sum(pred) + np.sum(true))\n",
        "            #     return dice \n",
        "            # return tf.numpy_function(dice, [y_true, y_pred], tf.double)\n",
        "            \n",
        "            y_true_f = tf.reshape(tf.dtypes.cast(y_true, tf.float32), [-1])\n",
        "            y_pred_f = tf.reshape(tf.dtypes.cast(y_pred, tf.float32), [-1])\n",
        "            intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "            return (2. * intersection + 1.) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + 1.)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in dice_coef {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Egz73rd9BX39"
      },
      "outputs": [],
      "source": [
        "def compile_( model):\n",
        "        try:\n",
        "            loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "            metrics = [\"accuracy\", iouMetric, dice_coef]\n",
        "            model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(f\"Failed at compile_ {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jNa9nYOcCV15"
      },
      "outputs": [],
      "source": [
        " test_x, test_y = datasetPaths(\n",
        "            full_img_dir=test_full_img_dir,\n",
        "            mask_img_dir=test_mask_img_dir\n",
        "        )\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wDDyk7GYCWU3"
      },
      "outputs": [],
      "source": [
        "# def evaluate(path,target_size):\n",
        "#   full_img_lst = []\n",
        "#   print(len(path))\n",
        "#   for imgpath in path:\n",
        "#     full_img = loadFullImg(imgpath, target_size)\n",
        "#     full_img_lst.append(full_img)\n",
        "#     #img = cv2.imread(imgpath, cv2.IMREAD_GRAYSCALE)\n",
        "#     #print(full_img.shape)\n",
        "#   return full_img_lst\n",
        "  \n",
        "# full_img_lst = evaluate(test_x, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pbuTQcYXCbvv"
      },
      "outputs": [],
      "source": [
        "# def evaluate_mask(path,target_size):\n",
        "#   mask_img_lst = []\n",
        "#   print(len(path))\n",
        "#   for imgpath in path:\n",
        "#     mask_img = loadMaskImg(imgpath, target_size)\n",
        "#     mask_img_lst.append(mask_img)\n",
        "#     #img = cv2.imread(imgpath, cv2.IMREAD_GRAYSCALE)\n",
        "#     #print(full_img.shape)\n",
        "#   return mask_img_lst\n",
        "  \n",
        "# mask_img_lst = evaluate(test_y, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_WCc1IIBIety"
      },
      "outputs": [],
      "source": [
        "# img = cv2.imread(test_x[0], cv2.IMREAD_GRAYSCALE)\n",
        "# print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VeQ8YyfqHgYW"
      },
      "outputs": [],
      "source": [
        "# actual_x, actual_y =tfParse(test_x, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "c1hGy4M6FyuV"
      },
      "outputs": [],
      "source": [
        "# full_img_lst[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agKhRncmBX39",
        "outputId": "d90a18df-bf82-43f3-dad2-9796853fb221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"ResNet50_U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 518, 518, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 256, 256, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 256, 256, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 256, 256, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 258, 258, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 128, 128, 64  0           ['pool1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 128, 128, 64  4160        ['pool1_pool[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_2_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 128, 128, 25  16640       ['pool1_pool[0][0]']             \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                       6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                       6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                6)                                'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 128, 128, 25  0           ['conv2_block1_add[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block1_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block2_2_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                       6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 128, 128, 25  0           ['conv2_block1_out[0][0]',       \n",
            "                                6)                                'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 128, 128, 25  0           ['conv2_block2_add[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 128, 128, 64  16448       ['conv2_block2_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 128, 128, 64  36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 128, 128, 64  256        ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block3_2_bn[0][0]']      \n",
            " n)                             )                                                                 \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 128, 128, 25  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 128, 128, 25  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                       6)                                                                \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 128, 128, 25  0           ['conv2_block2_out[0][0]',       \n",
            "                                6)                                'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 128, 128, 25  0           ['conv2_block3_add[0][0]']       \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 64, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 64, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 64, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 64, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 64, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 64, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 64, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 64, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 64, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 64, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 32, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 32, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 32, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 32, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 32, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 32, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 32, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 32, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 32, 32, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 32, 32, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 32, 32, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 32, 32, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 64, 64, 512)  2097664    ['conv4_block6_out[0][0]']       \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 64, 1024  0           ['conv2d_transpose[0][0]',       \n",
            "                                )                                 'conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64, 64, 1024  0           ['concatenate[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 64, 64, 512)  4719104     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 64, 64, 512)  0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 64, 64, 512)  2359808     ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 64, 64, 512)  0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 25  524544     ['activation_1[0][0]']           \n",
            " spose)                         6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 51  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                2)                                'conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 128, 128, 51  0           ['concatenate_1[0][0]']          \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 25  1179904     ['dropout_1[0][0]']              \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 128, 128, 25  0           ['conv2d_2[0][0]']               \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 25  590080      ['activation_2[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 128, 128, 25  0           ['conv2d_3[0][0]']               \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 12  131200     ['activation_3[0][0]']           \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256, 256, 19  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                2)                                'conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 256, 256, 19  0           ['concatenate_2[0][0]']          \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 256, 256, 12  221312      ['dropout_2[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 256, 256, 12  0           ['conv2d_4[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 256, 256, 12  147584      ['activation_4[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 256, 256, 12  0           ['conv2d_5[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 64  32832      ['activation_5[0][0]']           \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 512, 512, 67  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                )                                 'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 512, 512, 67  0           ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 512, 512, 64  38656       ['dropout_3[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 512, 512, 64  0           ['conv2d_6[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 512, 512, 64  36928       ['activation_6[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 512, 512, 64  0           ['conv2d_7[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 512, 512, 1)  65          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,668,865\n",
            "Trainable params: 20,638,273\n",
            "Non-trainable params: 30,592\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            "Size of training set = 1231\n",
            "Size of test set = 361\n",
            "Number of epochs = 120\n",
            "Batch size = 10\n",
            "Number of training steps per epoch = 124\n",
            "Number of test steps per epoch = 37\n",
            "\n",
            "Epoch 1/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 56.2848 - accuracy: 0.9879 - iouMetric: 0.0213 - dice_coef: 0.0409"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 428s 3s/step - loss: 56.2848 - accuracy: 0.9879 - iouMetric: 0.0213 - dice_coef: 0.0409\n",
            "Epoch 2/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 16.9263 - accuracy: 0.9961 - iouMetric: 0.0979 - dice_coef: 0.1769"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 16.9263 - accuracy: 0.9961 - iouMetric: 0.0979 - dice_coef: 0.1769\n",
            "Epoch 3/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 5.5628 - accuracy: 0.9962 - iouMetric: 0.1277 - dice_coef: 0.2245"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 5.5628 - accuracy: 0.9962 - iouMetric: 0.1277 - dice_coef: 0.2245\n",
            "Epoch 4/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 2.0862 - accuracy: 0.9964 - iouMetric: 0.1536 - dice_coef: 0.2637"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 231s 2s/step - loss: 2.0862 - accuracy: 0.9964 - iouMetric: 0.1536 - dice_coef: 0.2637\n",
            "Epoch 5/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.8642 - accuracy: 0.9965 - iouMetric: 0.1631 - dice_coef: 0.2773"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.8642 - accuracy: 0.9965 - iouMetric: 0.1631 - dice_coef: 0.2773\n",
            "Epoch 6/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.3755 - accuracy: 0.9967 - iouMetric: 0.1849 - dice_coef: 0.3098"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.3755 - accuracy: 0.9967 - iouMetric: 0.1849 - dice_coef: 0.3098\n",
            "Epoch 7/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.9967 - iouMetric: 0.1893 - dice_coef: 0.3148"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.1683 - accuracy: 0.9967 - iouMetric: 0.1893 - dice_coef: 0.3148\n",
            "Epoch 8/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9968 - iouMetric: 0.2078 - dice_coef: 0.3419"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0773 - accuracy: 0.9968 - iouMetric: 0.2078 - dice_coef: 0.3419\n",
            "Epoch 9/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9969 - iouMetric: 0.2231 - dice_coef: 0.3623"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0376 - accuracy: 0.9969 - iouMetric: 0.2231 - dice_coef: 0.3623\n",
            "Epoch 10/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9969 - iouMetric: 0.2330 - dice_coef: 0.3751"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 232s 2s/step - loss: 0.0204 - accuracy: 0.9969 - iouMetric: 0.2330 - dice_coef: 0.3751\n",
            "Epoch 11/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9972 - iouMetric: 0.2474 - dice_coef: 0.3947"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0131 - accuracy: 0.9972 - iouMetric: 0.2474 - dice_coef: 0.3947\n",
            "Epoch 12/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9970 - iouMetric: 0.2373 - dice_coef: 0.3811"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0109 - accuracy: 0.9970 - iouMetric: 0.2373 - dice_coef: 0.3811\n",
            "Epoch 13/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9972 - iouMetric: 0.2536 - dice_coef: 0.4017"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0093 - accuracy: 0.9972 - iouMetric: 0.2536 - dice_coef: 0.4017\n",
            "Epoch 14/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9974 - iouMetric: 0.2667 - dice_coef: 0.4182"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0083 - accuracy: 0.9974 - iouMetric: 0.2667 - dice_coef: 0.4182\n",
            "Epoch 15/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9975 - iouMetric: 0.2669 - dice_coef: 0.4194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0079 - accuracy: 0.9975 - iouMetric: 0.2669 - dice_coef: 0.4194\n",
            "Epoch 16/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9975 - iouMetric: 0.2737 - dice_coef: 0.4267"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0081 - accuracy: 0.9975 - iouMetric: 0.2737 - dice_coef: 0.4267\n",
            "Epoch 17/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9972 - iouMetric: 0.2481 - dice_coef: 0.3943"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0092 - accuracy: 0.9972 - iouMetric: 0.2481 - dice_coef: 0.3943\n",
            "Epoch 18/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9977 - iouMetric: 0.2924 - dice_coef: 0.4510"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 240s 2s/step - loss: 0.0072 - accuracy: 0.9977 - iouMetric: 0.2924 - dice_coef: 0.4510\n",
            "Epoch 19/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9978 - iouMetric: 0.3036 - dice_coef: 0.4636"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0070 - accuracy: 0.9978 - iouMetric: 0.3036 - dice_coef: 0.4636\n",
            "Epoch 20/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9979 - iouMetric: 0.3176 - dice_coef: 0.4803"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0067 - accuracy: 0.9979 - iouMetric: 0.3176 - dice_coef: 0.4803\n",
            "Epoch 21/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9979 - iouMetric: 0.3206 - dice_coef: 0.4837"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0066 - accuracy: 0.9979 - iouMetric: 0.3206 - dice_coef: 0.4837\n",
            "Epoch 22/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9981 - iouMetric: 0.3390 - dice_coef: 0.5049"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0062 - accuracy: 0.9981 - iouMetric: 0.3390 - dice_coef: 0.5049\n",
            "Epoch 23/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9979 - iouMetric: 0.3289 - dice_coef: 0.4927"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0067 - accuracy: 0.9979 - iouMetric: 0.3289 - dice_coef: 0.4927\n",
            "Epoch 24/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9981 - iouMetric: 0.3456 - dice_coef: 0.5121"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0062 - accuracy: 0.9981 - iouMetric: 0.3456 - dice_coef: 0.5121\n",
            "Epoch 25/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9982 - iouMetric: 0.3600 - dice_coef: 0.5273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0058 - accuracy: 0.9982 - iouMetric: 0.3600 - dice_coef: 0.5273\n",
            "Epoch 26/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9978 - iouMetric: 0.3293 - dice_coef: 0.4927"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0072 - accuracy: 0.9978 - iouMetric: 0.3293 - dice_coef: 0.4927\n",
            "Epoch 27/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9981 - iouMetric: 0.3550 - dice_coef: 0.5216"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0064 - accuracy: 0.9981 - iouMetric: 0.3550 - dice_coef: 0.5216\n",
            "Epoch 28/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982 - iouMetric: 0.3739 - dice_coef: 0.5426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 239s 2s/step - loss: 0.0059 - accuracy: 0.9982 - iouMetric: 0.3739 - dice_coef: 0.5426\n",
            "Epoch 29/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9983 - iouMetric: 0.4707 - dice_coef: 0.6368"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0053 - accuracy: 0.9983 - iouMetric: 0.4707 - dice_coef: 0.6368\n",
            "Epoch 30/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984 - iouMetric: 0.4985 - dice_coef: 0.6612"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0051 - accuracy: 0.9984 - iouMetric: 0.4985 - dice_coef: 0.6612\n",
            "Epoch 31/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9984 - iouMetric: 0.5179 - dice_coef: 0.6794"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0049 - accuracy: 0.9984 - iouMetric: 0.5179 - dice_coef: 0.6794\n",
            "Epoch 32/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9976 - iouMetric: 0.3451 - dice_coef: 0.5082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0075 - accuracy: 0.9976 - iouMetric: 0.3451 - dice_coef: 0.5082\n",
            "Epoch 33/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984 - iouMetric: 0.4903 - dice_coef: 0.6542"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0054 - accuracy: 0.9984 - iouMetric: 0.4903 - dice_coef: 0.6542\n",
            "Epoch 34/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9985 - iouMetric: 0.5272 - dice_coef: 0.6866"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0050 - accuracy: 0.9985 - iouMetric: 0.5272 - dice_coef: 0.6866\n",
            "Epoch 35/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985 - iouMetric: 0.5505 - dice_coef: 0.7075"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 240s 2s/step - loss: 0.0044 - accuracy: 0.9985 - iouMetric: 0.5505 - dice_coef: 0.7075\n",
            "Epoch 36/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987 - iouMetric: 0.5841 - dice_coef: 0.7351"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0040 - accuracy: 0.9987 - iouMetric: 0.5841 - dice_coef: 0.7351\n",
            "Epoch 37/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986 - iouMetric: 0.5779 - dice_coef: 0.7294"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 242s 2s/step - loss: 0.0042 - accuracy: 0.9986 - iouMetric: 0.5779 - dice_coef: 0.7294\n",
            "Epoch 38/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987 - iouMetric: 0.5920 - dice_coef: 0.7416"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 240s 2s/step - loss: 0.0040 - accuracy: 0.9987 - iouMetric: 0.5920 - dice_coef: 0.7416\n",
            "Epoch 39/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988 - iouMetric: 0.6105 - dice_coef: 0.7559"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0038 - accuracy: 0.9988 - iouMetric: 0.6105 - dice_coef: 0.7559\n",
            "Epoch 40/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988 - iouMetric: 0.6096 - dice_coef: 0.7549"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 239s 2s/step - loss: 0.0037 - accuracy: 0.9988 - iouMetric: 0.6096 - dice_coef: 0.7549\n",
            "Epoch 41/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989 - iouMetric: 0.6360 - dice_coef: 0.7750"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 240s 2s/step - loss: 0.0035 - accuracy: 0.9989 - iouMetric: 0.6360 - dice_coef: 0.7750\n",
            "Epoch 42/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989 - iouMetric: 0.6408 - dice_coef: 0.7793"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0034 - accuracy: 0.9989 - iouMetric: 0.6408 - dice_coef: 0.7793\n",
            "Epoch 43/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989 - iouMetric: 0.6379 - dice_coef: 0.7764"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 239s 2s/step - loss: 0.0034 - accuracy: 0.9989 - iouMetric: 0.6379 - dice_coef: 0.7764\n",
            "Epoch 44/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989 - iouMetric: 0.6503 - dice_coef: 0.7860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 240s 2s/step - loss: 0.0033 - accuracy: 0.9989 - iouMetric: 0.6503 - dice_coef: 0.7860\n",
            "Epoch 45/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987 - iouMetric: 0.5993 - dice_coef: 0.7456"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0040 - accuracy: 0.9987 - iouMetric: 0.5993 - dice_coef: 0.7456\n",
            "Epoch 46/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989 - iouMetric: 0.6353 - dice_coef: 0.7753"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0034 - accuracy: 0.9989 - iouMetric: 0.6353 - dice_coef: 0.7753\n",
            "Epoch 47/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988 - iouMetric: 0.6166 - dice_coef: 0.7602"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0036 - accuracy: 0.9988 - iouMetric: 0.6166 - dice_coef: 0.7602\n",
            "Epoch 48/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989 - iouMetric: 0.6296 - dice_coef: 0.7683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0035 - accuracy: 0.9989 - iouMetric: 0.6296 - dice_coef: 0.7683\n",
            "Epoch 49/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9980 - iouMetric: 0.4300 - dice_coef: 0.5950"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0064 - accuracy: 0.9980 - iouMetric: 0.4300 - dice_coef: 0.5950\n",
            "Epoch 50/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986 - iouMetric: 0.5629 - dice_coef: 0.7173"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0042 - accuracy: 0.9986 - iouMetric: 0.5629 - dice_coef: 0.7173\n",
            "Epoch 51/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988 - iouMetric: 0.6132 - dice_coef: 0.7579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0036 - accuracy: 0.9988 - iouMetric: 0.6132 - dice_coef: 0.7579\n",
            "Epoch 52/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989 - iouMetric: 0.6365 - dice_coef: 0.7758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0032 - accuracy: 0.9989 - iouMetric: 0.6365 - dice_coef: 0.7758\n",
            "Epoch 53/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990 - iouMetric: 0.6656 - dice_coef: 0.7977"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0031 - accuracy: 0.9990 - iouMetric: 0.6656 - dice_coef: 0.7977\n",
            "Epoch 54/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990 - iouMetric: 0.6609 - dice_coef: 0.7942"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0031 - accuracy: 0.9990 - iouMetric: 0.6609 - dice_coef: 0.7942\n",
            "Epoch 55/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990 - iouMetric: 0.6766 - dice_coef: 0.8050"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0029 - accuracy: 0.9990 - iouMetric: 0.6766 - dice_coef: 0.8050\n",
            "Epoch 56/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990 - iouMetric: 0.6757 - dice_coef: 0.8050"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 239s 2s/step - loss: 0.0030 - accuracy: 0.9990 - iouMetric: 0.6757 - dice_coef: 0.8050\n",
            "Epoch 57/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991 - iouMetric: 0.6902 - dice_coef: 0.8153"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 239s 2s/step - loss: 0.0028 - accuracy: 0.9991 - iouMetric: 0.6902 - dice_coef: 0.8153\n",
            "Epoch 58/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991 - iouMetric: 0.7014 - dice_coef: 0.8231"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0026 - accuracy: 0.9991 - iouMetric: 0.7014 - dice_coef: 0.8231\n",
            "Epoch 59/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991 - iouMetric: 0.7001 - dice_coef: 0.8223"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0027 - accuracy: 0.9991 - iouMetric: 0.7001 - dice_coef: 0.8223\n",
            "Epoch 60/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987 - iouMetric: 0.5843 - dice_coef: 0.7328"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0041 - accuracy: 0.9987 - iouMetric: 0.5843 - dice_coef: 0.7328\n",
            "Epoch 61/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985 - iouMetric: 0.5541 - dice_coef: 0.7080"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0042 - accuracy: 0.9985 - iouMetric: 0.5541 - dice_coef: 0.7080\n",
            "Epoch 62/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9987 - iouMetric: 0.6011 - dice_coef: 0.7479"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0036 - accuracy: 0.9987 - iouMetric: 0.6011 - dice_coef: 0.7479\n",
            "Epoch 63/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989 - iouMetric: 0.6637 - dice_coef: 0.7961"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0030 - accuracy: 0.9989 - iouMetric: 0.6637 - dice_coef: 0.7961\n",
            "Epoch 64/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987 - iouMetric: 0.6011 - dice_coef: 0.7464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0037 - accuracy: 0.9987 - iouMetric: 0.6011 - dice_coef: 0.7464\n",
            "Epoch 65/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989 - iouMetric: 0.6550 - dice_coef: 0.7893"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0034 - accuracy: 0.9989 - iouMetric: 0.6550 - dice_coef: 0.7893\n",
            "Epoch 66/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990 - iouMetric: 0.6743 - dice_coef: 0.8035"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0030 - accuracy: 0.9990 - iouMetric: 0.6743 - dice_coef: 0.8035\n",
            "Epoch 67/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990 - iouMetric: 0.6920 - dice_coef: 0.8168"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0027 - accuracy: 0.9990 - iouMetric: 0.6920 - dice_coef: 0.8168\n",
            "Epoch 68/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991 - iouMetric: 0.6990 - dice_coef: 0.8213"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0027 - accuracy: 0.9991 - iouMetric: 0.6990 - dice_coef: 0.8213\n",
            "Epoch 69/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991 - iouMetric: 0.7091 - dice_coef: 0.8283"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0026 - accuracy: 0.9991 - iouMetric: 0.7091 - dice_coef: 0.8283\n",
            "Epoch 70/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991 - iouMetric: 0.7171 - dice_coef: 0.8343"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 240s 2s/step - loss: 0.0025 - accuracy: 0.9991 - iouMetric: 0.7171 - dice_coef: 0.8343\n",
            "Epoch 71/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992 - iouMetric: 0.7194 - dice_coef: 0.8333"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0024 - accuracy: 0.9992 - iouMetric: 0.7194 - dice_coef: 0.8333\n",
            "Epoch 72/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991 - iouMetric: 0.7162 - dice_coef: 0.8331"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0024 - accuracy: 0.9991 - iouMetric: 0.7162 - dice_coef: 0.8331\n",
            "Epoch 73/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991 - iouMetric: 0.7206 - dice_coef: 0.8367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0024 - accuracy: 0.9991 - iouMetric: 0.7206 - dice_coef: 0.8367\n",
            "Epoch 74/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991 - iouMetric: 0.7177 - dice_coef: 0.8344"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0024 - accuracy: 0.9991 - iouMetric: 0.7177 - dice_coef: 0.8344\n",
            "Epoch 75/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992 - iouMetric: 0.7250 - dice_coef: 0.8391"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0024 - accuracy: 0.9992 - iouMetric: 0.7250 - dice_coef: 0.8391\n",
            "Epoch 76/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992 - iouMetric: 0.7245 - dice_coef: 0.8389"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0024 - accuracy: 0.9992 - iouMetric: 0.7245 - dice_coef: 0.8389\n",
            "Epoch 77/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992 - iouMetric: 0.7340 - dice_coef: 0.8456"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0023 - accuracy: 0.9992 - iouMetric: 0.7340 - dice_coef: 0.8456\n",
            "Epoch 78/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992 - iouMetric: 0.7317 - dice_coef: 0.8437"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0023 - accuracy: 0.9992 - iouMetric: 0.7317 - dice_coef: 0.8437\n",
            "Epoch 79/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992 - iouMetric: 0.7288 - dice_coef: 0.8418"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0023 - accuracy: 0.9992 - iouMetric: 0.7288 - dice_coef: 0.8418\n",
            "Epoch 80/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992 - iouMetric: 0.7341 - dice_coef: 0.8456"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0024 - accuracy: 0.9992 - iouMetric: 0.7341 - dice_coef: 0.8456\n",
            "Epoch 81/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7365 - dice_coef: 0.8476"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7365 - dice_coef: 0.8476\n",
            "Epoch 82/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7394 - dice_coef: 0.8490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7394 - dice_coef: 0.8490\n",
            "Epoch 83/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991 - iouMetric: 0.6848 - dice_coef: 0.8104"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0030 - accuracy: 0.9991 - iouMetric: 0.6848 - dice_coef: 0.8104\n",
            "Epoch 84/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990 - iouMetric: 0.6719 - dice_coef: 0.8011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0031 - accuracy: 0.9990 - iouMetric: 0.6719 - dice_coef: 0.8011\n",
            "Epoch 85/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9988 - iouMetric: 0.6190 - dice_coef: 0.7623"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0035 - accuracy: 0.9988 - iouMetric: 0.6190 - dice_coef: 0.7623\n",
            "Epoch 86/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989 - iouMetric: 0.6375 - dice_coef: 0.7763"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0033 - accuracy: 0.9989 - iouMetric: 0.6375 - dice_coef: 0.7763\n",
            "Epoch 87/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990 - iouMetric: 0.6644 - dice_coef: 0.7960"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0029 - accuracy: 0.9990 - iouMetric: 0.6644 - dice_coef: 0.7960\n",
            "Epoch 88/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990 - iouMetric: 0.6744 - dice_coef: 0.8030"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0028 - accuracy: 0.9990 - iouMetric: 0.6744 - dice_coef: 0.8030\n",
            "Epoch 89/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992 - iouMetric: 0.7257 - dice_coef: 0.8401"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0023 - accuracy: 0.9992 - iouMetric: 0.7257 - dice_coef: 0.8401\n",
            "Epoch 90/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7312 - dice_coef: 0.8435"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7312 - dice_coef: 0.8435\n",
            "Epoch 91/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7421 - dice_coef: 0.8512"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7421 - dice_coef: 0.8512\n",
            "Epoch 92/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7408 - dice_coef: 0.8500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7408 - dice_coef: 0.8500\n",
            "Epoch 93/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7432 - dice_coef: 0.8516"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7432 - dice_coef: 0.8516\n",
            "Epoch 94/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7488 - dice_coef: 0.8556"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 237s 2s/step - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7488 - dice_coef: 0.8556\n",
            "Epoch 95/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7543 - dice_coef: 0.8590"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7543 - dice_coef: 0.8590\n",
            "Epoch 96/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993 - iouMetric: 0.7553 - dice_coef: 0.8597"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 238s 2s/step - loss: 0.0020 - accuracy: 0.9993 - iouMetric: 0.7553 - dice_coef: 0.8597\n",
            "Epoch 97/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990 - iouMetric: 0.6775 - dice_coef: 0.8040"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0027 - accuracy: 0.9990 - iouMetric: 0.6775 - dice_coef: 0.8040\n",
            "Epoch 98/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9986 - iouMetric: 0.5022 - dice_coef: 0.6580"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0046 - accuracy: 0.9986 - iouMetric: 0.5022 - dice_coef: 0.6580\n",
            "Epoch 99/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988 - iouMetric: 0.6233 - dice_coef: 0.7648"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0034 - accuracy: 0.9988 - iouMetric: 0.6233 - dice_coef: 0.7648\n",
            "Epoch 100/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990 - iouMetric: 0.6746 - dice_coef: 0.8043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0028 - accuracy: 0.9990 - iouMetric: 0.6746 - dice_coef: 0.8043\n",
            "Epoch 101/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991 - iouMetric: 0.6975 - dice_coef: 0.8182"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0025 - accuracy: 0.9991 - iouMetric: 0.6975 - dice_coef: 0.8182\n",
            "Epoch 102/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992 - iouMetric: 0.7265 - dice_coef: 0.8407"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0023 - accuracy: 0.9992 - iouMetric: 0.7265 - dice_coef: 0.8407\n",
            "Epoch 103/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7404 - dice_coef: 0.8499"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 232s 2s/step - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7404 - dice_coef: 0.8499\n",
            "Epoch 104/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7437 - dice_coef: 0.8520"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7437 - dice_coef: 0.8520\n",
            "Epoch 105/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7359 - dice_coef: 0.8468"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7359 - dice_coef: 0.8468\n",
            "Epoch 106/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7495 - dice_coef: 0.8558"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7495 - dice_coef: 0.8558\n",
            "Epoch 107/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7480 - dice_coef: 0.8545"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7480 - dice_coef: 0.8545\n",
            "Epoch 108/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993 - iouMetric: 0.7592 - dice_coef: 0.8625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0020 - accuracy: 0.9993 - iouMetric: 0.7592 - dice_coef: 0.8625\n",
            "Epoch 109/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7419 - dice_coef: 0.8505"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 240s 2s/step - loss: 0.0022 - accuracy: 0.9992 - iouMetric: 0.7419 - dice_coef: 0.8505\n",
            "Epoch 110/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992 - iouMetric: 0.7326 - dice_coef: 0.8444"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 239s 2s/step - loss: 0.0024 - accuracy: 0.9992 - iouMetric: 0.7326 - dice_coef: 0.8444\n",
            "Epoch 111/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7527 - dice_coef: 0.8578"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 239s 2s/step - loss: 0.0021 - accuracy: 0.9992 - iouMetric: 0.7527 - dice_coef: 0.8578\n",
            "Epoch 112/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993 - iouMetric: 0.7629 - dice_coef: 0.8648"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 239s 2s/step - loss: 0.0020 - accuracy: 0.9993 - iouMetric: 0.7629 - dice_coef: 0.8648\n",
            "Epoch 113/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993 - iouMetric: 0.7704 - dice_coef: 0.8696"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0019 - accuracy: 0.9993 - iouMetric: 0.7704 - dice_coef: 0.8696\n",
            "Epoch 114/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993 - iouMetric: 0.7678 - dice_coef: 0.8679"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 236s 2s/step - loss: 0.0019 - accuracy: 0.9993 - iouMetric: 0.7678 - dice_coef: 0.8679\n",
            "Epoch 115/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993 - iouMetric: 0.7601 - dice_coef: 0.8628"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0020 - accuracy: 0.9993 - iouMetric: 0.7601 - dice_coef: 0.8628\n",
            "Epoch 116/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993 - iouMetric: 0.7638 - dice_coef: 0.8649"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0019 - accuracy: 0.9993 - iouMetric: 0.7638 - dice_coef: 0.8649\n",
            "Epoch 117/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993 - iouMetric: 0.7619 - dice_coef: 0.8634"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 234s 2s/step - loss: 0.0020 - accuracy: 0.9993 - iouMetric: 0.7619 - dice_coef: 0.8634\n",
            "Epoch 118/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991 - iouMetric: 0.7050 - dice_coef: 0.8250"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 233s 2s/step - loss: 0.0026 - accuracy: 0.9991 - iouMetric: 0.7050 - dice_coef: 0.8250\n",
            "Epoch 119/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990 - iouMetric: 0.6940 - dice_coef: 0.8177"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0028 - accuracy: 0.9990 - iouMetric: 0.6940 - dice_coef: 0.8177\n",
            "Epoch 120/120\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991 - iouMetric: 0.6943 - dice_coef: 0.8179"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 235s 2s/step - loss: 0.0026 - accuracy: 0.9991 - iouMetric: 0.6943 - dice_coef: 0.8179\n",
            "Completed\n"
          ]
        }
      ],
      "source": [
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)  \n",
        "model_time = dt.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_folder = os.path.join(results_dir, model_time)\n",
        "os.makedirs(model_folder)\n",
        "\n",
        "tensorboard_folder = os.path.join(model_folder, \"tensorlogs\")\n",
        "os.makedirs(tensorboard_folder)\n",
        "\n",
        "ckpt_folder = os.path.join(model_folder, \"checkpoints\")\n",
        "os.makedirs(ckpt_folder)\n",
        "\n",
        "csv_logger_folder = os.path.join(model_folder, \"csv_logger\")\n",
        "os.makedirs(csv_logger_folder)\n",
        "\n",
        "hist_folder = os.path.join(model_folder, \"model_history\")\n",
        "os.makedirs(hist_folder)\n",
        "\n",
        "saved_model_folder = os.path.join(model_folder, \"Saved_model\")\n",
        "os.makedirs(saved_model_folder)\n",
        "\n",
        "model_params_folder = os.path.join(model_folder, \"model_params\")\n",
        "os.makedirs(model_params_folder)\n",
        "\n",
        "train_x, train_y = datasetPaths(\n",
        "    full_img_dir=train_full_img_dir,\n",
        "    mask_img_dir=train_mask_img_dir \n",
        ")\n",
        "\n",
        "test_x, test_y = datasetPaths(\n",
        "    full_img_dir=test_full_img_dir,\n",
        "    mask_img_dir=test_mask_img_dir\n",
        ")\n",
        "\n",
        "train_ds = makeTFDataset(shuffle=True, augument=True,\n",
        "x_paths_list = train_x, y_paths_list=train_y, batch_size=batch_size)\n",
        "\n",
        "\n",
        "test_ds = makeTFDataset(\n",
        "    shuffle=False,\n",
        "    augument=False,\n",
        "    x_paths_list=test_x,\n",
        "    y_paths_list=test_y,\n",
        "    batch_size=batch_size)      \n",
        "    \n",
        "#unet = buildUnet()\n",
        "input_shape = (512, 512, 3)\n",
        "model = build_resnet50_unet(input_shape)\n",
        "model.summary()\n",
        "\n",
        "unet = compile_(model=model)\n",
        "\n",
        "# ckpt_path = (ckpt_folder + f\"/{model_time}\" + \"_Epoch-{epoch:03d}\" + \"_IOU-{iouMetric:.8f\")\n",
        "ckpt_path = (ckpt_folder + f\"/{model_time}\")\n",
        "\n",
        "ckpt_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath= ckpt_path,\n",
        "    monitors= callback_monitor,\n",
        "    mode= callback_mode,\n",
        "    save_weights_only= ckpt_save_weights_only,\n",
        "    save_best_only=ckpt_save_best_only,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "es_callback = keras.callbacks.EarlyStopping(\n",
        "    patience= earlystop_patience,\n",
        "    monitor= callback_monitor,\n",
        "    mode= callback_mode,\n",
        "    restore_best_weights= restore_best_weights,\n",
        ")\n",
        "\n",
        "# TensorBoard\n",
        "tb_callback = keras.callbacks.TensorBoard(\n",
        "    log_dir=tensorboard_folder, histogram_freq=1, profile_batch=0\n",
        ")\n",
        "\n",
        "# CSV Logger\n",
        "csv_logger_path = os.path.join(csv_logger_folder, \"csv_logger.csv\")\n",
        "csv_logger = keras.callbacks.CSVLogger(\n",
        "    filename=csv_logger_path, separator=\",\", append=True\n",
        ")\n",
        "\n",
        "# Putting them together\n",
        "callbacks = [ckpt_callback, es_callback, tb_callback, csv_logger, checkpointer]\n",
        "\n",
        "train_steps = len(train_x) // batch_size\n",
        "test_steps = len(test_x) // batch_size\n",
        "\n",
        "if len(train_x) % batch_size != 0:\n",
        "    train_steps += 1\n",
        "if len(test_x) % batch_size != 0:\n",
        "    test_steps += 1\n",
        "\n",
        "print()\n",
        "print(f\"Size of training set = {len(train_x)}\")\n",
        "print(f\"Size of test set = {len(test_x)}\")\n",
        "print(f\"Number of epochs = {num_epochs}\")\n",
        "print(f\"Batch size = {batch_size}\")\n",
        "print(f\"Number of training steps per epoch = {train_steps}\")\n",
        "print(f\"Number of test steps per epoch = {test_steps}\")\n",
        "print()\n",
        "\n",
        "# if __name__ == \"__main__\":     \n",
        "    \n",
        "#     model.summary()\n",
        "\n",
        "\n",
        "if validate:\n",
        "        history = unet.fit(\n",
        "            train_ds,\n",
        "            validation_data=test_ds,\n",
        "            epochs=num_epochs,\n",
        "            steps_per_epoch=train_steps,\n",
        "            validation_steps=test_steps,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1,\n",
        "        )\n",
        "elif not validate:\n",
        "    history = unet.fit(\n",
        "        train_ds,\n",
        "        epochs=num_epochs,\n",
        "        steps_per_epoch=train_steps,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "#y_hat = unet.evaluate(test_ds)\n",
        "\n",
        "print(\"Completed\")     \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MBPWHo79s1Hz"
      },
      "outputs": [],
      "source": [
        " def makeTFDataset1( shuffle, augument, x_paths_list, y_paths_list, batch_size):\n",
        "        try:\n",
        "            ds = tf.data.Dataset.from_tensor_slices((x_paths_list, y_paths_list))\n",
        "            \n",
        "            if shuffle:\n",
        "                ds = ds.shuffle(buffer_size=len(x_paths_list))\n",
        "\n",
        "            ds = ds.map(tfParse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "            \n",
        "            if augument:\n",
        "                ds = ds.map(imgAugment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "            ds = ds.batch(batch_size=batch_size, drop_remainder=False)\n",
        "            #ds = ds.repeat()\n",
        "\n",
        "            return ds\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in make TFDataset {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "LCumD8yCBX3-"
      },
      "outputs": [],
      "source": [
        "test_ds = makeTFDataset1(\n",
        "    shuffle=False,\n",
        "    augument=False,\n",
        "    x_paths_list=test_x,\n",
        "    y_paths_list=test_y,\n",
        "    batch_size=batch_size)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MGkGHRtCIlcu"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_ds = makeTFDataset1(shuffle=True, augument=True,\n",
        "x_paths_list = train_x, y_paths_list=train_y, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet.save('model.weights.best.hdf5')"
      ],
      "metadata": {
        "id": "VSrZF6OUpckZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/results/fit.zip /content/results/fit /content/model.weights.best.hdf5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrIfHhG6jOdC",
        "outputId": "801b028e-9c32-4096-bc67-c238632ab039"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results/fit/ (stored 0%)\n",
            "  adding: content/results/fit/20220827_013227/ (stored 0%)\n",
            "  adding: content/results/fit/20220827_013227/checkpoints/ (stored 0%)\n",
            "  adding: content/results/fit/20220827_013227/model_params/ (stored 0%)\n",
            "  adding: content/results/fit/20220827_013227/tensorlogs/ (stored 0%)\n",
            "  adding: content/results/fit/20220827_013227/tensorlogs/train/ (stored 0%)\n",
            "  adding: content/results/fit/20220827_013227/tensorlogs/train/events.out.tfevents.1661563959.be7b7abd434d.77.0.v2 (deflated 64%)\n",
            "  adding: content/results/fit/20220827_013227/csv_logger/ (stored 0%)\n",
            "  adding: content/results/fit/20220827_013227/csv_logger/csv_logger.csv (deflated 52%)\n",
            "  adding: content/results/fit/20220827_013227/Saved_model/ (stored 0%)\n",
            "  adding: content/results/fit/20220827_013227/model_history/ (stored 0%)\n",
            "  adding: content/model.weights.best.hdf5 (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/results/fit.zip\")\n",
        "# files.download('model.weights.best.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "z1P2DEQMjQB_",
        "outputId": "4c0af1cd-6c89-4497-b6eb-f7789eeba06a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ed95e049-c9b0-45fe-a1ce-97dfad700829\", \"fit.zip\", 240526119)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cM5c61hsY9zq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "bRy91OTxNnym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a2ae4c7-2743-42b2-c87e-d7d42a98dc58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05046413466334343,\n",
              " 0.997045636177063,\n",
              " 0.25915002822875977,\n",
              " 0.39566129446029663]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "score = unet.evaluate(test_ds, verbose=0)\n",
        "score "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehZjMJj_ViSR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ihfzEvA6NAS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b166e1-34a5-43f0-b2c2-93f05e437709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.997045636177063\n",
            "IOU Metrics 0.25915002822875977\n",
            "dice_coef 0.39566129446029663\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy {score[1]}\")\n",
        "print(f\"IOU Metrics {score[2]}\")\n",
        "print(f\"dice_coef {score[3]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W2FrY_epVoRS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dtht3dayvWSI"
      },
      "outputs": [],
      "source": [
        "i = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "IVeEZIevwLzg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Ms8fiADKwq6i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "A2Hu8b8_UMD2"
      },
      "outputs": [],
      "source": [
        "def loadFullImg_1(path, dsize):\n",
        "        try:\n",
        "             \n",
        "            print(path)\n",
        "            img = cv2.imread(\"/content/gdrive/MyDrive/cbisddsm/Test_output_full/Mass-Test_P_00016_LEFT_CC_FULL__PRE.png\", cv2.IMREAD_GRAYSCALE)\n",
        "            print(type(img))\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "      \n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "            print(f'After norm_img')\n",
        "            print(f'type {norm_img.shape}')\n",
        "            full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "            print(f'After full_img')\n",
        "            print(f'type {full_img.shape}')\n",
        "            print(f'done for path {path} with shape {full_img.shape}')\n",
        "            return full_img\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"There is an error in loadFullImg {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "MN8ydZ_-UV74"
      },
      "outputs": [],
      "source": [
        "def loadMaskImg_1(path, dsize):\n",
        "        try:\n",
        "            # if not isinstance(path, str):\n",
        "            #     path=path.decode()\n",
        "            print(path)\n",
        "            img = cv2.imread(\"/content/gdrive/MyDrive/cbisddsm/Test_output_mask/Mass-Test_P_00016_LEFT_CC_MASK_1__PRE.png\", cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "            mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "            print(f'done for path {path} with shape {mask_img.shape}')\n",
        "            return mask_img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in loadMaskIMG {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "wb2fsrPDUMK1"
      },
      "outputs": [],
      "source": [
        "def tfParse_1(x_path, y_path):\n",
        "        try:\n",
        "            def _parse(x_path, y_path):\n",
        "                x = loadFullImg_1(path=x_path, dsize=target_size)\n",
        "                y = loadMaskImg_1(path=y_path, dsize=target_size)\n",
        "                return x,y\n",
        "\n",
        "            x, y = tf.numpy_function(_parse, [x_path, y_path], [tf.float64, tf.float64])\n",
        "              \n",
        "            x.set_shape([target_size[0], target_size[0], 3])\n",
        "            y.set_shape([target_size[0], target_size[1], 1])\n",
        "\n",
        "            return x,y\n",
        "            \n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in tfParse {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "06CumsaLV6JC"
      },
      "outputs": [],
      "source": [
        " #model.load_weights('model.weights.best.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "aRVx-4W1T0jO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72519ed0-594d-4266-c00d-a0c3a89482f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/cbisddsm/Test_output_full/Mass-Test_P_00209_LEFT_MLO_FULL__PRE.png\n",
            "<class 'numpy.ndarray'>\n",
            "After norm_img\n",
            "type (512, 512)\n",
            "After full_img\n",
            "type (512, 512, 3)\n",
            "done for path /content/gdrive/MyDrive/cbisddsm/Test_output_full/Mass-Test_P_00209_LEFT_MLO_FULL__PRE.png with shape (512, 512, 3)\n",
            "/content/gdrive/MyDrive/cbisddsm/Test_output_mask/Mass-Test_P_00209_LEFT_MLO_MASK_1__PRE.png\n",
            "done for path /content/gdrive/MyDrive/cbisddsm/Test_output_mask/Mass-Test_P_00209_LEFT_MLO_MASK_1__PRE.png with shape (512, 512, 1)\n"
          ]
        }
      ],
      "source": [
        "res_x, res_y = tfParse_1(test_x[i], test_y[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "XMaOVHjUT6He",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3546a5-9480-4dde-edd3-ea45ef9e8841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 512, 3)\n",
            "(512, 512, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "(512, 512, 3)\n",
            "(512, 512, 1)\n"
          ]
        }
      ],
      "source": [
        "print(res_x.shape)\n",
        "print(res_y.shape)\n",
        "print(type(res_y.numpy())) \n",
        "print(res_x.numpy().shape)\n",
        "print(res_y.numpy().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "hh-whdVrYM4j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "22403f7f-6ea9-4652-daa3-b98cbe3f9dd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, -0.1, 'Before cropping ')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3600x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAHtCAYAAABRWdSEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9TahsS5Ye9kX+7p2Z59z7Xr2q6qK7oZumJmpPbKotgScCYZCEoWeNNbDbQlCTFsjggRpPPNXIYE8EDTaWwFhusEE9aDCmsTAeyKgxxkYqbBfGTVfRqur33j3n5N/OPJm5PTj3W2ftuLEiYue5P/uJ+OByMveOHRF777zxxbfWihWubVsUFBQUFBQUfDiMPnUHCgoKCgoK/lVHIduCgoKCgoIPjEK2BQUFBQUFHxiFbAsKCgoKCj4wCtkWFBQUFBR8YBSyLSgoKCgo+MD4IGTrnPurzrn/yzn3Y+fc736INgoKCgoKCr4pcO97na1zbgzg/wbwbwP4CYB/BuBvtG37L95rQwUFBQUFBd8QfAhl+28C+HHbtv9v27ZHAP8IwG9+gHYKCgoKCgq+EZh8gDp/EcCfqu8/AfAXYxfMZrN2PB7jfD7jfD7jcrl8gG4VFBQUFBR8UHzZtu23Qyc+BNlmwTn3QwA/BID5fI5f+7Vfw8PDA77++ms0TQMAaNsWzrmr6reu7VPnS+rQZWiq73MvqTZ0nX5bOdfl9KdP2Zy+hfqX0/drnl/quj7PN/eaWBsv+S2H+hXqmz52Pp9f3FZBQUFv/Il14kOYkX8K4JfV9196e6yDtm1/r23bH7Rt+4PZbAbgaaDQA0guaYSOcaD3y1l1spx/jX99ro/buo9Qn/xzIaL22+ezYlmf4GL9Cg3SVh90+Zy++/fsP+8UeYX64/c5BZ94/Pdp/Xb8/lvPSZeN/T5CRBtq368r9RsL9c1/TwUFBcPChyDbfwbg+865X3XOzQD8uwD+IOfCyWSSNRBaKiFEsH0HIJ8k/UEyNvDHCDtEvv6g7ZObX6/fP12vP7CnBvAQGfp9yCGg0HOxlGTqHep2Q4gRlf7sTz5CFga/HYuYQ/fuf+5jAQi9X/+5+X3xfyOh+9XH3oeCLigoeL9472Tbtu0JwN8G8D8A+BGA32/b9p+nrpvP53h8fAz6a/soXmvQz1GKsfpTJKivC/XXaid3cNbExrZD95SrKP3rLPNuzrPOGdx9gkvVa322iDxVZ+h6i+xZZ+p9W/VY5/taSSwS1v0LvcOibAsKhocP4rNt2/YPAfxhn2tOpxNGoxFGow+bZ8MfTC1FGFMLISKyBmeL/FLm3xAR+PXlEqJ1zJqMpNR7SCnGEHsOVrnQ91D5UJ2pd5HT9xDp5r7DWJ0hxX0NQm3lPOOCgoJPg08WIKXRti0OhwPO53PUhJgziKRIk8dSprzQudgAbR2L9dsaLFOIEWKsjznmzhTZhUioD3HlltNKOKev/vHUs8191rmqXfc7p3zORCL2u4n1rSjbgoLhYTDpGp1zUbLNNcVp0rTMhDl+P/3ZIulUX64hilh91yiXkN+xL9GEzM7XqKfUBCFUt2XKTb3DWN+tdlM+Yf9YbCJiXZ/7Dq3f2bXWjIKCgk+LQZCtcw7z+RxAvh/L+q4HV9/HmaMIrPpCfUv1JTbgp+7TV+ih+wjBH4j7kLpFLH1J/lrfpPWcfD91jrUg91mHJiOpvlkTv9A1oXeY6pNVn/85hNTvo6Cg4NNgEGQLAJfLBaPRKKg8iRQphIjBMilrWAN4qK5Q+z4h+P31+5Lj67TuQxNCavDuQzJWf1KmzpxyqWv94ymzc6yfqXeoJ2GWpSL1DkP9D92P9fux6nnJO/TrLSgoGBYGQ7YAMB6Pg+oiZ8CLqZI+fjS/3ZjZONZW6FrfHB2bNOSYSzV555Ji6No+A3ouSYf66bcf6pNPSCkVGWvXejYp036fdxirM2SNyJkohsql3mFBQcGwMRiyPZ1OSTNmznF9PmT688to+IOdpbD61sXvmmStPulyfj0hko6pM0tRW21ZKquvgo1NfPw+WvDL5BKvvufQNdY7zFGJfn255vGYovX76fcpZKGx+uRfU1BQMBwMgmzbtsVsNjMJIWfmbhFJrA5rUIoNWD4JxMyR/BzrW6i+0N9Uv1Omd5+ofdXl37NFEDmKK9YPv27r+hBR5Zjfr0FfZRgz54fqjanrPpOaHBN27v+XgoKCj4tBkK1zDrPZDKPRCKfTCYBtLu2jfv02QuhrnvMJPKWQYsqT14dMiFb9Vls+OenrY/cYUlbWoJ9SrPq+/HtNTXj85x2qJ3cCFDpnfQ/dV47ijvVLH4/du39NSPXmWAFyzeQFBQWfDoMgW+ApcfpoNMJ0OgWQ9un1GVD6qsTcMiGlkVKdOYol9x5Tg3jMjOlf38dUHCKwkLm37wQo9ZxT9cQmPn1+N7HnGjP58m/oecfMxDlWBeu8brugoGC4GAzZnk6n6E4lvvLoYzrzFUZIRYU+5yopn7RiJBIiJV0uZF6O+QdTpkyr/32J3e+71e9YH/3n5PcjZBWw+p3zDkP9ylGKKYtF6Dn4z9FS+KH7u/Yd+vUUFBQMF4Mg27ZtUVUVxuNxcjD0zW055jl9jUVyIfLJHSStY/ranL6G7tGv0zKL5vjzQvcQIoQYqb0UvpILPXv/c45qTl1rvUNL2YfKh/rZx7xrwf+Nxt5hzKqQM5EoKCj4NBgE2dJXmzNb90nTUrX+AB1Sw7pszLwbaiM1APrHdX+tMqG+5Zgh/WtjExWrfqufMdWaIuQU0fvPt+9EIof0/DYskk7dY6gf2lpiXRNrW5+3zPsWdJ2h51lQUDAsDIJsgacBgkktQsg1p8a+5yoSv12rvhAZ5Jr3cgZ3fSx076kJSaoPMdO31ZdQOykzct/6cr/nqnjrHVplU+8wRWrWNSnTtVVHzueCgoJhYzBke7lc3smN7JOBNajnEop1TYz4clSGrsdX2ylSzVUxfQjNMiv2UXXXqma/PT1RSE0+clwCof7zs2U+fuk7TPUnNAnIOWbdS6iNPibiYkYuKBgeBkG21oDcx8RnKcKYKTi3bzkKJld15p4PmWhjfYn5Na9RQJZpt4+a0/3J6UNMXafIKlTXtdfm9Mc/HzOj97Wi6M+577AQbEHBsDEIsiX8wb2v2dGvq88AG/Ozxsrn9iV2XJuhQ0SZM2HoY8bN8a+mnl/snq4x11vwn0cfZdfXIpBzznoHue8w1maOtcV6DsWkXFAwbAyCbOmvZUQyYKvWHLIJDfgxX6h/XYh4rMEtVW+M2CyzrnWtpXata3xfr6/2/LZDqi026FsEbfUlhD5kHHo/17zD3IlFqP+x+gHbrxxrM/Vb8fseq/NaFV9QUPBhMYjN44GniGS9zjZHyeiBL1Y+pgZCROR/jvnfrMHVL2f1LTQ4+vdknQv91XVeY/JN9a1vv1Pme//dhEg/dj8xpRl6hyHS7PMOY5OMUB05rpDQu9TthWA9i4KCgmFiEMq2bdusjeNTdbBsX3+jPh8y7fapR5suQyovd0DMGZz7XOefj6nOnL6Gno9VZ1+frf/8UlYLv46Q2vV/H6kJTajfqYmfX0dMLVtWjVBdfX/HfawFBQUFHweDIFvnHMbjMebzOUaj0TvnQuZN/Tk2YMbMuKFrfd9bjnnRMjfq/vsDfB/yDU0kQn3uo2ysiYV/zr/fUD3WPYbuIXZvfSYAMcuDPmYRZswa4r9D3zzrv4fcyYTVf6vv/jWh8rH7KigoGA4GQbZUtqfTCZfLpXM85c8KnfOVjH8uplpTbfl1+oNjiPhyybWPmTlkGg21Z9Wry4X65k86Qv0MPRPLtM1z/jPPacfqe045vz7r/YTqtsg11UbOsRx1mnqH+nleM+EqKCj4eBgE2XIgO5/PUWKxfGkpddNn1m+Rm18m9j2EGLHF+pZS1laZmLL3y8XKpsysuef0ewy1Z9Xl15fz7GP3EZughcrHjuW+r9g7tPqTei+6zDUTj4KCgo+LQZAt8DxwLBYLiUgODW59/In+9z6DpU/ullLV53IHfv+4rwL7mr5D9fn3lKt0U2X0uT7qOXR9n3doHX/JOwyhD1nF1GaqfOy37cOabF6jmAsKCj4NBkO2k8nkHX9taDCPDZJ9zImERVwpAsxVpv41MZOsRRK5dcc+5xCNVZ/up1Uny8QUYx9Teorscycf/ju0Jh4vMcP6fQlNvnIsF33fcSHWgoJvDgZBts45IVsdJBUaiPTA6Q+iVhn/ex+yyfXVWeRkqd6QXzC37j7IJS/92X9mfh+sZxp6B74p2FLDlu8xROA5RBOzRITK5VglLItBrsneqid0PvSciom4oOCbi0GQLfA0cOmNCFKmx5A/T9eV+uzXaymlmI/V6mOI0PuSaUxZxo75569RsbFnGzqfa5KNWQdi9aQmPCmzbY56ZRt9Tb2x31dqAmb13Z+0FAVbUPDNx6DItqoqAHm+QH3eV2O6Tv2Xn1MmUcss6NftX5Pr8/TPh5SkdS8p86l1Tc6AHVNpfdVYjDhj1+a8Q79cqq3Qu7LqySHC2PlYH3MmVdb5kAk81Fbo/0FBQcGnxyDIlqp2NBphPB4HlVVsQPVNmEB80IkpMZ9wcgYun8wsv12sD33uNwf+QN9XBVuqLnY/KWWXeoehMikLR+g+rIlMqB+xevqYqkPtpq5PTSpD7zCllnNM7AUFBR8fgyBb4ClACgBmsxm++93v4vb2tncdKbWT4/vKISarrWsUhTWAppRlSuH4fepL/lY//Xqu8XX2NQmHSCdW7iVk07cOf4Lm9zNUty4TgzVZ6WPdKCgoGAYGQba+r3MymUQHkZTaCSlUfd4i4pC6tAbNnIEvZpZNXZOrEmPm25Bp+5rBOWTCtJRWqK+h86FnapFWzrFU2ZDaDZnuY8o65V9NPes+Kjo2melreSkoKPj0GATZAk8bEcxmMzjn8Pj42Mkk5cMa+IEuWVmky8/6X8gX13cwS5krc+rqS4YhgokRVwrW4J4a9FN9TNVp+UJjCjb1nnxS9dvKUaM5JucQUuZwfSz2fGJtFpNxQcE3B4MgW+ccptMpptOpRCTPZrNgWWsgDg2gOQNVTEWmzuvP16pGjRRpWNf4yBmEQ4TFa63jsXM5JvoUYu8w9q5j95v7DvuYj2PvImbB6PMOc/ryPp55QUHBx8EgyJaD1OVyweVyQVVV4sP1zX0vIbSU+S1XMfn9zvVbWqSUo/Csa1JElxr8LROo3+e+JmT/mr6fU7j2HeZcY5UNTUhSfbYmNRr+s0/1Q19nWW4KCgqGhUGQrXNOzMZMbuGTgE9WlvlU/2W5kGkwpXp9MosNkinS0fXEBsg+Cjv0OUaMRA75+O3FlGGI9K1n4pNVzIzr9zHkD801sfouhVxrQOy77kPsN+m/J+sdxurQ5/0JXkwxFxQUDAeDIFsA4q+9XC5omgZt28oyICA/WjY20w99t4hJD6T+oKrhk2ioHd0/q51QeaufMYTMvdb5GGGlTJQ5g32IkK0yLBd6h6Ey+ntscuG/Q6vNnPuO/VZCsMqn1K1fR4iwredTUFAwTAyGbJ17SmpR1zWm0ynm8zm+9a1vYbFYZA0sOSozNODlKLLUOb9tS3VadcWINEZqIVNp6F60sutD2tbEJUQA+m/MkhBr33pWlpKzJkJ9yCdmTcgtm0LIuhEr51+jr/XLFdItKPhmYBBky0FCm5DbtsVkMsG3vvUtfP75551yfesNHYspHb98yu+WUkEWQsooNDBbg3TqXnSdKRWbUluxQb3vvabUst8HS4mmTLKpiUpqkpNS97Frdbu5hGjdT99ri1m5oGB4GATZEm3bYj6fY7VaYblcwjmH733ve/j1X//1j9aHlyjbHLNhaiC0CO4liA3iPJZLoH0Uqq4rZ6KU8+z71JMyz8fOxyY5FkKTp9i1fd5rbp055wsKCj4+Jp+6A4RWt1VVoW1bnE4n/OxnP8N2uzX9Y76f76XmNEtZ+u35n3XfQiZAfdwvb9WbUmbva1DNMW3GTKg5g3/MR53yy+b2NdRnS9WHnnXsXecgRd6h8h/rPRYUFHxaDEbZnk4nAE9ky/W23GrveDxiPB6/s98tcJ0fLaXKcvx2uWY9X0lZCtInr1hQj9W3PvD9oFb/U+bn1PdUEFHoXN/nGqsvVLfl1/b73lfRho7779A3X7+PiaFfVzEjFxQMD4MhWw5Ej4+PnQxSzjnc3NzgO9/5Dl69evXOdRy8Yr7AUFs5yBnQ34eJt49qzTFJ55SJkWgKOWrXPxbra1//6PsgQn0u5L/NNatbvz2rj9Zzz+mn/9ny0xZ1W1AwPAyGbGezGcbjMcbjMYAnhesPQOPxGIvFQr6n1F9O4FKszDX+Set8nzr6miND9V0zCdHtvOSeeX3MxK6P932HfcrkPv+c55QTVBXrY+y3Z73zkEuhoKDgm4fBkO3pdMLlcsHpdELbPmWTmk6nAJ7yJs/nc9R1jW9/+9tYrVbvXB8bcLV6eokay1GSqTpz6wmZG/uYDVPmcItU+5BUX7PxNWo657n1uT9dPvZb8N+FPymImf/1dTFfdc5ELebXjf2uCwoKhoXBkG3btjifz2I+Ph6PGI1GshyIgwqJF7AHK3+g1QNlaBCOHdPtWO3FBrocZcZyvj845W+0juco2dQ9xfr6kvK5Kjv0Tnyii73D9+njTk2edB988u3Tbp/JxLVtFBQUfBoMhmwZFDUejzGbzTCfz4VsOZiMx2Psdjucz+d3rg+ZLEPqLKQUQuXf1yAWI8LU4JpL1P7xlJk1x7weOhdSwSE1+1ITtC5nEV3oHeZYLnLJPsdnrr/7vxf/maWeud/31DtLlS8oKBgWBkO2j4+PQqzH4xHOOdR1jfl8jvl8jul0iqZpMJ1OZWkQkSKKa8x3fZAa6CwiDCnVlOn4mn71MZ37fdDPzzJl+9fm9ruPGs8x1fvl+0xW/PIxUvXrS5msfatFqC+hZ5hq1/peiLegYHgYDNmORiOcz2fx3TrncDgccLlcMBqNxLzMaGXuDDSZTDCfz8XcrJHry+o70Gtf2bX+Mj2IxnxyL63b6rN/XMOaEFikEWozRrgxEsxR4aHzKRNurF7L/5qC9f5DLoE+9epnZ6nl2DssZuWCguFhMEkttF9Wm4s5iEynU8xmMzRNg/F4jM8//1yWCJGoD4cDdrsdAJuo3ofSjamj3EE6dwCO1WmdS5maY37Q1PV92gyV95Vy7r1cY42w2vK/p/oRUvp9fkchM3vsWcbq4jlrklFUbUHBMDEYsnXOiTo9n884n894fHzs+Gsvlwsmk4kQLD8fj0f5nGOavGZAspRKqEyovb6+Sn7OUU/+8VBfrP6nFPZLJwapfvBvLqla1/llYnVZZJczkci5/5irIDYBSCGkePV9pO67oKDg02EwZmTgmXAnkwnqusbNzQ0Wi4Wo3el0iuVyKdvx0YS8Wq2kTFVVnTrf10xfm+osc6z/2ScyfZ+hfln19Rk8Odhb/Q2RX0plhfoWU39+m7HnFuprLmJlNamHTOV9zNM5/dbHQm1Yaj7VB78foQlGXzN1QUHBx8cglC0HkPF4jMPhAOccptMpxuMxTqeTDGJ1XWO32+F0Oknyi7Z9WpNbVZWkfJxOp9hut+LnfSksdecPgL6vzr9H67uliELXhfqQ8g/m+gljdeSWDRFITH2l2rPuL8fMailfqw3/utSE59p36JeNWRdi99vH6lBQUPBpMQiyBZ58trPZTMzCDHYKrbMdj8c4n884Ho+dtI5Uu+fzGXVdY7vdZpl2U6ou12xsmSZjdaTOpfppTQJyBt5Q3bn3arWXIoWUmTl0XYgMY88lpMJjJvLQhCFEhjG873do1Zkz4Xhf1pyCgoL3h0GQLZUss0ZxEwL6aYGnKOTz+YzVaoXFYoHT6YTdbof9fo/D4YDpdCoDJKOZGUDFZBmxQa0P+fbxjYXUT+i7pfysPsfqyiV7i4T6IlZPzuQjRoR+2RTpW+VD9af6GmszhZz+x95hqK/WZKgo3IKC4WMwZDubzXA+nzGZTMR0TOIEnkzDXIt7OBwAAMvlUtbfNk2D8/mM/X6Ptm3F99s0DQ6HgywpivVBf76GhFKDZ8653Db9PoZIOzQ4x9p9yT3nEH9OPX6/YmVi95prrfD7mpoc5EzKcp9jSuX3fYd92i4oKPi4GATZjkYj3N7eCrlqYuSxx8dHGfiqqkLTNBKF7JyTxBebzQbr9Rrb7VaUsXNPa3aPx2NWUIpvskwhZHZMDYCpATSnzRBiJJcikphZ0jqXUpr6OfZVjpby9wnoJc/Sei85yrTPM+mLPs/c9y0XM3JBwfAwCLKdzWb4zne+g8fHRxwOBzH78m/bPm0kfz6f4ZzDfr/Her3G8XiUZUI8V1WV/N1ut6JuR6OR1BFTK30IJ+bn7Kt6rLqt4BmLNC1i8+vT5S349Yb6GbsvXzHmXHPNJMKvK2WqDdWTMmX3gfWMU3XlqGyrvpxJQEFBwafDIMh2Mpng1atX2Gw2AJ42IdhutxiNRnh8fMTpdMLxeMR+v8flcpGI5bZthYzbtkXTNDidTjidTphMJmKa5uAzn8/RNI2oZovIctRTCCFy8nGN4kqpw1y1FaojlzxT/bYIrq9J+VqiyHk2oe9WMJR+h338+dY95JBuaFIQOh+aNBUUFAwbgyBb4Dn4Q/tod7ud+GJpRqZZmBsWOOdErY7HY1G7wJN5uq7rDiGPRiMcj0c8Pj6+037oM5HyF/K6kGq+BjHVHCsfuge/rphJN7f+a/2VMdPyS/r0El9l6h3mTjqsZ3TN9SmVnaqnoKBgWBgE2dJMTH9t0zTY7Xa4XC6iRLUfdzab4Xg8YjweS0AV1+QyKpnBVG37tD6XmxpsNhs497RE6Hg8ytrcUJ9ig1uOOomV0+2EyloKNEeZxfrQx4waOpfTnt92jERyJjnWPVjfU3232o8ds+rU30N151oRUudz3mFu/wsKCj4+BkG2l8sFu91OApioYEmiHGym02nnPPCcU5mfuXSIipffL5cL6rqWaOamaWSA5Ib1xDUKi8ghsZi6s+q/xvwc6pdvHuWxFFFY9afUvnUvuYTmE6XVJ+v95apB656sOmP9ucb/myLiUPu5v5+CgoJPj0GQLQAxDY/HY1GeJFqSJ8tw1x+agpkMg6R6Pp8lEpkmZH5nZirumbvb7bDdbt+JgCZyB7KU4gyVzTHr+srMbytF5NbxkOILqfmQirSej/9XP4PQ88j1Q4fq9tGXVK37Sd1bTn+utRqkzoXeYajPBQUFw8MgyHYymeDb3/421uu1LOWpqgq73U4GFvpsaR6mouUGBMwcRX/seDzGaDSSoCq2QwImsXM3of1+j+1229mYvo9iyCGvWH05pJMzKIcIL1R/qN6QuTVEuKH+xPpu3XcfVZYiGP9+Q3207uF99C/Ul1A9Ob7X1D3GJmlF4RYUDBODIFsq2dlshsfHR/G7zudzMSfP53OJUOYxvUsQCZMgAXOTAgZRkaxJqhycWCeXHvFcH1Odr96uIR/re8xvZ6mdXNXmf7+GgKzjqYlHiCSt55QzcfCvfx/36yP3GevvOb+hmPq3nknqN1VQUDAMDIJsL5cL7u/vRVmSHAHIdx3IVNc1AAi5MunFeDzGfD4XJQxAlv/wer3elkTNchxEfcLVf0MIqVp9Tl8f8sHlwCfSlEIO9TnHVK3rCX327yWmfP3+8JrcspqgYgQbOh4jpdQ9hc6H+mndS1/iTrVlfc/pa0FBwTAwGLL1174Cz0TrD2pUrfTVzudzKUcfLQmXCpn1cWAiuTr3FCDF/XHrusZoNJI1uznwB/Uc1aVhKaU+JsIc0+Q1E4aQ4vTLpAb72EQk9Xxiz9a6xmozd4KTM0mJPeNcC4Jl8o5NlvTx3N9GQUHBp8cgyLZtW1GTDGSq61rIkxmiAEjSCqrY4/Eog7BeBjQej7Hf7yUhBusZjUYSXOWceyeHMr+Px2MhXO3HzbmXnIHeUqkhctGfc4jAN932Ua4x5Wn1OaXmQ+3495QiltA1VvuxNkPXxCYOIXLso55jlgatkHOsB4VQCwq+uRgE2QLPy3a4Ny3VKjcgYATydruVazgAMdPU5XIRtXs4HDCbzVDXtazdpbmZ2/dxw4OqqsT/S7Jt21b21w212Rcp8ssZVEPnrWMhpFRWiET9+kJm8JSyjPUpRm4xYs0hyFxzesoS4E94QnWE+m7db8rs3YdcCwkXFHwzMBiyXSwWsv/sdDoVkqQpmQFQDJDSf51z2O12ACBK1len8/lckl4cj0fc3t5KWQASNEUi5mYHs9kMo9EIDw8PQQUWg6VWLNWSa1b1y6euDRHAtaSdQwSW2ouRmqWoU88jRKj+M/Lbz7EYWKSZS/D+Nf7x1PPPJd6igAsKvhkYBNmOx2MJeuJetvSfOufEvzqdTrFarfD111+LuZnpGUmKp9MJVVVJXXVdy5Z8TGYxmUyE3Eni2v/Ltb70/+q9cPsOZtYgmKPQQu1Z5S0lZ10fU6O6bOh4n37G2tP9jqnIWP9jBOffR0pRWvcde4d+eznPJvdZWOVTk4OYK6CgoODTYBBkS5XKZBOz2UzOMRHFfD7HYrGQdbTH4xHH41EU63w+l4xRAMTPW9e1+GhJyNyej+VI2jrwigP6/f19Zx/cXKINkYJ/LkbcMbNuDLGBuu9EIdR2DpnociFSs1SdX1+IOHImCalzIZIMXRezHOQ8y9RE41qk6ivKtqBgeBgE2TrnJLMTzbhUtCRNP9exVp+z2QyTyQSPj48SccwIY5qKSbB6+z6SNsleX8/8yxyYWX9MZfQhUd5j7JlY1+Ve0/d86tpUME9O232Utk/AVj0p/6l13PK/5kwUcok2p08ahSgLCv7VxCDIliZiEiSV5eVyET8tg6cYqcxAp9FohJubGzH/sj7ujXs6nfDmzRvc3d3hcDiIiZnlqFr1vrmn0wnL5VI2OqCJ218KlDIPhvyCLyUI6/mlyMzvzzW4xvTqf75GeadUZerZ6DIxUrWuz3m2/rEcBZ47KUu900LQBQXDxyDI1jnXWXJze3uLtm3x8PCAqqqE9JgR6vHxEa9fvwaATg7lxWIhJH04HPDw8IDT6SRm6S+//BLz+VzInP5amj7YnLIAACAASURBVKO5pV/TNLJsiH7j8/ncyVDFfvvwA2V8X1pM+eaYWS2Ss+pITQZyBvtQP63786/NMX1bE5Gc/qbI5loisvzAKf9tDnGH7te/NlTOv6dCtAUF3xwMgmwnkwl+4Rd+AePxGFVVCcHtdjtRr8xhPB6P8ebNm84etTQF0w+73+9F1TI38nw+x+vXr9E0DW5uboTAGZ282WwwmUzEB8wt/Ogjjq21jQUt6TKh4yGEBvUc4vOP+33z+xy7l2v6nlKKsUmGf785fuBQvS9V76F+hvoU6puebITu7dp3eE3/CwoKhoVBkO1sNsOv/uqvyqBEczE3G+Dgsd/v8fj4iKZpADwv8zmdTrLOln7W7XaLL7/8Evv9Hs45iUSm6uWyIBJ0VVXSJpccMVfy4+OjrMm9dlD0yS9lMg0N6pZiDNXN4yniiplkQwFCfVQn6ws9s5Sf1CLenP76vt5cIk4pydQ9p4g4d7IQ+xyqJ3diVlBQ8OkwCLJt21aW54zHYwlioo+UwUxMTsGyx+MR9/f3aJpGciGTqJ1z2O/3snMQlSr9uiRPHWjFDFSLxQLn8xm73U4UMIO12M41JrzYQEnEiDg0sFsqyrou1JdYX68lKOveYn2K1e9fl6t8+7RpTWxS7eWo6djzs8rlEHlOGwUFBZ8eSbJ1zv2XAP4dAD9v2/Zfe3vscwD/LYBfAfD/Afittm3fuKf/7f8ZgL8OYAfgP2jb9n9LtXG5XLDZbCRLFKOFtTmXkcPce3a73WK73WK/30sUMxUsy2gFPBqNZGkR/bF6AOPaXpI9s08dDgdR19zzVudYjiE2COf4YFOm1T7E6p8LKchQvTkElZocpBSh9Sw02edaBFJqMIWUus0p26cPuROh2G+pkGxBwfAxyijzXwH4q96x3wXwR23bfh/AH739DgB/DcD33/77IYC/n9MJ7vpzf3+PN2/e4P7+HpvNRjZ2v7u7w1dffYWf//zneHh4wHq9xna7xWazEf/s+XzGdrvFer2WACe9Jnc0GmE+n8vyHZqoGVylCZe7ATEpBtf5cs2uNUCmTMy+UrTUachcmCLaUPt9fa2he/LrzxnsrX74hKHrDD0LXdb6Gyrnt2M9J/03Z/Ljf7fqZR9C7zCGl7zDUF8LCgqGg6Sybdv2f3bO/Yp3+DcB/OW3n/8BgH8C4O++Pf4P26f/9f/UOffaOfe9tm3/LNYGN33XftHj8YiHhwchRC7J0ZvEn89n8cVSEdNv2zRNR5k652SdLs3TNBvTD8wgLL1X7nQ6xatXr7Db7WSw45IkDcukmONP8wkipIws1XeNsozBIvmUOvWPpyYeVr+s+8lR9SHitiYufvuxZ5Rrqg9NHvT1OVYC615yiLYo3IKC4SJH2YbwXUWg/xLAd99+/kUAf6rK/eTtsSS47IaK9uuvv8ZXX30lJl+SIX2w3GB+uVx2CPhwOEhiDBLt7e2tJKkA0Nn3lj5Z+nNJsEwNWVVVR+Eyb7Ner+sjl5isa3JJwB+Ir1FO/nXWpCFUNlSP7pP+F1KUqT7E+uGbmHNN6lZdsftLqeqc9nKsB/p7rE85E5mCgoJh4cUBUm3bts653vYr59wP8WRqxre//e3Orj273Q7r9VoCoc7nMyaTiSS0oIKtqko2F3DOiTm5bVuMRiNst1sh6NFohNVqBQCyo9BkMpH6qZ6pfEnEq9UK5/NZgrBolp7NZnh8fETbttnpHFOk6yuynGv8661r+yhOXVfsvEafe9N/LVNvjJxyFa5WhyklHrrO6p8Fy9KQ0zYRe645ir+goGCYuFbZ/sw59z0AePv352+P/xTAL6tyv/T22Dto2/b32rb9Qdu2P1itVuJXZWDU+XzGZrMR/yujk0mGmjR08BN9scDTcp7FYoH5fC7H67rGYrFAXdeiaHkd1a1OsKG33auqCsvlEovFQvbFZS7mwP1d9WD9wTOlunz0IUlL6eqyfUgmp5++4g2Vj6lp//78CUTMZNxnouG3H1PlsXb9+nKO9+mfdV8FBQXDwrXK9g8A/DaAv/f27z9Wx/+2c+4fAfiLAO5T/lrgedBk9PHd3Z1st0fV2DQNnHOdDeO53+zhcJB0jjQDkwyZR5nqdTKZiApmu8vlEpfLBdvtVkiZxH9/fy9tLZdL6dPj42Mn6YVWt7wnjRzza0rF5Kq9HAKxjuUq1NixnHvRx2MqMOeec/tr9SflU82xMliTAP/amMpOoY9qLigoGBZylv78N3gKhvrCOfcTAP8Jnkj2951zfwvAnwD4rbfF/xBPy35+jKelP38zuyNvE/3v93tZz8pt70iUj4+PQqo6jzITWdAszB2EtKLVGaiaphFzMweqqqrE30vT8Gg0wuvXr3E4HLBerwEAdV2Lf5iEOxqNsF6v3yHcEKwB+O2z1s89eq2GrxBjBJU6n1LG1sTA70cOYYZII0YcOWVSxBN7/inkEGXqGVzzDkOq2ZpoFPItKBgmcqKR/4Zx6q8EyrYAfqdvJ5x7WnbDqGAmrhiPx5hOp6iqSvIbc8s9AEJ2X3zxhQRDMaqZg85isRAfrP5c13XH78roZQZXMcWjcw5fffWVbOHHKGXnHO7u7qS+vgM2PweeYdD86asiS/mGgmn69E3/DfXFmhjQ1BpTqjFVltNHS43GnkmsjpcQVegdxp6bdQ+W9cJ6NjkWkoKCguFhEBmknHOiPKuqQtu2kjFKZ3yiX7WqKuz3e9R1LcFKq9UKX375pQRQsTz9tMwUtVgsJPEFSX48HmOxWKBpGvk+n8+x2WzQti1msxmm06lERtOPyzzKAGSi4CtmH/5ArI/xWei/+nPM/BlTRKH6/XMxUvTJNFTGbzt2LPZcYn236k0RtkV+OQrcmhjFJjZ9iT/0mwj13ZrUFZ9tQcHwMQiyHY1G4jcFnqKFJ5NJJxmFc042F9CDD83Lm81GlPDj46OYe3ktg6Coav19bxnstNvtRO2STC+XC5qmEcI+n8+oqko2J2BkNCOgc8zJKYKzrgl9Dn3XbcSujxFVbnuxoCGr7tjx2Dm/LWvy0bc9XUfufeeo0hyEfgtWGzGLRlG1BQXDxSDIlsqWGwVQWersTQxCattWIpaBJ2IGntbUcuu8m5sbqZcbw3MtLjNIsW76Xtu2lahntsFgKxJs27ZyDICQKhNuMK9y0zTv7H3rI6bcctSmX9b6nqNkQ++jz0Qgl9z61BFTlC/tR+x4H8K0nqX1PmLvMKdfKRdCQUHBcDEIsiWBrVYr7Pd7bDYbWT/L/WfrusbDw4MQMq+p6xpt26KqKux2OyFCki/Xyeot+WgCZmTzZrPBdruVpT/0z1K50pzN1I4k3fl8jsvlgtVqJcfW67UEdlkKN2Y2BGzfaage61q/LUvJxgjDvzakvixlmZoc5KhQy0zblwhD/UyRe9++WybqlJk655z1Dvs8j4KCgk+LQZAtAEkgQTKkkqW5lstyqFqpUpumEUKdzWaygfxisZBN6KleR6MRbm9v8fj4KES72+2EFCeTCRaLhaR8ZBILBlxNp1Mhdi5FWiwWAJ53EQIgmyPQxxtCaoDUg7dFFNeYLS2llToWQo6JNdVeqF/6u39Nyj+ZQ5opRZsq4/fDek7W5CM2scmBRb5+uwUFBcPBYMiW2aKoYrmkhnvYcslOXddCfvTt6ghlKuLlcilBV9y3lkuFmBZS50BerVa4u7uTgKzZbCbkO5/PZT0vzcVcs8s1v5wUTKdTMTkvFgsxTYc2n0+ZgEPIJQ/rXExpXWvSzjFJxxCrL6QUc33Euffj9zfWN6scj/kE65fvU1/oXO4kraCgYFgYBNlyAGEksHPPmwZUVYWqqoTUnHNi6uXAQlIEnva4nUwmqOtagq6YJUoHYHFXIG7hNxqN8OrVK1HM+i+Dn8bjMXa7nfh79/u9JL+gCqc5mZscMPEFI5VjSCnJ0DPr+5zZTq7fL4csYyZX/3xIOcZM5CnV11f5pszEsb5dOxnS115jgfDrz/XfFxQUDAeDIFvmHiZpMViK6pIgibVtK8t7GPxEHyo3DyCBclcfAOLrZRuMSNYZoDhYcb0tjzFBBvM3a98vfbVch8tNCrhxAQmduZupfC3kDKTXEK3lb0whh5RDbaWOWcdzv4fuKaUgQ35n/1q/vD6f8ltb99XXVHwNmRaiLSgYLgZBtm3bSoL/tm0lYxQJlcqybZ/yIpPgnHNiNuZ3EpxzTsjb3+ydKnoymXQIkOTtD+B6iQ/9yVwuRKVNcgcgflouK6Lqpdo9n8+ye5H/HHIIwhrscwJmcklQnw9dFyuf8nfG+tMHMTLLuf+ctvuY4QFbwcbera7rGvVcFG1BwfAxCLIloem1ryQ2AJ1t85xzspsPFS0VJgAhXX4GIMTtnJONDRj4RFMyAFG7jHj2E1SQ7J1z0r/pdNrZJQiAmLyZ1pEThcPhIDsQ1XUt7VgEkSK62GAfI94UKeUQg6WUrUlBn0nEtXiJafUl5VKBX/p4TgDXS99h8dsWFAwPgyDbtm0lIQVV7fF47PhldQAUrzmdTpLGEUBnb1odRUzlfH9/j7Zt8fDwIAS93++FKKk69WDFCQAJEoAQsd6sfjweS7KM0+mEr7/+WgiZdZP8WZ5kr5+DHlxjClGX96/1y/nPOjWQW+otRIzXKshU4FUuEfcl6Vi71/pk+0w+UlaEHOXtl8sh8IKCgk+LQZDt5XKRYCPu0ENypGKln5Y7/BwOBzHLAhClSwXJ6ObD4SD5kkejkZBb27bY7XYyANKETaUMPA9aTdNIP5mR6nQ64XA4iD+4bVtZK/zw8CB5mKmim6YRE7duh+3q9nIG2ZyBORY8lEsuoTavMXXrPobIOofwc/y7of74x6xnFzoXmpzE+ssysfeT49MO9bWPhaOgoGBYGATZkvgWi4WQql4Hy3Wx2k+rg51oHtYRx3pQ5JZ4TdOgbVvJJsVEF849RT8z85Nviqa5Wu9dy/ZZhmr3eDzicDjId2asItGz7wDkHvUaXX9QJ1Iko4kw5TfV32NmTn7OUZl9+pMiHr8fVhsh+BMCi/Rj95EiuBz1S8L1r7FMvClrQ6z94rMtKBg+BkG2JCNuDkDSpA+UftG2bWWjAfphj8cj9vu9KFuqUp+0OPjpbfSoMBkpPJvNOmqVJD2dTmVJkt7kgOR7Pp9xOBxke0CauLn0h9sCcmLAfjEDVtM0QsoxlZV6hv7nnGv7ErBGinh9wg3V34dU+rSdOp7Tbh91aU0ocicaueQfarMQbUHB8DEIsgW6flASFjd6ByA+WL0vrR4MGejESGEu0dGBVXr/W15HHzGJl+3R10r1q4OgSOjsH8mW2ahIqjxPguZ3kjmJ3Lnn3NBaEeUM9CFi7EtSVntE7HisXotkckg7Vz3GTLs++irAnElLjmndekdW31PvPceKUVBQMCwMgmzpiyXRNE2DxWLR2Qye5x4fHyVrFFM0klxJonrtLZf2UIkyK5XehJ7BTSRJZopq2/YdnzH7yuAsLvuhSl2v12J6ZrAUSZz9pprmPfkThxQx8XgfU2uMZHV9sYE9p96YWotNInJUnl9HjIxCx1PtXEtcOb7gUD9iiJG3VVdOvQUFBZ8GgyFbZn7yTcTA8zpckiqjhrVflP5ekhpNxdvtVrbao4pcLpcShazrZmQz00NS0TKJBc/RXE2iPZ1OuLm5gXMO+/1eyvMz1fNoNJIdhgBIsBQnA7zXEEEB75pdU4OrTwL+35iZOKV2c4ilLwH1RUqlh8pbbeYSvI8cggv5bv1nH7rGr9uanORMtgoKCj4tBkG2ACSloY4EZtATiZjmZe5Z27ZPgVX0p9K3Sl/qbreT5TUctOiHpUolyZJEAYivmLmOScYAZMkQk1twpyH6gquqCvp66S/WS5VYjm2GTIPWoJzjr8sltpSZOKQEc0ys/vlcIogp0Jj6zVGm1vmc5xhCiAyt61k2x/yder65yregoGAYGATZcoCgauU/5jamL5Y5jvUmACRgRgHrre9IwKybBE7T7Ww2k6VDDMoiYWo/7eFwEDIEnnb1IWieJmGTbNm2jkbmvrz0PzNqmROJ+XyO3W73zvOxzJ19CSdEYjweU7n+e0q1k9ufWBnr/kLlYz7Q2LPK7eP7uFfLuhC6tm9/cn3WBQUFnw6DIFsAYkLWZDSdTkWdTqdTMRXf399L4goONLPZTDaPB54JhHmKuSzHOSek6pwTMy99skysoZNZrFYrqeNyuUjyCl2Gftq6ruW79tdOp1NUVYXT6dTZXJ7ETCUcQkyZpny8fdFHfYbgD/wpoovV5ZMTj+WaUV9CtDnX6j7G7kOfC/U5x09/rWIvKCgYBgZDtjpBvyZRAJJI4ng8drIyaZ+qnzKR/l3gedkPcxzT1ExSZHuadEmCOkLZuWd/sCZsBjwtFgtJwciAq8PhIJmwGLVMPy+vpSmcvuftdtvLTxqCNUDnXN+XgELBTn6bueRl9TdGTimT8zWTE8tsfa1Sj52z3rPlKkh9LygoGB4GQbYkHZImFSYJVecx1oFQdV3LZvBAVx0DkM0N+FnvGMT6tbJ9fHyUzFO8huZlKmIAnYCp8XiM7XYr2axowibBt+1zEo3j8SjmZvpvqXB5jBHW9DP3Ua0xgu5jpoy9J78fsYAufT5Exjl9jfUj9D1XAaaCq1LPK2Wuz+27j1DAVN93mArYKigo+PgYBNkCT+p1s9kAgPg6qf5InvSNUlXqfMnOPW1QsFgshBiZ+5j+Xh7318fS3MuoYG4wwKhontMJKEiqJEcSLScLJMy6roXAfV/ydrvFarVC2z5tNM/7ZHltqiZiA39MyepBOoU+ptiYovSRKpO6z5w+WT5pq4x1zCI1y7T9voKTXvIOS4BUQcFwMQiypRKkOjwcDpJLmIqUS3mOx6MsmTkej6iqSqKDOQhRgQLAcrmUQCoAsmyI5Mjy8/lcApjatpU2SJwkVJqDaVJmv7ldHwDUdS3+YfqbWR/NzPv9Hm3bdtrUOZyZ39nfeShEJLmqK2Z+tZAi0D7lYmVS95hjfg0dCynplDr0y1vX91HUfdFXORc1W1AwbAyCbM/nMzabjShFAKJCL5eLbATAKGEGKmk/J83MNA1XVdXZ51YHXXEZD1XrcrkUFUvVS9M2Tb8AJFKZClTnZj6dTqjruqN4Q/vp8r5IAiR2RiPzHliedQBp3yiRIqdrVaOFECnG1HaoDzGTsn8+1xyeQ+66nyl/bwypvlxjlu7j+/2QxF9QUPByDIJsL5eL7PNKM+x2u+2YZfWGALPZDE3TiEIFIMRI87LOUaxzEutsThyw9FIitsHjbIOftS+WYL0AJOoYgLRPk7Xe9o+7ETHoq22flyO17XPOZhJ6LvlZ6jWHSCwyjw34+hmk6o7VFbsHqw7/vnIIjdflmqFf0l/rfF9Fbr3DvgRdUFDw6TAIsiXJ6tSKAHB/fy8m2PF4jP1+3wmAIrkywpfkpEmYOYmB5w0N9GBENcvgKqpIquG2bWWDBB2hzGu0OmUZva/ucrkUlXs6nYRwAYiZmmbu8XiM+XyO8/ksQVV1XWO73b5DuDEfaq5CSxFVTD3n1Bkrm6NIc0jK72+sjlQfUt8t1d+H3HImB/795PbftwYUFBQMB6NP3QGCiSsAiD+Vg4lWoyRLKtD1ei3X7vf7TsATyZMErvMYz+dzLBYLVFWF169fA3jOHHU8HjtmbWa3AiBJMbjbEInRXxLEzeYZbBUaGHne3xGICTBms5nkXGYwWCzoh+irxvr6B/32rPK6jF/etw745TRx+P/89nyCCbVl3UOMmPw6Q6o/px2rvE/YLyXJomgLCoaLQShb+jSdc7Ihwddffy3Lcs7nM5bLpZhYqQBJwvv9XhJKcN9aXkt1yg0LGGhF5Xo6naQtEh1VJLfb4xIkKtD1ei0E6pwT8t7v96KutQma56hWgSeVzQAvva6YZnDnXGd9LicilvlQE6f+rmERcqyuXOKO1aP7zc8xcr9GOYbairWTU2/qGfUx2eaYe1MmYn1tTv8LCgqGg0GQLaNzuayGplgOOE3TiCLVa2NpFmbWKRKX3u2HflMml6BZmSZcmqBJsLPZTBSr3uVHB25RzfIanRiDilXvYavTPWoiG4/HEhDlb9unk2lwcGUb15ot+w7OPum+pK7YNX2CfSxTbsokm+PfDJFY7LqcSYp1b32Ivq8fuZBwQcHwMBiy3Ww2QrSEXkJDFUq1dzgchDSpLEmkXN4zn88lGxNTJJKgAUhwEgBst1tRvto32zSN+Ia5DKht2w45cmJAciXB8/xut4Nzz9mt+FkHSPG43oaP98dc0ZxM+H5njT6+USKXkHIH8RgRxvoc6ocmwFg/Y/eSMhXH7i/Vtz7X9CVNvz6rj/79FBQUDA+DIFuSJyOKgWfiYSJ/51wngxTVq95oAEBnM3gmnGiaBpvNBrPZDJ9//rkEUdEEzLW8OrKZJmStirlRgnPd9bMk4vl8LjsX6QxQOpkFB8Pj8SjBUCRxKnG2z0Ax3hfbJrHz2fF58XtsQO5rvswxl7JMjnpM9SdH5cbu1S9jmdN9K0Mugeo6rGt1/RaZhyYTseeSOldMywUFw8YgyFYTCMl1Op2Kj1Obekl4HNxpcqb/k+e1YtTLb/b7/TvrY/V+s/zMwZJ9ISlS8bIeAJ3sU3oLPfqfdcaqyWQi2aWoXgF0tvFjXXrd72KxkD5wEpIKukmZf0M+3BxTay4ZWYRmXZci5Vj5EOGFyqWeSexerTr9Y1ZfYhOX1PHUO7T6WVBQMAwMgmw1aA5u26e9aheLhZhWuWOOJiCSMDM0kbB0fmRGEgNPe9yS9ABIMBLX0gLP/tT1ei3Rx3rjAm3eZvASI525RpjKleRMJcwIZxL4bDaTiOW2bWWtL58B72c2m3WyTYVSOfqwBm+eyxm0rzFL63K5iquPbzXnmE+4fr9i5mGr/r6qMWUViJ2LTX50mb6WhIKCgk+DQZAtMzMxsYVeRuPc04YDADpJH+jLJBlpfyxNsnoNK9Wtc08Rz3VdC7myDwSJjCqXSplqm/7T+XyO8XiMw+GAzWYjJKzX+ZKo/axQWp3zs16jCzwrY5Iug7R2u534oWMJL65RvlZZXb4PLNKz2spR0bpcjHSvUeR+PakyqetShJ16B/6zS/WlEG1BwTAxCLL1BxqaiyeTCVarFaqqwps3b7BarXA4HFBVFZx73nKPAUSr1Ur8vlSOVMJ6KQ79oUzTqM3AJFYqSL0Vnr83LdMrklj1mlv2yffX+suW2A6DoqiQaU7XQWPcZIHl/bSQIfhkl6PYriEmfa1VT+x7yPecgxBR5bbp15Mq4/ezz2TAeu6h+7T85jn9KygoGCYGQbbn81nUGgcRktvDwwM2m02HgDTh0BTL7FJUrDTvHg4HCV4Cngcq5jzm+lsSKuukL5fXaL8ryzOIimtjdWIKAFInP3MzA/aNdWp1y/Y4oWBbJGNNtHx2NK/rqObQ39hn/Ww0OfQZ2C3SSxFSqAzbziGZHFWcQ56psn3K+c8ydl7XlXqGqfdRiLigYJgYBNmSQIDn9In7/V5yDDP4qW1bSW7B3ML0d9JkzOhiAOKrpWKlmqVypYql8mW+ZZptnXOdwCx+5z65Omcy1wHTf0tFq4OeaHZmIJjezQh4DuSiOZx9YZtcb0zfLQBZVqTrsZ5xH99haJD3v/fxaV5DEn0U+LUk9b6IywpgstpI9ful/SkoKBgWBkG2JJimaWS2fz6f8ebNG7x69UoI9fHxEQ8PD9jtdqJy27aVre30OlSah5nViYFWJEftA2VdJFCqVk38/ExS3e12EtREFUqyZgAUA5l0hDWXNtV1LSZwvVWf9i9T+e52OzFPa98v1xpvt1sAkH6GFF7MfOsrWf1efLOpPtf3Hfvt56rnHJLpM5EInc8xN+f6h/2yuaZki4BjFoeQWTvXBF9QUPDxMAiyPZ/PuL+/l8xLJELto6RCbJoGTdN0Nolv26esTVqVUkXyM824DIpiVihuOK+jgUnCDI6ichyPx6jrWjJG6QhkJta4u7uTKGmahrmelp8BCFmfz2dUVSWBX7vdTpYwjUYjIdq2fd6Kj4Fi2oxOc3ZOQE1MAYaUrBUo1MfUHAoayjH/xvrwEqWeqiN0X32UcYhoLfRR9Po++qjigoKCT4tBkC0ASbk4Ho9RVVVn0wGqXqq7zz77TPx52veqo5Op+haLhZAtBzwumdFrbIFnczYDng6HgxCtJn0SuF42RFMzTbyTyUTaZSpJve63qipsNpuOKZlmcB11XVWVqGOeG41G2G63ovi5WYJW6yFYiilGcJoc+/pkfdNqjpk7RV5W/SEy9+8jBr8eq81Y30PH+t5/H/R5VgUFBZ8WgyBbmnsZvUt16JwT1UnzLJM7MErXuec0iDrpBP9xPWzbPm9GQGKiKqUCretayI2+XE4AdBAUy3NQY5IKDq6r1UqOU4HqNIs0WVONMoMUALkvKm2thmnK5n0uFgsh9qqqZMcjHf0cIk0iRpYpAo6Vt4KDYiRwjTk5pur6mqpD9eT2p4+5Oafdl95HMSMXFAwPgyFbJoN4eHjAcrmUrFGPj49icqW/lb7RxWIhxMc9ZxlIpfexbZoGVVVJGse6rjsql32gz5YkSwVMlar3ryVRE7yGbQJPxMnrgOdBkL7Y1Wolmx5wffFut+uYsv2t9bhUiOXpw6WK11sV5pBpahAPEVzsmpcE/PQpm4LfvxyCyjUxx0jWui70vHII1O9/zvVF2RYUDA+DIFuaig+Hg6yjbZoG3/rWtzqZl2azGR4eHtC2rfhFf+M3fgM/+tGPcDgccHt72/H5kvz0elQOTszwpM3VfnASAFGL3MKP6lIPdFS1zAZFszPX2rI8A7gAdCKcuV6Y6pkBTzrlJE3NNC875zobHDj35L++ubnBZrORQKwYYmTUl5z8QT9GPPr6axRnnz7lgH2NBUvpOvv0W9cbsyyknlcIfftRUFDw6TAIsh2NRrLBQNu2z1G0kAAAIABJREFUeHh4wBdffCHLf5iYn3vC0lRc1/U7S1+0PxaAECfP6TW1TELBY7vdrrOBPDNbcRs/boencxpTlev0kMvlsrOG9nK5YLFYiOmaPldOIgCI+ZeKfTweY7/fY7/fixpnRinufMQBWkc5M2jrzZs30ic+ByDuk8xVd7652IcmrfepvkJ1+b7aFGFaBBXqW2pCEepbTp/98rpM6Hq/favf1xB2QUHBx8EgyJZmUT37X6/XuLm5keU+zFX8xRdfyEbv+/0ef/zHfyxEdjgcOhvO0wSrlS6XAZFw+Vf7SqmiSXR6He5yueyYlrUZmupVbyDP+wMgpM9+Mj0l+8D+si8kaipaRjRrQnbuaVehzWYj/eB9cMLhI2Wy1O8lpUz96y2CshAizRDBhJRhrH5fLfrtpEzh1n2G2ovVkTJjp8z5ue8qVragoODTYzBkOx6PsVwuhXjpP314eBDzKADZuo7Zotq2xd3dHb744gtJbMFlP3rAYw5jAKIMuR6X/169eiUKkyS43++FVGezGabTKWazWcdfzOjktm3FdK13+OH3zWYjfQGAm5sbSc7BLFBUg1S8VNYchHWmKU46mqaRzyzHDR2obmOEZcEi3xS59CXcUJlY/ZYqDSleq/9WO35/QnX7qr2vuvQJX5dPXVcItaDgm4lBkC0A8YnudjshvP1+j7u7O4noJQEtl0tsNhvM53NZJkRfLYlMJ/QnSHx6GRHrJeHS/DudTrHf71HXtQQ6cSMCbU7WUcPAc6AV184CzwTB7FU60pl5kmkmp4maUdjcS5ekyWMAZALAKG7nXGfZEdU8++Ajx7SpP6cI4SWmYb+elOLLMQVbplqfcHPUbehereMpxMzRqess9PWBFxQUfFwMgmw5kK9WK2w2G1GcDw8PYqZ9eHiQ4CUAnWhdmm6ZSIL7yrLs4XAQsyvJEoAQG8sx+IkmW+ecpFmkotWRw1ySxHSQbJ+R0zqqmaZj55wEOZHkqYJpNqdC3u/3kq2Ka2/ZVy5t0tmqaDbW90Ffb2ijAsvUyu9AfBlLSJnFSDKkKFPtxH4zfn9SCPXX/8zvsXvLbSN2LKeeVNux51lQUDAsDIJsAQhBcs3omzdvRH2SSBhYRBMvsz/xPKOFSXT0b1I90t+qM0ABTz5SrsHV6RwXi4WYlFkHgE72Ki4Bqusa+/0eNzc3cM6J6ZjldHn2czqdYr1eC5nTV8tdiUjS7AdVMdWzfnbAczDYYrHAer0Whdu2bWdPX0ITokUkFlHGApBify3ETMNWm9a1/r3p63MQMvP67cTM1P53695Tpner3lh/CtkWFAwTo3SRD4/RaITXr19jOp3i9va2sykBNyPY7/ey5na320naxu12K2tyAXQI9OHhQQjIOSfRvIwypl+XipQbHOgsTDRFkwi16uWmAIyYpl+ZAVokOQ6mOmCJSv6zzz7rpJOkn5X9onmcmybweTn3vLSI/aT65f1VVYXlcilbCRIhYkypSpaxTLG6Ph+hgKJcxBRorL7QdTHC9Qk2RpJWX/TEJVQm9rxifQtNeHQ7LFOItqBguBiEsqVJlQFITE1INci1sDSncqN2AEI4DKRarVaS+J8k69xTEBEDp3SOZOBpoHp8fMT9/f07wU3sH3MfcwLAPgKQbf2okHk/5/NZcinTBMylRvzO65jQgiZqvdECy9O/TOKmKZsDL4lC+5L5XGmi50QhhZgp1FKrIZIJ+UZf6nu0VHSonpBJ+xp/dAyWedrygWvkTCauKVtQUDAsDIJsOQCSSEhADBwCIKZdABKR+/j4iPV63SEW7sDTtq0k6NfrdTVh8TsAIWCacBnERIKkz5aD5s3NjSwTormbdXACwEGcKpdta9+rcw63t7fY7/edwCs9GeD1nAjwPumvpRpnG9qETd8uI6i326250TxwfVYii5xz/JehemIk1dcnapF3TtCVPhfqY8hcndvP1LPIMaHn1lVQUPBpMQiy5UBBs2lVVZ0sSnogoZrU/lKah6fTKR4eHmQ7PQDimyURAZDkGFyLSh8viYp+URI9SUNvFE9yo5lX94kkyHvS+9eSKPWyIUYV08dM9U7CpImZfSKJkng1MbO/VMi8Zz5DPi+an0MBTDF12Zcw/H6FlO41sNRkrG19Xc69hvpulckxUevPWnX79VtWBKv9HAVdUFDwaTEIsgWeE1twGQsAyRGs18zqjdWBp7WqJLPdbidBVno5DxWozpGs95XVOY+5+xCDmlarFdbrdWc7PdYdUjQ6YprneZ3OPKVVKombQVZ603mt+nn/fF7clGG5XHZM0Nx9SG/MMJ1O5Tkw49R+v3/nPViDtqVUfaKOkYOllnMDhd4HQmZkq51UX3LP5yh5/TlmkrZUfOieCgoKhoNBkC0Deu7u7sR8q83KNCFTNQIQRcqt9PR+t5vNBq9fvxY/LQcfltPLZUi6zjlsNhtst9vOmtXD4SDkpJffMC0jB1OSMAOi2BYnD9wZiIMi1bVO87her0X1MviKy3+0guXzappGlgvN53NR5NyZSO9+RB/wzc2NZMZiViy9FjdFqiHEFLCv5PxzKTKy2nhfJGz1KdRGbLIQ6o810bhGiabM631UfkFBwcfHIMiWqpZkAUAigzl4kICbpsGrV68APGWC4pIcEuBqtZIt+2azmahk55xsFl9VlWwewJzHNEFzXSwVLRNKjMdj7HY7IX+miGS/qYapgKmUSYKcOGiC/fLLL8W3zACszWYjx3TyC04SqIIZIMWgMapcqn62xedLPzif22QyERUdyqGs301KgcaIJkQOuUovdjyXpHJ8vqH+5tTjK8iU+rTaT/mKY9aBmDIvKCgYDgZDtpvNRghnPp/L8h6aZenz5B6uXBJEFXc+n2V7PW06pbmWS3tIhlSdHKz0HrA8t1wu5bOun8p4v9+Lv9fPVqWVuY4u1sRJPy1N41SjnABQCQPoJNAg2dKny2cxGo2w2WxksqFzPpNQ9cSEy5hiuMaHGHq/KYLpSxp9y1lmVstX6vczx8R9zbPR6j/UrnU/vtWgoKBg2BgM2a7Xa1wuFyE44CmQabPZdIKMGMREEnx8fMRms8Ht7W0nPzDwHMVLZXo8HmUpDk2z/n6yJNvpdCrqdblcChHq5Bl6T1mdwIL3pPsAPA2Keq0tlzT519C0rbNdaf8r8Oy7Bp6TWtCUzQkKs09p0mbQF0nXX3/bxxxq+T1DZtKUCTZFGH0J2yKiVJCTX5d/vq/ZN6ft2PPpawUoAVIFBcPEIMiWGZpInsx8xFzC9EPqgCKmRaTKZIpEmnU12VFJalVI5Uhlx0HK36mHf1erldTBqGC9F66//pX3RdO3Ni8DELJmliiaiBngRFWqFbLuG/tKpa0TYFBN0xzNutgnJgHhtVVVYb/fJwfplM/V+q6vtepMITUJ8L+H+mSZZC1CzjVB+9eGylokGHtmVv2xsoVoCwqGiUGQLfBEZgDE/0kFSbKlvxSAmG3phyVRcwnQarXqLMnRZmif/Eg6JEydbIK76axWq3eUklaQ2ly8XC5lJx/6RrXJWw+QPvnqtbl6PbDemg+AbDBA1UsTNNU38DyB4XlOAPSkgJMYnR8aCJtZ9b3HiCtUh39ek5mut6/vUl/rl9PtW4RrmZWv7UOoT5bPO3a/sWfrTyhS5FtQUDAMDIZsAXSie7fbLZxz4mclWTKTEpUgd7dpmkaIZr1ew7mnZTvcvi5EPAyM4nHmLV6v12KiZcSz3j9W+3812TJymebl0ehpg3v2lXvOMgMVdx8iUZLgnXOiNumbpeqliuVn3jPN1SRnkikjqzkIM3CMZnWa6DVy1FJKOYZ8kb6K88voOmIkkkMqMWLPVYSxMqH+perIqS9F9KGJQSHZgoLhYxBky8GCwUMAxLcKQIiU6lcTDDM+UT3S3KrNqFrF0tfJrfkAiD94v9+jaRq8fv0azrmOSiQZkmy5n61zTky/zjkcj0fZqIBEzQmCvoaZn7jelW1wMqBJVatR9otJM6hydbINHteKXe/dS7801yTP5/N3ckLHTKn6fKxMTPH5Zaw2cxW0pbpD/UvVZ92TVW+OErYmEqE+heq4xgddUFAwHAxiIwLgeRDRy1tILMvlEjc3NxKpTFMvFaTOAjWbzbBcLjuKl2tWSUb093IQOxwOYoIGIJu4k6R2u13HvHs8HiWgiz5SgvVpUy19yHpbPpIz74PnV6uVqGL6ohmEpVM58n55jKDvuqqqThYrmop5Peuu61qejf8+QiZQfg6RV6gsj1vnQr+BEKH4ylT3I6T4cmGRXl+lG0NKVfvl/Gv0tX65YkIuKPhmYBDKliAR1HWNxWIhqnU2mwm5kRhJHlqxaTMzg5/0TjwMMKJqpiol0XDdKQmMZmwGU7Fu4HndLgAxUbdtK7mZWYamYibX0FmoqL6ZmIKbzuv6NTFrcmEENNUu29XHNBEz+Eynu+R648ViIbmZtUk5RKgpxWchRwnHFJ9PsFb/dJlYmzG17Z/vS2RWu6l6YibnPtfGJjQFBQWfBoMgW5IefZBMRqF37yHpMKsTiVMrN+A5QQZVHwAx11Ixsqw2u9KsezgcUNe1mJpJqJoktWmaGxRohUvC0hvRk2jpe2Wwk1bmnCRQQZOk6Vvl/bFP7Lf21bJubT6mop3NZmKy5j1RQfMeUpsUWO/PIkG/TOp3EGozlxD5OaS0+xCtdV+5sEjzJcqzKNiCgm82BkG2bdtit9vJd5LE7e2tBDtxyQ0AvHr1CovFArvdTshvsVhIJiYAkk6RgVXA8zrXqqo60c0kNpqbqQB14BITYDjnZP2t3m0IQCeQiRmaqNYZnczgLn9Td731HfMzc9Kx2+2kP845IVMSNH2uXDu8Wq1k/18+O03uJBEm1nDOiXleB1pZJBZCjrK1yuVE36bMuhaZ5vh8Q+WuJdrQvcXq69tGrGzKh1xQUPDpMAifLVVZ2z5vBHA6nfCTn/ykQwY0BS8WCwBPyuz169f44osvpAw3c6/rWsiHiR24lpSfufE8AFlqRAXJhP0MKNKBTewHA5cIrUZJqnp5jTYL02RL8lssFtK+3mKP/SJI+ty5h0Fb3EKQ/dHrjoGn9Jd8LrwnKnNODlgX0CW5HB+j9T1HRfbxhfpm5VR9obpDPs+XkKDVF5/82Pa1/uVUuznPpqCg4NNgEMoWeN7hhybf29tbMRtTYXLrvLqu4dzz2lmqPAYXAZB0ihyA9MYFwHOuZfqBGZnbtm3Hr9k0jUQRM4EGMzvphBFc66tNwACC5l+2yYQSzNlMHzXL02xNkuc96IAo9oV+7LZtxRRNszU3saeVQOdn5jXMMR1aChSC5V+NmZP7moljSPlDLfLM9aH2VZt9TNM+Uj7snL5bCr2goGAYGAzZns/nTkJ/pjG8u7vDbDYTc+t8Pu/sV0vFRnMpfbNUoEyKwcGQ/l36bvlZL/MhMVKV0DTM5BqHw0G29mMglR4E9/s95vN5Z5kNiZZLdahw37x5AwASIc31vaxT7zikFTNJXatmPrvpdCrLpVgPA6G4DSGvJZlzEsN1yaGApBzkkEZuvb4CjBFqDrlafc0lSquPlvr377Wv7zhmSu9jDSgoKPj0GAzZ6t1t2vYpVzIJkKblpmnw2WefiWmVS1dYjoqOy1pIUjpoioqP/kySNPCcL3i73UoiDJ6n0qRPkyqQZmKagnV2Kk2IVJicAOi/evMBvY0gSV9nwiLYBuvU55i1SvuH+fx0tDWXBnGCwsAvPTmw0Ic8YmTRx7z8PpDy/RKpiYFPstaEQtd/LUHGlK9fVyHdgoJhYjBkS9Mtg3loUr65ucFms+lE2lIBkuT0XrEkUn/t6Ww2AwAsFgtRpHo3HJL0drsVQuIuQwxuqqoKs9lMEk/oyGadjIODMOuhCZomcRI269L91HvektT1Uh6aeP18zyR3vam9n7KRCl2nhdTPnaZ0TbYxwrHMyLlBSSnkmIZDx62+9UHKXOt/12SXq5RDhG5NYHLM9sWEXFAwXAwiQIoDPbewI4m9evVKyITkRXKken14eMDd3Z2kSaQ/lJ+ZtIGm0rZtZS0rAAlWYvQwSZzkrIOhGL3L9alcu3o6ncTMTdBUzPr0shpuQq8DoRj05RMg8y0zlaPv+9Um99lsJuqUPlgSMdtkMJpW3gyUCiW3AMKpAvW5VMDPtcQXKxcy34b6ZxF0Lq7x6Vpk2ae9VBS4T+iFaAsKho3BKFsqWi4/oYmU2+5xictqtRLTLtUaiZHrY5fLJdq27SzRmc1mnb1ktXkZeCZdBguRoGhuJlEynSPVN32k/MxIYUZPO+fEB6o3PaAi1psUAM/b69EcPRqN8PDw0NltSO/Py+9aVdJ3za0F/UQazHDF63l/tBJo+AFP1wQiWeijylLthsqHylnXpcjL8s3qe+2rPq37CZXPsSr491JQUDAcDELZkpC0aZRqlEQ5m83w6tUrMSNTGd7e3uKzzz4T/yPVG02qVLyMJB6NRmiaBpvNRvydu93una366KOlkqQ/dTweY7/fS795Xvtj6YP1cxHrZUT+elf6b6ksnXsKzFqv10KWNP/yPKOxtWrW5fgMORHQEdisk/dL9a1N7mzHf1eEVm2++dgvFyur4ROFJkGLRPoQq6/EdVnLDB6qK3bPfQO5YveRmoCElHNRuAUFw8MgyBaArP+keZO+UwCyzR0JZr/fy7Keuq5lSz3mBOZgR4Wqd+HhcZZjAgtNtlTOeps7mmWpCnUOZwCyplcHHun+a2VJlU3TNPuo29T1kaDZll6Ly/7xevYdeDYz8xj7qyOX2RbJfzqddlJO+oO5FZSj1Zdf1vdpptSwZa62oEnSJy+rL6HyVv+sNvXf0DmrL6n7yIX/XHPbKSgo+PhIkq1z7pedc/+Tc+5fOOf+uXPu77w9/rlz7n90zv0/b/9+9va4c8795865Hzvn/g/n3L+R0xGmYaQKI8mQaEi06/Uam80GX331FUajkahdnSCCmaR0ZK9Wbayfarqua9R1LceZYIJZnriUiATn775TVVXQT6qX6ZAMGejFMrp/OhqYvmG9vpaTh7quRcHrjQlontbmaqp7+mz1cicO1qxTJ7iwlF2ISAhfmeWQVkgZhpSdJslQ+5rwLZKPtWndU06/rev9ZxUi0xw17rdhqX9L4RcUFHx65CjbE4D/qG3bvwDgLwH4HefcXwDwuwD+qG3b7wP4o7ffAeCvAfj+238/BPD3Uw2cz2fc3d0JkZKgttstNpuNbAxPVUkC1GZdBipRyXHjdqpV7ker93J1zmG5XArZ6t2DSFj0rQKQOmezGeq67uRfZtQvFS3Jn0FUDOzSpM9sUwyC0lmkSJJU4HonJJ2QAuguEeKAq/24NGlrxU6y5YYEfDYkZm3ODiFEfH0G+ZR51PqcQ/qpui2SfGn/rT5Zat7/7JvarXYt5VxItqBguEgGSLVt+2cA/uzt57Vz7kcAfhHAbwL4y2+L/QMA/wTA3317/B+2TyPBP3XOvXbOfe9tPUFcLhd8/fXXHX8nA3y4jpYpFuu6lkFGL79hYJWv1pqmwWq1EjNs0zRCqsw9PBqNxCytNzjQploGW7VtK4qTRAg8L8VhH6hambWK5l7tY2XWKSarGI2ethOsqgpN02C73eLu7k76o03PWvHrHYCY4MIpPzj9tLwnbTJm8gsqaD5LZqbidSGEiM9SkBb6mGH71JvTnu7/hyYr1h9Tt6G+xSYCoX4Xwi0oGCZ6RSM7534FwL8O4H8F8F1FoP8SwHfffv5FAH+qLvvJ22NRsuU2djp3ME2+Ou0io49JGO6t35ZRtowEbtunTE43NzcdxUCy4nrY/X4v/loqPWZzogqmCZlKtK7rjrkbeDKD60FUf6f5VytLTYD7/V42NQCetvrj8iUd1AVACJETBhK67pOejPAZNU3TSaKh+8h7JIEzIE0/9xg0kXi/l875a+ATiu/fDRFOiJgtRZsyM1/T/1g7fScgsbpC51mmoKBgWMgmW+fcCsB/B+A/bNv2wRuMWudcr//hzrkf4snMjOVyCeecrF3lelo9sNBk+vr1a2w2m06ifm3q5YbxVGjMB6zTNuo8xpqgmFRCr7FlBiadvMK99Y3qfjJ/Mn2pWhGyHV0Hg6dIwLr/DNhi5PXxeJTcxtqMrp6lfNY5nH3fMcmb5bgOmQqYZneqb5K5RQ65JGQRZp/rfEKP1cXyMaL1n5smKL/uPhOOnHtKlY+RfeiZXNOPgoKCj4usaGTn3BRPRPtft2373789/DPn3Pfenv8egJ+/Pf5TAL+sLv+lt8c6aNv299q2/UHbtj/grjZcAkMVRpLiX+45SxOuv/E7Vd7j46PkMD4cDuLT1SRIAgYgxEll5y+f0UtydGpH9oORwxwAGQBFgqUPVvtUuSyHREg/r14fy6Aq7UfmdToxho4+1mZiTgzYX15PvyzbYFkdBJZSjG/fu/y1gnb8slb5wO/jnTZCiB1PXRsq38ckm6sg/ftNEaKeLIT6EbuvQrQFBcNETjSyA/BfAPhR27b/qTr1BwB+++3n3wbwj9Xxf9894S8BuI/5awkSHH2rVHRUaszrqyNzuWWc3h2obZ+TOtBsSuUGQDZjZ4ILEiPJTBO13rye5KZ9wwDEBKsVKtvzyZQkCUD6ycxNDMjSEcN66zuW1yZg3i+fCwdxKlP2y+8j+0UVS5+x9gmzDvb17W8h9jt553so8McqH6ovFkQUw/swo+a014eY+5TtW47E3OcZFRQUfFzkmJH/LQD/HoD/0zn3v7899h8D+HsAft8597cA/AmA33p77g8B/HUAPwawA/A3Uw0w6Ih+R19NtW2L29tb8c9SgZKItJJk9DGVKgcevTUd0y1SGVPRkGS02RWAmHRJlCRdEp1epsR/bJ+JJ/SWe35eY7YNQAKVSPQAhAyZR5mkDDybpDWJsx6CxMoUks45IdrL5YLtdivtMqEIlx/xHlKEa5lz+TdEAJYZNISUSu3jfw3V8z5Nsv6kImeyEroHy5wcqu8aMi8oKPh4yIlG/l8AWP97/0qgfAvgd/p0gmrs5uamE0mrCe/+/h7L5VKIVatCqmAdUUtT7GazwWKxwOFwwGKxEDLU62oZXFVVlWxBRyKiH1arw9PphN1u10kkQTIlcdMcrc3KrE+TujbzNk3Tyaes/dGHwwHL5VJIn/WxTd227w/m4FzXtURGc70wTemawPf7vXwODdx9FGqonO8L1eTRlyhSflVrAhDrSx/zc4zMLT9wrG+xZ+H3K3TvxWdbUDBMDCY3clVVkoz/dDrh4eFB9rGlL5Yk+MUXX2C1WgGA7MhDoiZZc+kKlRmVHZUwN23nxgVUyX5Urk4qQdJkBiid0J8mcL2GleRMaDM3+8hjHGRpziVRajO4Jm2awoHnZUdAN+CKz0MvjzqdTri5uUHTNBIFzeVH9IezrM7vbCGkskIKzA/qCZFarrqM1ZWqwz9vEV5IWeZcr49ZKtXqi//criHOQrQFBcPEINI1OudkU/hXr17h5uZG1qdy8GnbVvy2zDZFv2tVVVgul7Jc53A4AEAnkIr1kOi2223H3EsFqDM9adICnk3aenmNXsbDdI6+b1RvyM4EHVrlNk2D3W4nitRP90gTOQPIuDsRI42pbrTqZx/4j6ZovcSIn3VGKZriF4tFZ80todVUymzLMrlqMWYiTh3LMQ/nklesryGTeEyt+v0KETV/VyGS9usPlS8oKBg+BqFs27YVMtDBPiQvkqVWqIwWZtQy1836O/poQqLpFID4ZemPpGLVZVkH1SHrJnRuYx3gpHcX4kCpI4R1AoqmacSXyk3eWRfb5XXcAEEP4IxO1uZq7ZflPbVt2/Hr6r1xAXSsAkwVyf5QgYcSXKS+62PXmmh9srHMtv51Vj9eilRbMVNwTJWH6gx9ThF6QUHB8DAIsiVZ0bTJta56Bk+1d39/j9VqhdlsJmRL5cbrmPcYeB6gqM6YFGOz2QB4VipUsbpe5xzevHmDm5sbIWX6d3VuYpqRSX40X+v8w5r8qaK5Py2/s16ad+k3nc/nePPmTScLlCZxJukA0DFvM7qYZfmsGFSlJyZ8xryOAWuM6tZtXos+ZOCrRcvkGjv20v5ei5R6tyYR/vV9lHhRuwUFw8YgyJYEAkDSFTKAyE+4r3fbaZpGlgBRGXMzA5psSXhUw6vVSlI2MlCJBEpVSX/lZDKRlI/n8xm3t7dC5HrtrTZFM8rZJyjdB5rIdfIJPSFgggwmnNhut6iqSrJKkcxpvtbBZHrzA/aLbTMIS5uVdfYsmrg5IVgsFh2/rs7P7CM20F9zLmVStkg2poItXNv3UP0xP2yuSb2PWrfUbkFBwbAwCLIdjUaSgJ9mVSaiAIDVaoXlcilmZJIVA4kY4DOZTGTjApqmAYhC45Igbsyu94Cl31LvSbter3E6nSQHMv3FVVV1iJR73TKl4maz6WxSQLIDIJHTNM0ySEvndWZgEjdeWC6X0j4nGLyeQU0kW5qN+VxpWq/rWnJN663/9KSEaSI5+ZnP52JKpu9ZK2XLDOojh8j6qLKY6TpkYrbaDSnhHLO4BYtQUwTrt2v1J6f+om4LCoaJQZAtg4toTiZh0qRLU6eOmOU5Di5akWoCoZ+W/mAuGdK+UeA5CIqpHKl6m6aRTQgAdJbE6KU//KfX0ZKceS0jl7VvFnjeC5fqmEtzWDfTNdIE3jQNnHOoqkrqbdtWIrP5WW/UwHL8zAlKXdfY7XbSX51Y5Hw+i8qmiZuES/gkci1p5votLbWXIsqQH/UlxOrXGfqbehYxM3fo3izF+5J7KCgo+DgYBNnSJMw0jSQoDoxc58rN4Rm1rAOoqPhIpByEOFD5gUlci0sTqb/Uh8R5e3vbIX4ujaFS5TGqPx2kRAJnHwF0iFKvl2W/dFATSW25XGI8HuP169fYbrcds/DNzY2Yl/Wm8iRw+mD1mmWd0pFKfbvdyiSDpm4+H/aL5E5fcx/zr34Xoe+WuvOJZIuZAAAgAElEQVQ/W8SbUs8xH2msj9axUJuhe4jdc6we63zsORUUFAwXgyJb7vtKsy1VHpefkCQWiwVubm46kctN0whR8bPOmETCZRs8RnMs8BxsxF1/WO9isRBzLAOQ6DOlgqYpXK99JWFqv6ofuMVy9FOzjxxESdh6f1veA1Us+0qy533pzFcMwPIza/G+uacu/bL39/cysaGvmf3is9Xvz1KRGqHvls8xVkcOgVlthq6JmXn9crpMzPzL75Yi1fcSI+CQ6bigoOCbh0GQLQBJw0gz5eeff46mabBer2Vgv7m5wWeffYbXr18LAT48PIgS04qPQVAkbq0g2/Z5WzkSnN6vdrVadRQizb16vSmT9hPs+3Q6xXa7BQDxe/Icr3POYbfbAejmVmbmJprKScYARKXqRBNU21q1cr0uyVYvWeJzoG+ZCpqTEgZtcfIwm82wXC4BQMiW5K93ZUqpVYukYkozRjaha1Mm1hTRh9rR16dM1iHCtnyrob8hgrYmIaH+FSIuKBg2BkG2JLaqqjpKlX5TJupfLpf4/PPPxcQ5n89xe3sr5MP9VxnJDEBMrDpxA6OIaQ6mWmVeZS770Qn69SBHkzEJTCeH8KORd7tdZxcjBiAxqIr3pnf94URCm9BJoJxAkPjZDp8jJxc0q9NPvdvtOn5irbx5Tww600uSAHR2L9K5qbW6JUJKzyfH0HH/vE82lhnXUo0Wsenzflmr/7H78mH5hmNqPEWeOf0rCrigYNgYBNlOJhO8evUK6/Uao9FITJiXywXL5VIUIoOT9JZzVH+MsqW5lqRA3ylJk0Sso4WXy2XH3KuzQjEfs04DSSLSW+sxipmmVma70pHLbFuT/3a7lWhjbtfHiYQePPVOPtxqkGTHzFBMRqGX63DycHt7i8lkgv1+L/fGiYL2F/Me+E9vqEBQ+QLxzE1ESKGxjEVcKcKIqVz/vFW/7nuMpGIKMlVHyvQc6lPKpGxd699XQUHBcDCIdI1cH8uEFtx1huRTVZXkQtb+Qw4+JAluqde2LW5ubkQBMsBI+35JklR/AMS/ycQYmmSce1pixCxOJFceZ/tMzch7enh4wMPDg9TBPuv9b6mGWa+OktZ95b3paGDgORqZQWYkdFoMqIi1BYFt6SxXBMmRfeGGD3yeegcllgfCBBsjzfetwGIkEyPkVF9iCtQvF1LMKQL01X1u/f71BQUFw8UglC0Hdm021kt7SH4kDqo75u7luln6e7nRgDa5kkiZxIEKmAMofZFMm6jNrVSUJDqaY0manAAw+OlwOHSSV/jrd1mWUc80/QLoBEfxnhkVrNf26uOcBFBx+/vfMqiKz5M7FvEedX5lbh9IlX84HIRo6ZPWf/nc+B5T6BPc5KtG3UZMAYbOh67LNb3G/LW5KjTWTswsbZWNHStm5IKC4WEQZOsrOQAdNcbgHSa+0DmKufaUKtM5Jz5OLrOhL5QqlHXs9/tORC8ACVbRGatoLiaZ0nRN/7JeasQ+kUg5wNJ0THO1Vs86L7HehIDkzu/A85pkqnKd2EP3j2TISYFersTnTdW62+3kO5U9I5cZIEYzNSOyqfCJGBnmmostMkoRdIoodZlc32uorZyJghXYFGonNdHIabf4aAsKvhkYhBm5bVtRT845fPXVV3jz5o0QLSOMGbxDVaqjhDWR0kxa17VkSWI2JD/lI0lNqzQqaJIWyZRlqfiAZ0WszcBamTLlI4mKZl6W1Rsi8DwVJvtIwgz5Dqn0CS7j4bU6dzOJnf5jTcR6b2DeC9U0TfF1XUv2KqbItEgvZHL1P/tm0xARa+KK1eXXye8pU3aqb35/YtdrpZyDEPmGnkVsgmJNTgoKCoaFQSjbyWSC169fiwK9ubmRJS78x6AhLlvhmtaqqsTkTGXHZTY0LTNIabPZiJmZ9XAwZuIK+kgZzcs8xAzU0ktwdBQyAEkPqf3CWiE65yQYigk5qK51FqnNZtPZUIHqksdI0lSc9PlSZdO0raOu2TdOEnhvnByQ1Lnk5+bmBs49R3i3bYvFYiGbPTw+PuJ4PEYTXMRgmVhjpt2QEvUnIJr0ru2P35bVp9A9+P0KXRdTxH1QVG1BwTcHgyBbADLAc/AmwQLPqvFyuWCxWIiZk7sEcVceRhvTPLvdbrFer2XtKX3C2hzK7E70A1Pp6cT7VMo67SGJnYTHICnmSCahMkpaR1AzEIzER1+zDtoCIH2istebyFOVMnpYm5HpdyYRaxVe17VMEmazmWSkYoSz3pJP+7G19WG/33eyVekND3xYSs8irhTJxQgvpCz9a/1rQn3KIfmce/CfQU49qc+hevxzhYALCoaHQZAtfaYkQR1dS7LR5tH7+/tOVCyVqs4yRXPt5XLpKFqah+nnpSKczWYSRawTVqxWq84OOewXFSrNsyRpnXKS5E1olU4Cpu9T+3jZDutlMJRzrhPoxPWzwDMx0//K5BT8TGXM63QmLU3yVKx8RjoLFk3NzFHNiYsO6vLfa8rMnPPbsMzTOaTYp82Y+oy1lyLx2Dl/IpLq+zVtFBQUfHoMgmz9rehIHNzebr1eSwQs8xfrjd6ZVB+ArM8l2VKNUiVzLepyuRTyAZ4DsqgMaIKlinXOdfydJDBtviaxk8i0D5kkx2QdXDO83+9lnSsDp4Bn/52+Bx3NrCclOiUl1S4JVW8HqJf5+L5gfr9cLh1zPU3HeiclRovTvE0/uI8cgojhpcSSQ4K59afUsKWmU9fEJikhws/pW/HZFhQMD4MhW5qGqchIcvRTcocaliWx0DdKkBRvbm7w05/+VPy3VGYkDeZY1okoAAiBUFHqjeI1wQLo7LKjFS7NvtzQnX06nU6yww5NwtxGj/vXco0xyZIDp788CICYgHWfqPaprHXGKgZ20SpAfzL7R5M4zdA6bzTN1FwGxfdBQqfCBmxVmEMe78MPGTOnhnypMVJOKdzQOatOv18pkrRM6dfcd0FBwafFIMiWZmSqJEYdA0+mVya1oG+VSpjb4ZE89W4+d3d3nQArksr9/X0nCAt4IuI3b95guVzCOYe6rjt1UU1SeWrTNklYK7vFYiF9ulwu2O12svYWeBpESfTcoJ1+ZT6D1WolipX1k1RD2az4l2TIqGZOMFj3arWStgB0zMCsn/5zkvp6ve4k/OA70D5bvkd/sE8FA/lm4WuIIkaAVrlQYJVVlyZOi/isyUWMLFPErY+lJgV+vQUFBcPCIMiWplZuKsBUhCTD29tbWT5DP+VisUBd10JgTKtIE6pWaRyoqPaoErnJO1UvCdZP28ioXb0rkP5Mdb3b7YS86AMGIH5aPVFYr9fiL9VkRbPv3d2dpFikj5ekz/qZXEPvYkSlyQmM3h6QEwK95peTBSp0BnKxfp3Ag4QMPC854rIgBmHl+Gktou2j3qzvMcQIOWbyjvlqrfI5vmaLoENt5tznS832BQUFHw6DINvL5YKHhwfsdjtsNhvc3d2JWXmxWHTSA/IYfa5cisIIW+BpWcvr16/f2S8WeDKHPjw8iF+YGxyQlOgfpXJbLBZYr9edpBcAOn5S+lWXy6X4YJkxij5anTmK6hFAZ5MBTgi4NlZv6g6gQ9bMkMWlQQA6ClVHUpMw/dzIbFuTMvtBc3PbtuI732w20mf9/Jxz4uftq7pCZlUrIjdVlz7uE17KP2pdF4NFiLEJQeq4VadlUn4fZveCgoIPj0GQ7el0wp//+Z9js9mIMmV0MU1x9F8yGEpnYSIZ05Sqzae+H5jkpfd+3e/3ncT6jDxmEBaX75BcuL6XyhB4GiRPp5MQN9W5Xu5DU/Z4PMZ2uxX/LE3OTLtInyjVNa85Ho9i4tbt0sSrN4rnEik+J/qu+TxIvizP3YV03VTzvAemxuREhMepjvn82K8Q3geJpXyyvunVMv/GlKlVZw5p5yph67hVV2xSUlBQMGwMgmyPxyPu7u7QNI1sBTebzSTjE4N59vu9qDNNBIxUpolTK0i9/yvXszKBhPazsi69nlUHHmmfKIOHAHQyUtEUSxLjRgr+Bgasn9HKDGTi+lwqUpqO2Vf9mRm2uAxHLwkicfpmSW0C1sSsl1HpNbhcO6zX9TrnOhMcltfm7BQs8vTPs9+xY/xuEXDqnG7T6l/M/ByrK9TP1LWxcqH6C+EWFHwzMAiypWIlkWy3W9k8YDQaSRIFEgPXgXILu/v7+06CfCpXEjXJgwMT61gul501qFSZzGS1Xq+xWCwAdLNCtW2Lu7u7/5+9twmxZVnT896ov/VfVfvue1p9+7aEG3rgoY2EwHhiWnhiC0sDiW4wQgNBTw0eyHjkiSYayR4YicY9kDRpTIORMHgmCWPwxELggT1RC4HuldT37LOr1v9ataoqPaj9fPWtOBmRsWqfe3YeOT7YVFWuyMjIXJt8432/P93e3hoTZD2cD8NGWgWkfIQxzJNiGGwYnp6etNlsjjYbq9VK4/H4KCgKQAb4mRP/MMz9/v7efLT4wQFkNjCj0Uiz2UzSa2P41WqlwWBg0jPPgWfoyzwS0Mb3mQOANuk0xwzbxsTjSq4Xr62UQXrrkrU9i+66fmqOknO6ZOdq1ar1y3oBtpQ1PBwO2mw2enx81HK51O3trSRZ1O779+9NViVa9uPHj5J01BRgvV4b04QhE1jkax5TxhBApEUen7EuqjFJOtoEIHUTLCXJru83BDBW5vd+USRYgJ6NB0xyu92aL9U3tWdzgj+W3GN82D4gbDqdHhWl8Gk+lLskSG2321lAFg0g1uv1UZoQUjkvde/rbmOpUllBiS6facwU2+btkny7ZOjY2gC+xLebO16yGemSpUsl8GrVqvXDegG2MKUQggU/8TKEJWIXFxdaLpd6fn7WdDo1JohEvN1utdvtLJAK4AJ8MN+uzxd/oLzhdDo1+Rd2S0EMgHA2m1k+MAzb+4hh2EjjXJdoZlgwaUG0A0Rivr+/t8hpX13Lg6YkY6y+PR6yriSrc+yDqSgr6aOVkbJhqQAtOboYv7P+HPjlGFqOZeYArZTFxnO3ybunAu5bzsmtsW19OUm7bY7c869WrVo/rDdgSxqPZ3wA6tXVlUUlw07xkyLBNk1zFITUNI0Wi8URqK3XawMb358V/6TvkLNery2KebVaaTQaWSrOzc2NJB0BKnIusrD3wYYQjG361nfcO35P3z+WZ4F/mmAqn1YE6AKuXib3vXD5HMBm7WwaNpvNETNtmpeet4vFwupH+w0J3w/SOPcRFxj5nGCpnFSbGvddBGflQC3+O/XZqVJuDKalzD11frVq1fpnvQBbUmx8G7jHx0fNZjPd3NwYyw3hJVd0tVodvWAAK475tBbkY3qwPj09aTKZGEACfBTY90UwCHQikhdAgUEul0sLFIKdEsgFa5RkgAj75ifX4eVKh5048Mj3+G1jkgRsEZyFIsAzofMRMjTzAZykCSGBI+X733m2XNv33/XBUnE3JamsYEUXUJSw0lP9lznGWCIVp65zKuh1nZ9i/anzq1Wr1j/rDdgOh0MDr5ubGzXNS1u72Wym7XZroECnH4ru397eWiDRdrvVer22lw8S8nq9lqSjtnVIrIfDwZiqj2hG3vXn4D+dz+e6vr42MIT9+vZ3IQTzmQKC+HsBp4eHB2PNgK8HNdJrYJ2j0cgkal8xC4aKfxgQ9dfhWfjWfB4cn56erJIVzJyobmorhxBMfveBUp5Vd/laT2FhbeO7gNuDcgkwdTHjEraaW0vJfebGtD2DLkYds/9q1ap9eesF2CKhTiYTK9wAUC2XS6smtd/vjyJ3m6Y5KuwPGAAQRDZLOqr0RHEGjgFgsD+Cj/b7vRWWoKoSkcH4l32A0mq1+lYz+c1mc/SS9JWgACvuAdCCKQ+HQ/Pj+pKNsGv81QArQVCseTQaGYv2HZTo78u6YeIwX/y50mtxD19rGXCH+Us6Au74uy3xuaZAse38U5jcqf5eNjpvYc1tUnBuw1ByT6cw2cpuq1Xrr/UGbPHFwjphhr4/LfWE8eteXFxotVrp8vLSgqrwUcJwvSQMQMLykK/H47Fubm50d3dnYI88e39/b+vA7woASrKSj8jGlGFknQAQkcKHw0HX19cmMcMYycdF0iUSm40EQVLk1m42G2PaDw8PevfunYHyaDSyCGLfupCUHp/ixPW8VO+bKgDK0svLnA2JZ9UAsvfXYiVMKwcmbYw2NV+J1NzFrk8BwbZjfg1tvte3AOUpknFltdWq9dN6AbaSjjrHADqSTOIlwGcwGBgQega22Wysa44vcehb2MEoR6ORAQhsjSpSjJVem7DjEx0MBuZH9qUKieClrR/zeja43W7Nd4t/0zdq943sb25ujKl6trXb7Sw4ar/fWyN4rsU9Ub6SesWAqo+CZl5YK8+dZz8ajTSfz219AL73a8OwR6ORbXrwb0vtvsaSAJ8uaTdlHuDaJNVYfn6rrzMH4jmJuuT6JZuBHEuu7LZatX5ab8D2cDhotVodNSEAlPBpLhaLo+pFh8PB2rwBvkjAsFNyR/2L3pdvBCT8T8AKoEF2JdcV3yr5tgRbeUCRXtns5eWlMW0ihB8eHgyA2UBQpEJ6BT4PNrBzGCcvVvyovusPcrtPnUIOZ81eNoaJ459FDeDZcT1YMnP4lnt8L75uNGv3IHKKDzbHAmNAbZsnB4r+uyrxm7b9nrpuGwiWAGPKL9s2Z9e6q1Wr1h/rBdiSH+vTeWB+GCCAHxV/pY8G5qWPlEy6kCRLp/GpL/hnF4uFJFm/XNiwLy5Byg0skprDACjyq08jYj0euJGSeVEPh0NLpYHpbjYb2wwgmfNZ7MtFDvYlJn09ZR9VjUwPS/etA30LPx+g5dOSOA64c850OtV+v7fNUkpO9j/j42+xHJiVgHcpWz7l/NTmIcVUS6TvrjW9laFXq1bt+7NegK30yrqk13KB+E8lGaDyIgMgKHLhI3Q9EAJGFxcXFvEMCM7n86Mes0QU+6hkQAXg9nWFkZd9aUhYHUBNYBdF/LkH7o/AJcAU6ZnG84Cz9ALM0uvLlWAlSUcVnXhubFY435d1xMcMo8WPy3fBc+b+6UYEC+Z+uffhcKjxeGwVqJijy7qYZZvfM2VtIOQ/Kw006vqs7RqnMtLUmksBPLexqH7batX6Z2fdQ74f8/1TJRkzm0wm3ypP6KN5faDQdru1whb4QM/Pzy1lBh/mw8ODsdmzszNdX1+bhAvL3m631kMXvygBSjBv/MWAKr5gX5GJFBrYpGfBvvcsa4EF+44/PqCKCla+MhYbD98G8Pz8XMvl0roowchhyr5TEP5yALhpmqP1xkyZZwIYM/94PLbjXUDVBoT+WAmIMa4LyGI5Oz7PH4vP7TIvSTNHDHax7zhlJYFk8drbrllZbrVq/bNegK2XYKnl62sRPz8/az6f68OHDzocDhqPx7q+vja/J6yTsorxuavVSuv12oAY9sULKmaOvvWdL1bhW+adnZ1pOp0aCAEybAyQeMfjsc17fX2tr776ypjgaDTS7e2tlXokz5V6zb4SFWUbkZl9CUWCowBc3/SdFzFgKL2qCBS7iOViGC/XmEwmBvLj8diUBTYZvq6z9O1yg21A2gaEKYk2BsX4/06btY1NBR+1gXE8Tw5M4znarh+DY2ptbdctkcYrwFar1m/rjYxMcA5SZwiv6TDIljDN0Wh0JKEyHrAhUIggHgAQhupfuvhSkXsBU47jCyUYarPZHNVHRmaFqfqqUE3TaLlcmj+a+6Q0pQ9ymkwmtp4PHz5YrWOfUsM5sGukcj5jA8HLl+vC2mmc4HN0UQqkl00KHYdgxKgEvp+w32D4qGRJR20L+V5ie6vP0QNlThJum68NtFIAl7q2X0PJWlNrKXkm8fVO8elWq1atf9YLsIURAggwXEkWcOPLEAJufgzSrffzMvdwODR5lNxaX0QCOdWDlyRjqP5Fh9/Sd+4hGAtgJRcVIJJeK1JRPAPmiaTL/ICf32hwrzB1Nh0+B9bXOgbEp9OpNpuNrdufg3+balysjfu/urrSZrM5KivpS0UiHxPQxrP3zyu2FFC0gWfbOTmptCtwqQS02oA0x4S7rIvBxhsH/9Nf5y3XrlatWr+sFzIyQICvkPZ16/XaAAfDTwsAj8djCyaC9SGbAlxx83MYKQDC9X2BCc/+mKNpjqOJGSvJikP4HrREN/uiED4dZ7vdmlTs83NDCJYeRDQzwVi+mQDMGVbP/P5+4txkgq8YR7CX75zEtRjDM/OBYLHf1peMTDG/z/G78ntKaj31mqcczwFcl7Qd+6NjMG3bQJzi767BUNWq/TCsF8xWekm78T5DD7JN81LQgTQTLwnT9o6gJwAbNobsS2APgCS9vtRgktPpVA8PD1acgkpJ+CYB1sPhoPl8btdGvn737p1JsIDPYDCw9bM2Sbq/v7f78/WFiQ726TVe5uV3NhTcTwjhSFper9dHubdcF4ClnjOMloAsD5b+J5sBH6nMpsM3S2CenKUY5qkSaRsLTF0nHhMD3qlr8HJ9ag0p8Ez9XeKfbVt/tWrV+m+9AVvf3Hy5XBpLpGjFdrs9YprSS3UoQGQ8Hpus60GCBgVIqAAUzJjzYZdUgvKlEQFqgAZA9JWpmqbR9fW1rq+vtVgs9M0335jMejgcdHt7a52CttutmqYxOZkmCz61iXUNBgPr2+vBmPunkTu+WfKNPTNerVYaDAa6ubmxjYwHaZ6FL4iBJIz8jkrgi1awGYC5jcdjy7n1agQWA1TMVEsAr01ibQu+6pojd90S8C2VduP1xtdok8jbpPMqJVer9sO2XoCtl3P3+72BrZcnJR294NfrtQ6Hg3a7nWazmb755htjVB64JR3lk8LIYKuwNq5DJLTv4fr+/XuTWkejkcm2nE/uKcfJN6U4BsDD7wAU9wLgAb4hvFRq8jnDjIWJ0lCAVCVSpwA+D8qs0QegxT5rHxjmG9CTH8wGB+ncF9KAZftCHm0MtxQwcoB36jFvbQDftr5TgK2LYcZsOuWbTV3zFGCtwVPVqvXXegG2nmXxdwjByjQS1OR7vK5WK5M8AUZSe0ajkWazmbHQ3W6nEIJFEwNipL9st1sdDgdNJhPz1QIu5+fnms/nur29VQjhqFIV7E969Rczn78Pqkr5lytpRL4KFowSmRefr5eBkYl9pLAPSgJUyY31pSXx1cJUAXGeDdeVZG0NYfyecTdNY+sGcH39aN+IvvTl3+W37ZqrhN3G55cEZZWsNzdv27iYlbcBdtfaKuOtVu2HZb0AW17+1EemipIHM2oI+3Z0vvE5bE56bYpOWUVAgVrKSMO8uHzQEvMQuARrW61WR+lHpL74usSwPUnGhGGT6/XaxvCypBWejyRmswAAk2bk+936v3kGBIvFfWulF58w8rkkY6b4mlkzoMl9s1ZvPHfkZDYu/vPYJx5/112yLH/nJOEUY4zBLScJl7DRNstdo+T8tmvFgU4lwFsyplq1av2wXoEtQVC/+qu/al148N1OJhNjVQQbweJgjfh3AeuzszPNZjOTZn3FJMDEt84jSIt8W8CTHFLAfzQaaTQaGTPFN0pksM8V9rWOAWA2AYAZYDUej02aHo/HFlXsmwawSWA+1gSAEiQ1Ho9tA0EBDl9rmrnw7yK5swHwqT9eefCNDQB1JGM2Hm0BUm8BgxLmGI/PgVYJQ05ZiS+4bX2nrD11rTYgz20+qlWr1j/rBdhKspc4+agADy/vEF6btcMsfRF8JFMihmFugCqMlWpISNK09fOdfSRZvWWCfQAmCkMgpQJy8/lc+/3eApbomAPDlnTEwh8fHzWdTiXpaC7fAhCg5BiyOAzXRyZzTaKjYasEgTEePzQS9Ha7NRD1wV6+a5AvAwkQk36Ej5fxvqEB53jASEmgfmwXoOWApgt0UiyXY36NXWPfwoxLfcBt1yoJ3ErNUa1atS9rvQBb/Jr4V6+urqwZOgCAtEmRBnyKkrRer62aEYFGkqxeMuwLkPRBTbBE/KjSK4D4jjlnZ2dar9dW8hDgQrpmQ7Ber81HylopaXh2dqbFYqHHx0erELVer23zwFhffMIDaZzXut/vNRgMrOyibxDP/YcQjLVyv77PrWfNPBd85RcXF0c5zbBmJHYfccx35BsilErGjI0/j8/vApjPYZy5daXYcc6vGs9Xyqhzzy5mu6c832rVqn1Z6w3YUt/YRwn7lJ0QgpbLpbEnom9J1QHA+NwHEfmUISROnyPqmaX0yga9RIov9OnpSavV6ghEYY285GhQAMiRfgRo+nxW5HF8oHyGDA4wYoCrvw9YsO8e5CV2X5gDHy8MFLmYdbK5GI/HR1K+9Fo8Akbt+/sijcfM9RTZtisgqAuIcue2jUnNGTPD+PzUz9xaPgcAU8w9BnOOVWZbrVr/rBcVpGBrdOC5ubnR7e2tbm5ujlrl8SKJ5VhfNtCDny81KL0wO1KGPNj6CGQP1FzTS6MAO40N/Esa4JZei04Mh8Ojz2lM4AGefFY2G0i0/E30M00AfAcgX91Kem06j5/a126muYFv28d1JNk5PEPfN5fgKb4DvwHhGfl2hf67bbOcb5XPu0CmC1Q8GOYka8a0sWvOfYv8m/o8JRWfMmfb88ux9mrVqn1Z6wWzlWRlAvk3Go2sXCP+XC/9AgoUYcAv2TSvJR9hv4+PjxZwJB2/WL1/EUACaJBrfcMDgFl67RZEXqkHMHy/l5eXR/12Q3gN1IJJ+pxU2DXjiXieTCb2jDxzBYwBPl9oA7Bl00EDBO7fl3UE/D2D5zmziYj/xcpB3DLQWw482+Ti+Hgpm207r23sqaw7dY22IKa2a7ZJ0fE6UjL35/iPq1Wr1g/rBdgCnICP722LxOyDdgAe6vp69gtbROJFWuZ3AAJW6IGDdnaeQSNjw+ZCCJrP57q5uTnyxUoyedazSpoU+H66w+FQ0+nUNgusz+enwrrZfLAGmrQT2UxO72QysefIM/XpPh58AXfk7hCCydcw4fg4z8OzX3+sTXmIv1mASecAACAASURBVOPc99/2dxvTjK0L2HLnpsZ1gfipvt82sMzJ7SWsPsX0q4xcrVo/rRdg+/T0pN1uZ4E5pN4ATkTiDgYDawEnyX4yBy8apGFSXQAHUmAI7KGoA/Lycrk0WVp6zUe9vb21YhUUevCgBpv0eb0wbIpJeB8rAPXu3TtJL0A4Go10eXmpzWZjLPz8/PxbDBvAJzKaDYhn3wRMEcBFUQ0fJObXQ6EPCmv4co7UiWa8zxVGPuaeYrUgByBdftQccOSAJnWtNlBMraHtvBhgT2GYqfFtbPdzGGplt9Wq9dd6AbYwPFJyAFyCfZB1OQY44uOF8QEAsEGKWABS0kvkspdJqbkcQrDoZRjpw8ODRqOR7u/vj9gxvksAfDQaabfbaTKZ2AYB/zHskgpUq9XKxh8OB71//97Y4PPzs2azmbFQIpNh8CEEk8yRzzk2mUyMkcadesgV9psRlAIiwOPKTx5wYcFEZXsZP4RggWqAry8ViaXk0pQcW+p/LJFs/XX8OanP2+aJ7a0gXDJnbmNQep1q1ar1y3oBthcXF/rqq6+O8kaRLgEL35Tdy68AI6CJDO2lYkBDkqbTqdbr9VF3G3yt5+fnur6+NpnVN53nJwUjqEuM+Wty3Oepnp2d6Vd/9Ve12Wy02+3MTwrzBbiRZCeTyRHDJb3J+1d9MJX3ubIpAPgoo4g/FbDlGSDbs0HgWaEW0AoQ8PaBYzBm8ovphLRarY6+4zZQ4nf/Mx4bW5f/su14StKOfcOlUq7/vASgcwCY892mnlnq75LrVatW7ctYL8AW5up9tby07+/vjYH6sob4QWGUlCqEST4+PhrYEiAEOABEMDoAiOpQFKNALobFeQbqG6Vzvi/M72VdGDayNX5g8nC5Dp/5zQEgDBDzGSk/sG/fTIHNB/Wb8UeTP3x5eWkAynPxPml/fR/M5TcXALmko2fo6y2fyhpTbI3xXUFJKcDKWYp1dsnbJbJvDjzb7qGL1Zf8Xf211ar103oBtrx4ABpkSMoI8jtsCrnTA5oke8n71nk+dzWuHUznHgCVEofksgKAMG4PlgQxAcRUYqLClM/pDeGlyAXrbZrGAN+zSjr5eKna+7B9oBIbD9rvsQEYDofG3Ln+8/Ozycxx3nDbnPF348GYilYe3L2P2z8v/912ffepv3NglAPxLkk2tRnI+V3jOVLnpgA5JW+n5i9h9/F6KqutVq2f1huwxR+73++13W61XC6N7SId+5KOpLHQDm+9XhugEJEcQrDKUrBDonF9SozPc12v15JkkcDSca4lTNFXX8LHCVAhExPdS3EO2Dn1iKfTqUUTsz5KPvJcuD4vWK7jma7vyYv/lmfqK3ARmQ0j9Y3qkYM9Q2WT48HVb3oAXv+C93nNJd97ClhLJOI2OdqPScnJKYm2TRaOLQfiJQw5dx+5Z1F67eq3rVatn9YbsN1sNvYPNkVkLMzT19/1KSgXFxfma5VkwTwETcF48asSncs1mPvs7MzKHhJgxU+Y52azsZfZzc2NlU2kKQCABiBROpLzAWufowvTpF4yAUmsFRkXRkxgEyBJJLf305KvK8lqJgP6AC5dlNiQeKBlvQAwQM9GA6ZLl6DD4aDFYmHneTmzhC2WSMT+nNy4rnPb5mn7P/ldgFaKuedYb2x+U5Hy01arVq3f1huwJbrYF8nHj0qwzfn5uYGdD2IiUhmGOpvNjPk+PDyYfEwTdLr7SC9pRQAPQE7tXwAORuvLJIYQrJuPdFw2kfVRKxggl2TpNQQ2eeY9nU5NOvbBYp5Z8xz4CTMPIRgb3263Nq8kY/FUrsKvzPMIIVg0MtcDaFmD9FpLmcAp8nwBYa7JeViXfzMHOm0+yFK/bBtIpcD6cwG3VH5OSdep8W3H22RrjueeR7Vq1b6c9QJskWO9lAooUGgCdrZcLnV1dWVt9mC/vn0c0cI0ISDdR5IB0Gg0OpKc9/u9BVQBFgA4zNZXm4JVUrgf5gxjpogFUjcvRlKLttutxuPxEXv3RTr8yxVJnEbxMMumaYwpS6/5xL7aFJuS4XB4tBb8tTwXfMM+wpl0HjYAAC3jPYP19+0jvVOMtARgY/DoYoVtINMmObdds81yY7o2D/EcJb7oEpA8BdCrVavWH+sF2HrmJB2XUCTYCZ+u9xN6GdW/VDlGwQpAgeAm72eEpcWdd/yaKFbBC5MIaB9MxHWpwLRarQwcJdn6AW9JRxI50i7+XEkWvMUziZsjAK4+T5jj3DNAjTQOqwZoYd6wXF960ufMxkUtkN8lGQv2NZ1T33OpbOr/X+TGpI6lQD3nx+2aP/d5lx81tlRw1ykBZb9M+btatWrfrfUGbKmchI8VkNntdsaYSAMCOCQdBUIBXAT3SDrqDUu0rK/yBHvG9wqDBcRWq9VRb1dSaihAwdoAWxgt6Tz4fankxNo8eONf5WVLNDJA7YtNAHSkSN3c3FgkMn5Xzt1sNkfgCTv17Qlhq8x9OByOylYC6LG0jVzs2+z5++LvFJvj8/h4CkxKfasx+40tdTw1T9vfbWvJgWAJG80FaJVsUkoDvKpVq/ZlrBdgK8nYGKAJgFFQQnopz3h5eWnFHnxO7XQ6tXNgd/gy46IUT09PWi6XR0X/AQ3kWcDl4uJC6/XaqjYBSLvdznJ9/fqJOIZBPz8/a7VaGciyeWAOX9ACORwfMoA/GAy0WCyMqQP+yNc+B5gXLoUmYMJUf/JpSz4FiGeMZB7n31JE5P7+XpvNxjYVsN/VamWFNrwyUfK9f864Ep9o6pw4Orn0+m0MNAWebQy77djnWgXZatX6bb0BW1/Hl+ISvLSJCKbDDSwUvyRgSnEHJFB/rmfA+HtpVH91daXRaKT5fG7nS8eBSJIMDJGzCZhqmubonOVyaUAI+EuvvmnWTu1hNg5N01iTAXzYsGIf9ctL2vfBDSFYY3svNUuvG4GLiwstFgvzGwPUPhjMty9kA0DgVNM0xoq975aoayKX/QYEa2OxpwBESu5NjT0FdFOfvfXc1Oe5oKwSWT01X9vxatWq9ct6A7bSS2ATIDAYDCzyGH8lL3F8m1SZIsKY/FQqQEmydBdfxvHi4sJyUQEUGqYTRQxgzWYzhRA0nU6NQfvayoAtQMz8FKXwsvP9/f23AohIvyGCer1eW01k3xGIiGWezXg8NqbNRgLGS+CY9OoX5nk2TWNg6X3QlIJkI+JTfqSXF/hyubSgM74L6bVUpfSaZrRYLOzzHFCeAoylINIGYiVMM3XNt4Bdyl9ccn6pvXUjUK1ate/fegO2AMzZ2ZmB7vX19VFAD2NoDUcEMgwYYOIlFuepwmwBMub1UcS8FPnnc1xvb281Go1MziWVhrrMpOHc3NzYGEnGook8ll6bBQDqREOTyuQ7+SBhc6+sDfbKveBvxfw4nguR3gSJwVyJhEYVADwBiP1+r9VqZc8J6Zk52iKG/fkp+2UBQ0qqPYVVfpdgmAqI6rLcJiF3TrVq1fplvQBbX3+YlnKwMcDINxXY7/f24oFl0QIPMPRF9kMIR2kpzO8Zl49K9oUoQghW6IJAJemFhcNepVfpFinYM5ntdntUKpF7ZQMwm81sIwGw8vnZ2Zn5dmGwMFc2A4AndZ8J0JJeJXDWEJ/DevjpA74AYIpseH8zbJugK0A8DtLJAUOX3zM3tsvamGXOTgHDVDBSjsG3AWUJgMbrLzm/Mttq1fpnvQBbmB+y6G630+3trb30kYAxZEvvi724uDAJdDgcGmBS4AG5FECnCQEgSZASL6qrqyvNZjM9Pj5qs9kYSAM0gKMHuPF4bOUekaLpgAOQwQZ9IQtAPM575eVNXi7gSFQw7JNgJZgsBT34DD8vKTr4YPFxs4Hx9ZSZi+CszWZjGxofYAVbx5/syz6WSLClIHqqr7b0HM7LrckzRUD2FPBPgXObxPw5G4pq1ar113oBtoAlYOv9oUi1kiwXlXZupKhILy805FBfgYoXP0xssVgYwHm/o+8JSxAUkcBN09g1JRnYkaJD3eHVamWslOuxYZjP5xZEBVsGZP2mAUbqX+qPj4/mK6VxAaUh8dVuNhsrtUjAk2/lx7V9zWbG7nY7A0nAl6YGfE6XJB8Y5QOi/Plx15/Ud+5/ekv5Uz0Y5s6Nr9EFSF1glWKqbettY7slMnDpWks2FFVGrlatf9YLsJVeSwrCOOfzub3sYZLInbzgYaaAgy/OH8JrBC4vOaRgWPBsNrPr++4/3udLgBWSNPWWyfP1ObsEacEAydv1BSIuLy91c3Ojw+Gg6+trAy8KcXhZfDgc2v1MJhOF8NJ8no0FAIp0zX2MRiPt93sD1u12a12JPMuCYbMxYWPgn8N+v9dmsznqaQuY4+ONWbjvZtRmMRjkJN82cPXHcvOkZNu2v0sk5zYgLAHaeO25uUuBP8W+S+aoVq3a92+9AFskR6KPYYXn5+dWehH59vb21vJtJdlLHfkT1ofcSr9XSSYtI0NTuD9OWYlLRgJugDpFI6j2hPzqo4V9R6AQXtJyvC8XFs16yANGpvVddsiFJbiLtcJkuTeil33Kj29350GWOXyLP9aCT/hwOOj+/t78tSEE+468jAz4Iimfn5/r137t1/RHf/RHR7J0DnBK2F/XHDF4xsf8uHiOLl9oDtxSc+eANb7uqTJ5SpKuVq1aP60XYOtb35HmA3gAnEjNkqzYPhIyLA//KS8zfLGAAUUdSBUCKAFImBsMz6+PNbIuX0bRF+z355MzSwEM36xAkgEmbJaUHJiyJJO0adGHvA3D9EU/2BhwX741HpWkYlndbxIAa1js3d2dlsulNpuNpVP5kox+E8CcXhrvArwUsOaYbtsc/rz49zZ/bG6e+Lox4+xioCWgF6+t7V7856WAXP231ar11zrBNoQwlPS/Sxp8Gv+HTdP8dyGE35D0B5LeS/qnkv5K0zQPIYSBpL8n6U9L+kbSbzdN8y9z14CBer/tdrvVZDI5ilSWZHKuL4eIFAr7lGQNBjx4AUwhBGOE/A7o+IboTdMYmABe0nFNY9aPv5j74MVHJSd+h6HDtpGOPZuWZBHTHIexwyi5XzYZND3w8/gykFTO4nxKMHrARw7e7/f6+uuvrVSll8RRIXyQFAyX5+yfVWwxWHWBZc5K/Jwlx0uuWyrzMjY3V+66pZsMPn9LYFW1atW+fythtntJv9U0zSqEcCnp/wgh/G+S/mtJf6tpmj8IIfwdSX9N0t/+9POuaZrfDCH8jqS/Kem3uy5Cio7vxerrCHvQ8x1oyC2dzWaWoyu9pvN4tudrLtN6zwMF5RcZj0xLdSQvGUsySZmgIAAeloyflPZ8+HV9lStY58ePH61qFIUwYNq8gCnVCEter9darVYWwUypR9+1yAdl+ZKQ+K15jrDx/X6v5XJpObXr9foouMrPz32Q68s9+lxfrt32e4nlpNzcnG3BVKXMr0TmbQO5FAvuuk4bg267l3hN/vcaFFWtWr/trGtA82KrT39efvrXSPotSX/46fjflfQXP/3+Fz79rU+f/7nQ8YYLIRyVYgwhGKv1RSooqziZTHR7e6vb21vNZjN99dVXBtAwXs++ALxP92PpQHzuc3q9/7VpGgMcAAQAxJfMumCS+IV94wPfyg9gHo/HlhPcfApwoj0elbB8oY2PHz+aDI5/dTqdWioTa9ntdrq/v9d8PreKT7vd7gg0ecZsPna7ncnCnOs7FyE/U2CEZ+h92tPpVJPJxApyxICb+f+V/TwFPrn54s9P8YueOs7/P0vNk1pvzPDjcf7/b9s8sURe2W21av21Ip9tCOFcL1Lxb0r6HyX9kaT7pmnQCn8m6aeffv+ppH8lSU3TPIYQ5nqRmj+k5vc+VIpFUCnq8vJS19fXR3WKGQ9AAwiwNFgoMjABVU3TGBj4l5iXlD1Y04QAmXs4HFqDdyRbfM1sDDDYHilDPh2Ico4wXxgtkdiAGLI2a5nP55rNZjo/P9dkMtFmszmS1DebjQEj90AxC4CYgCiYv8+PXSwWWi6XFhAFUyVSHLAlV5fAKh/4xfV5/l3M8lRfbjyu5f+qfR5ftyTwKbWuts9za/Vzl7LqrmeT+ruCbLVq/bcisG2a5knSfxBCuJX0v0j69z/3wiGE35X0u5L0/v17hRC+lX7jI38JTsIfCCvzvtbn52fN53OroATYxmk0zI+PEllYkvXOxW+M7ApY+/SXGECRrX1lJXy0MOtPz9MKWuBrbZqXcpA0CfBydtM0Njd9cX3ZRTYDBDB5adjnv/K8eJ48DzoT0dEH/6wvy8g9Iq9zH1T28vnO5OR++p7j/0tZcIgB5BSATo1JgV18LLe2lLTcJleXrvMtMnNubAXdatX6aydFIzdNcx9C+MeS/iNJtyGEi0/s9tcl/fzTsJ9L+pOSfhZCuJB0o5dAqXiu35P0e5L0G7/xGw3+RIxI27OzM81mM3upk7ID4yKFZrFYGLAB3Ph0n5+ftV6vj4KjPAgSPOTTgJbLpYE4zQHYAHgfKuDPWgEbfkqvJRN9JSfpNXoYydUHWjGOzQEbD8/gYaTX19cmR6/X66PPKUTBuiWZDB1L5cjOgCuM2Je65IXuo5p3u51tUgD8tgCpt4DBKWzWWwlDLmXOOaDOgboHy7ey59T1/fwlc1WrVu3LWkk08leSDp+AdiTpP9VL0NM/lvSX9BKR/Fcl/YNPp/zDT3//n58+/0dNh2MOXySAdnt7e9S+zhe18JHBFOv3+aKAHkFPyMiUcqR0oi8BCQDTk5XoXiKGPROmGbyvLwwgxelAgDXpNB6wPGP0PmtYLQFd3CvgRcS2T2XygUseEH1AF8zUy73c64cPH0w+BsBZ1+FwsP61KAXcF5sHosJ95HLqKy9lYG1gGYNPGyCm/JefA0anAvxbr/kWSbuCbLVqPwwrYbY/kfR3P/ltzyT9z03T/K8hhP9H0h+EEP6GpH8m6fc/jf99SX8/hPDPJX2U9DslC4G58TIfj8cGQFRr8mwRfyAyMUDsg3b2+70+fPhw1Kv17u5OTfNSVIJ2ebSWoywi5vvrIrfyN+CDJOt9zLw0AVzuz6fJ0APWy92+xCTND3wtZOm16w/N41EE8L96RunZKffvo6kfHx/1s5/9THd3d0fPN5bL2fRwv8zrNxu+qxFRzswppaXXLsbYxu7amGkJW42v0XYsF2zU5ZvNWYopt91XiVXZuFq1H5Z1gm3TNP+3pP+w5fi/kPRnW47vJP3lUxZBwBOsDYZLgQtYJQwyhKDRaGRlDWFagA+NA3z0buxbA6QBW9juaDQywPUdeog0bmvZx7o8K/V1lwFA5GQY7Hq9PlqH9FrukA2A90n7nGNfxpL6zIz1BT64vq+kxTXu7u40n8/NT8s1PLv99J3qcDgcNYDw7Bd5/3A4aLvdHpVpzDG1En8l494KRCW+1LY1lfiKT1lH6ty3AmYF2mrVfljWiwpSAJ3vSyvJgM2DHjmmPrcVoKGIBaDgC/cjiT4/P2s6nZq0CrAD6N4/+fz8bAybnFvYHJWoYJY+WAofsGeE+Hu91EzOre9CxJrw3/rUp7gU43Q6PWKh5OYiQSOd+3UAirvd7lvRy35T4AEdxhpCsAhq/iYa++HhwaRoqbywQ9v/BX52+U2xlHxbuoYSxtoWrNTGgtv8tDl5uTLUatX+/2G9AVtYGi8rApdgibA9SVYS0BdXIE+2aRqTo0lB8ZWbAGdehj74CUCbzWbabrdar9fabDYGgkjTgAzFNiRZBC7gxGZAeo0+BqgJUPK+WsbFgUm+/V4M4p4RsyZ/jEIhyLz4aB8eHrRYLLRYLI6kYXy+NBjwfl02Ir7SFKD78PBgDBlQz/lXveXAphQkU4Do5+haxynXyLHV3LEcW/6uQLeCd7Vq/bRegK2ko/6wHsRixgnbY5wPOKLAg/dzIkX7PFjfiGC/3xvg4pdFfiay1kuovoG8Z5pUskLq5cXOP64bwmteLSCHVM51qBQVd0LiJer9wtwbmxFKUnqfqZfpYb5sCJDImY+AKPJvPXNmsyC9MrftdqvFYqH1em2bhFP8kaXAUAJsKXbrv482Vtnlvz1lvbH8Hc/ZNj7HglPjU2Mr0Far1k/rrCD1fRkMCv8fLyBfpIJoWR/kAzACGjBigA0WBnukIbwv9n93d3cUqATDpOkAx2F2MO7Yj0oVKKRZ/o3HY00mE5PJYcowQe7V5xjjH/Z5xR5Evb/Yl6H0TDmEF9/2bDbTZDKxnGXPvLme94/DvL0fWdJRVDTrXy6XRw0KeKYedOJNR9vn8Tg/vu1Y23neusbGPnw/xh+P5+2am/PjOWLgbVMASi23/lPmqVat2vdnvWC2AMhyubRyjPgfedHjy+R3z1Z56fg6wICGb41HhC/gQIlDAB4J1hejQFLmb6KOKfBA+tDl5aWlC/les9Rf9oU3eFFS0clHNuN75jjlH0N4LQvJ/QB8BFyxCeGZAe48CxrB848UJ8CVZ+QbLnAfvuoUAWh+Hiz2uca/x+Ni9ptilTlGmvus7bqpa6auF1vb/bSd03aNkrljy/meT5m7WrVqX856AbZN0+jDhw8WYeyZXpxmQkCRzwP1HXrwI3p7fn7Wcrk0UBmPx7q8vNRoNNLV1ZXVPqaZO75XL9XS7B1Qh0X4fFrf7ScO+CJwCsCkNCXnUXby6enJ1gd4khYkydi6JE0mE5sLAOaavoQlvlf8yT44inGSjlrx8dwlWZQ3cz0/P+vu7k6bzSb7vbb5UlNjGBeDR0r69X/7eXJgmrtmbg1tY1MgXTL+FPk3ZrC5NVWrVq2/1huwvbu70/39vb766it7gflUFF89CYDiJUMKEC8lDzC+9RzM0gcuUYQffzEg6VN5fNoRayKVhuM+bQhgAgj9Ofh2uT/GkavrA6/IWQW8fdQzcvfDw4NVx/LyO2N8UNR6vdZ2u9VyubRnBtDiE4bdA8LI02wu2IS0WQogS3yXflwboHA8BVpvZXc5Nlo6tstyfuO2cfE5XKvtvlPPvFq1av2yXvhsAazD4aDVaqX9fm8/AQ7YG9Kl79Djz/fMEnbmc16l14bsyMn4MgFdgAofpa/D7EFeeg3gIugInykND/D7Aq4YLNQ3j0eSJh/WF7XgH6AOq4aV+3sHXGGu2+1Wm81G9/f3Wi6Xtta4R21cbxnfr69ylSrFeIp1+Vfj/xseqDgW+ypTAM34U9aSW1vq97Y52oC7VELOSe+5c6vPtlq1flovmK30Aj7U58U365nafr839kfELMyS8wEZGBoAHQMaebK+QhRBS/hlySP17BnJejgcGugOBgMDNACKDQLABwA3TWPA7jcIBHZ53zHXRB73jBJwWa/XltLjI6YBWdgrKUwwWzYZgCvyNyqAl6oB36ZpjjYv8QbGW465nTLe32v8k99TMmup9JxiqymmXAKc3xXDbJuni8G2gXS1atW+vPUCbHlBAFDn5+dW+vD+/t6KWyyXS43HY3v5k0+Ln1J6lYbv7++NIfuuN/iFkV5hrk9PT5pOpxqPx9bObr1e6/LyUre3t8YykYVpdYeETECTL62IPxi5F/OR0L5pAeABwHk5HUClwb2v4IQCQBELD8DUK2YjQ4MFrkfHHwKdfCckfLI+1Qo2nGsQz/dQIsXG0qkfkwLa3P+jeN7PAeO29X7fllpLiRxfrVq1/lgvwLZpXvvMUlj/9vbWPvOpKIAmjI0goaen184/AKX0WjDjcDhoOBwagHggoyqSJAuOGo/HkmSVlDyze3x81Gq1MsBlo0B3IXJ9fb7vbrfTaDQ6ahPIOnz7Pe4Nxol/2su9nO97znrfNONhsQRFPT09aTQaHcnzPFPfPAAGT0Q4KVf+/tu+Q+6nzfdY4l/t8p+WsNDUNdvGpoKOuubNnds21o9ve0Ypy91X2+fxdapVq9Yf6wXYnp+f6/b21kr9+VKMPveTWsKAEEyOwKTFYmEt3zx79WUXpRefKOwMsBkOh0cN3YkIJq93OBzaMcok8mJDOmYc8rWXaNk8eHlZei2wwT3jt419zmwMkNA3m42Boo+OJh+ZZ+YB1wc4NU1jfuPVaqWmeWk0j2wt6UiK9rnOMdjmGFcXqH5OYE8q8KiEvbatpeuz3MagjTnngrZOeQZtzzS3EajMtlq1/lkvwJaXA2DjWR1AQwQxzBMfKFJp3JLuF7/4xVHNZEBkOBwa0NDWD5aH3xUwHAwGGo/HxvrIo6Wik5ewm6Yxf7KvMsWGwZc5jA0f8WAw+JbvFt+q9Ap+bACQjiUZg+Yzest6uZl1cL+MB6xZC5K5JJvj4eHBKkud6q8tkTxTLK1NAm67VhfDLGHSbevNrT0Fgvxeyly7ns0pG5YKtNWq9dN6AbaSjgrb46P1wUH4Jpum0XQ6lSQDFACAMTBbgII0FsDx4uJC4/FYIQRjtKTb+HKLAKlPAcJfzEstZqKcD1hJsuAsn47j2TvyOQUlWLvvVkTVJ9YQMyjvx4WJxvfunxPMF6CNc2t92g/+Xd86z1uXpNomp8Zg1iWtdvlYS6XZtjneIunGa4q/j9T5MTCW+mRz660AW61a/60XYAuwAQSStF6v9f79e0kypkbpQQJ8KDaxWq0kvUbOAgjMid+RiOV3797p4uLC0nLwcd7c3Byl0QCGvkEC6/GMmGv5alceBPncpwDBhDebjc1DVSaf2+rrJfv60CEErVYrY6q+jCPM3LNpL0WzaaGwBYw89ktLMrCmalTbd+etDXhLAaYEaP3fuaCnLstdNyc3lwZtlcjpbT7gmO22AXcpCFerVq0/1huwHQ6HxuTwj0qvsiYvIAruSzL/I5WfvvnmG0uHoeKS7+kKw9xsNiYtUx2JohG+1KIkOw6YjkajbzV4B5hZn3/5wWa5T8YT1ezze33Esy+GwSaCe0Y+Jg2JADJetviJ/T0DoLBk3x3o/Pxck8nEylICsBTU2O121uM3xWLbJNES+Tc3NgVmKXacYp9dzDtnbQzcH28DurZn0Hbcrzlef9vxXNCV6W8dIgAAIABJREFUv9cKuNWq9c96A7bIqoCbb8DuGwBQYIIXysPDg1arlR4eHqzxPHmrBBDFTQvIdSVy+ZtvvtF0Oj3qnStJ2+3W/Lx+fQRbwRR9sQdfvN93zWHNl5eX9vfDw4OtV3qNWJZkEcP+/qVX9k6RC3y0victkrMHXObCx+tzc8lx9vJzHOnsv6vc76dIuiVyaBeYpc47xXcaj29bW9e5JWAZH4/X3nbtU+87JWNXq1bty1pvwBYWx0+Ym5czYXKwN0nm69xsNsYakYaJWEamDSFYAQoCme7u7qxhwXg81mw2M58xrPLu7s78uoDej3/846PAJ38vMFgfZcwxH83LGpFvvc/Wdw8C9DxrRu72fWYBfNip9Jou5f2tvlOR9/N6Brzf71trH6cYl79//5NzOJZievH8uevl1hT/v2ob2/ZZSppOzZW759wmIqUIpO4jB/jxc02BcrVq1b689QJsMVJxpBdWSWTu09OTttutRQD7CFrfm3W73RpQACIYgUjSa0RzHDQEEOIXvrq6MmAmAll6lbZ96UYkY1i69PrSgwXDRGk8wL1JMmD2hTFCeOkXy/15sPJMmmhmX4aR66IUcI8+yIv7HY/HaprXgho8yzYrYVwl57T93TZXiaxcyohL2WoOEHPXTEnpqb/bZGB/PAXwOVZcrVq1flpvwBaQpKIRhf6pYUxw03K5VAgvpQphjQQZcfz+/v6IPSKn4pP1jHI8Hlte6uFw0HK5tAAo1kMvWuReAGy73RrTlmRABVjiC/ZF/ZG1fbciQNo3G/BgKL228ENGJ88W3670CsC+oIYvBMIzYDOCAQC+cEUcsOOtFMhSDK+EraYsB1xdLDD1+Xfx2VuAPDXeb6ragstOkeqrVavWD+sF2IbwEiBFf9flcilJxsDiIvsUpfDdfQj4wQcZ550CZhcXF1Z1yjcyoE8t0c3Pz8+6vr42PzHN6GGbBHDBYuMGBTBWANczR8+kAWDG4mvGVwro+o5Am83G7pfGDL67j2/wTlAUEjapUqwZ1QCADSEcycclL/PUSz8HJrljKRBrA++UhJzyjXYBZAmDbfsstf7UutrWkZPlc+tJycnVqlXrj/UGbL/66ivd3Nzom2++kSTd3d1pOp0eNT2n+QBM0ZcwfHh40Hg8NlYIkHq2hqwKmBFQhbxLas50OtVPfvITPT4+6quvvtJoNDL2zBg2AXQJkmRRymwCAL2maSx9h+pS5NFOJpOjesS04GMTQAWo8/Nzexb7/f6oh6/vXQt4swHBR71arew5kBvMPXM+gVF+3bkXeJevsuTF3yUB+7lOmbfkejFj/GWCVMzm29aUUgHiz/yYkiCzatWqfXnrBdhKr8X5kUjxQxL8AwAhgyKnci7+yhCCJpOJtejz/WKp9TsajTSZTAygiF4G0KbTqd69e2eBRdJLo/bZbKYQXvJbQwgajUbGDn2LPYCYICVemEQhc5z1szEgAhjWzj2wmcAvCzv2zdx9VLIPeOIc7tFHe6MU7Pd7a8PHtaVvg8Dn+Fvjc04F4tzvpT7VrmvFzDLFPN9iXSzcXy/FXruef2W11ar113oBtsi41DB+9+6d5vO5+S89YJIfi/R8cXGh3W6n6+trk4pDePHd+m48NDrwAUZcm3P8y+7u7k6TycQ67UivoD6ZTMxXC9CGEIxZ4hNFmqYoBO34mEuSNpuN+ZQJxvJys5d2fYWnGKB9az2kY3zBviIXc+DzpfXeer0+Srdq+47iv08Bobf4N/3Y1Dm54/E6u66TWmcOBNvW0SVpl45PrT/1TKqMXK1af60XYCvpKDDn/Pzc/LLSazN1JNIQXlKFiE6m+D+gNRgMdHNzo8Vi8S1wIi/Wv1wB8sPhcMRWCaAaDoeSpNVqZX5V/KTky9LQHSCjUAQbBSKbYd/cg6Sj9nZ0DYLlN01jjQK8RA57lmTytm9m4ItSEBzl6xxT63i5XJovt61CFPPzrEpl2Jy8WQIKpUBXcrwEfHJydtcaS+Y+ZbMRs+sUa3/LmqtVq/ZlrDdgS/UnX8vX+2XpqIPvFXkVoCWFhwbpNEzHFwnAIqNKL9WlaEDv+9kSYEXxCpoWSC9MlNKP+IAJPrq+vj7yyxLMtVgsdHd3p6ZprKsQzep9wwHKRrIpYCOAeR8t58LMfaCXl7U9uOLvRTJeLBYmHcd+RKyULZ3KVLvmjYE7t5Yc+41B7pS1xvPE55YAehur7ZKDu9YYPw//ewXbatX6ab0A26Zp9Itf/OKI+dH0HcCSXoCOYha+ATpt4pbLpQHIer023yrM0ku7BFPBlEejkd69e2eNCWIJltQbgJ+8X6pMDQYDLZdLC+Jar9eazWZaLBb61//6X9tmgAjr6XRq/uDlcnkUbBVC0HK5tHu9uLiw9CcPwD7NyOfpAq4ALq322BQsFgstl0tjuimg5bvxL/WucViXXzI3j7ccUPljpRsCnl+Xv7PEj1pyDzEgtq0pt4YuYO6av1q1av2wXoAtPlb8iL4vLJWbkGkpiE+NZJrEr9drLZdLffz40Qoy+KbrMMDLy0tdX19bDipy6p/4E3/CIppJD8KX6zv0SLLG6nzOCxzZmjzdn//85yZ1e9BomsYqVxG0RZQwYEhzAHzWzIG0jo/28vLS0nd8Sz7AlT7Au91OHz580IcPHwxguxhtymIwKf2O/fnx82DMqYCRCjpKra/Ln5rzpeau7//m3LbnlHt2p8rHXb7gatWq9cd6AbaSLBUGMAUcQ3hNf+HFAiOELfp/yNAwXkkmC8NaqUcMS/W+X18gAiZKGUX8phSKIOKYQCPk6MPhoMViYb5d8nevrq4snWm5XOrs7MwYvKSj2spELlOAA1DF/4ovlrQoD6D4jff7vVarle7v7zWfz7VarczX3MYgY/uuAnBimTeep0uCzfk724AmNb5LCv5coE3NHd971zyptaeeW05Gr1atWj+sN2AL8D09PWm1Wmm9Xms8HhuY+bQVXyMY4PDyIIE+MFJAazgcWtGL6XRqQVWDwUDX19eaTCaaTCbmo/UdffCpwrhDCAb2vikA63t8fNR6vT5ixoA0G4EQwlF+r2ewbAB8jeVYBvUFMHyu7Ha7NTl9tVppsVhoPp+br7eUmZ4CtCXMLTU35+WAMyWVtoFPCky7pO0u4E5dr9Ry/tkcw+66ZgXaatX6b70BW9ghqSyHw0Hr9dpAjG49TdOY71HSUdec9XptLx0A8ebmxny2RBJLMhn67OxMo9HIqkUBYnTnISXJt9nzgOn71S4WiyNJuWkaux7r9DI5AOubtPvm9d6nzFwAL8ya8wD47Xar5XJpPXzxZcN4sRi4vX3OizsFBqeeFwNtl6ydAsTSIKzUZ6UydHwsHptioV1ScMm9dPnTq1Wr9uWtN2AbVy3yNYQBJNJzAJHn52crNAFwhfAS7HR5eWljAFok4OFwaJHHTdNYcBRAC6COx2NjyT4CGNZ7eXlp+cAeKCVpOBxaWUQP1AR8EYVMf1wfAIX5Gs7UQEbqxp8rye6Ta/mgKCKy40IVWBdTysmW3koDlErOKWGcp17zVMAuPd4mUZeCeAySbcCbY+Yl91WtWrV+WC/ANoRggT3ke1KwAeDdbrfm40QKBoyRemG0kgx4AcfJZGI+09lsZkwWGRmp17M95oUle2kXAyB3u91RW77JZKIQwpF8DJD76ljUYiboaj6fS5LVcfbgLb28XIfDobbb7ZG8DNtHHUApoBUfzzl+7rnvpCR4Kid/xpbzQeZ8sal5SiTtUzYKXT7d+BqlAJu7xy7Z/RSfc7Vq1fprvQBb6fXFgxz6x3/8x0e9a303INrvUfiCqGL8nQA1vtnpdKqbmxuLMiZQKoSX1B7SgKTXhgLMRR1iwA7GzcYAfy4StJeYPfgSXEWkMPeKn1Z6bVZPahLPhDXCrn1ZR6pTUf+YtJ7lcqn1em0bgxIfZBcY+HP4PJ6nhNX5uUtl58/xlcZz5yTcU+bOgXbpfeXGp4D2rbJ5tWrVvpz1BmyRPH0HHx/MQx9YAqmIXvY+Uy8XX15eajabaTQaaTgcajgcWlrP5eXlUds8ZF2kVq4B2wQQ46YGPkcXWZcoYp+nSxoOwVAAr/Tib4Uxn5+f6+7uzloLAsgw46urKyv8AYD7GsiwWKKQfUBUG8Nrsy6GeQoDjc/LzZlbSylbjo91AVP8d9c1UkFasZUoCCXXrXJytWr/7lhvwBagosADPkzAlGAmLxvD8ubzuX7lV37FpGX8pwRVjcdjXV9f68c//rGkl5cVDeI9k6XfLdK1z6ulIIb06kulChSgyFj+pqnCfD63tn6SLMIaaZk1+X67vmCHJANc34AAlizJfMA+1cj7ar3F4IGlXuK5z0qZWXyNGGxS/sv42vH5bSCYAqbceto+P4Uxtj2LEnm6S0bOXc+f812w/mrVqv3yrFdg6yVaAAlmeDgcLO0GpkkJQp9Xi0SLf3QwGGg4HGo0GlllKIKVJBnQDgYDC9ICMCWZLEyeL+scDoeWR0tFKdjrdDo9KoUYwksjAd8MAZmaaGj8z8jRnv36DQGSuq8ShawM26chASlSKTZ6Cri2sc8cE4w/7wLdU9haF2iWWBsots2Z85m2bQi6GHCJxJzzbbeNrwBbrVr/rTdgS29ZAoua5qXKEmURKVnoWSR9ZieTiZ6enrRYLIzRXl1daTgcHhWGkGRFLXyKDS8r0nwYK702sKfDUAjBmGcIL52H8CdTbALAw0dL1DN+WNr7XV9fWzTzYDCQ9Np2D7BFyqZaFtdomuaoHCNSMv9y8iq/Y10g0yWvlgCFnyfFrOM1xGO7mHC81tJ79L+nnlEXy01J9fGaUz/9+uO1pa7zVlZcrVq17996Aba8KABcXz3pcDiYtEwXHQ+gg8HAfJT4aZ+enqyhQAjBmKD0+oLy3X9gmjBaAC+EYD5amCVg7COFqXrFPERU054P+RlAxMdLQ/cQgqUJAbCAM2vxwVXkzgK2+/3e2uRRmjEOjMJyTNJ/FzEY+M/isf65xoyri0F2gUQX4LetMzV37u9S9lhyrRQwp+6lBChLvsPqt61Wrb/WC7CVZIzV+zWll5KMBAY9Pj5qPB5rNptpNpsdNSkgQOlwOOj29taCjkajkflPkXkJjpJ0lLsKwAFikjSbzb5V4pDoY9YMi2UDEIM4bNeXlZR01OOWdVCVKoRgAV80VYDpIxtvNhvrh0sNZGT1tud76ou4i5XmgPgU2fkt1iXFllipT7aNQbZJyzEIetaaA9+2NZ0iQcdryykG1apV+zLWG7AlWAj/rGeuFNyXXgAKvytRu5IM1ChoIclyWn3QE4FKMEbOAyS9tAwQXl9fGzACmvhEPWP2ZRnxLTN3CMHyhvn5/PyszWZja2Q80di+ITxBT/v93nJpaT5wf39vLQo5ByuVgnPHUpJrfI0S6dnbd83CugCzi9mmLMXQTxlXsjZAsnT+3L1Vq1atX9YbsOVFDvMjDQgAbZrG/JHL5VKSjkBzuVxaEFTTvOamNk1j9ZF9uk3TvAZR+UpNyNS+4pQvHEH0736/t5Qi1gKTReIlEph5CADzDeVJ/fHgT3UqfNQPDw9aLBZHUcw+v/bu7s66H6EIYF1BRqeCBp93je26bsna2iwHmqWSd+m88fkpSd7/3sXwuxj55zDa3BzVqlX7stYrsCVXlohcJGSYH5Ipx3e7na6urgxkx+OxJpOJfvSjH+n6+trYLAyZPF1J38qp9Q3rCZ4CeJGoYY4+9xX/7Ww20/39vUUXDwYD3d/f2/1RAcv3wh0MBrZ+QJINgE8NQgpHYsaPvd1utV6vj4pk+OpWPFcsFbCT+j78OG8p8C1ls10yZ06+LmHhuc9PuWZubDwuxe5Lr5/bpJQy8GrVqvXXegO2sEeib8fjseWUIgvDbsfjsflcAeVf+7Vfs3rH+GS32+1R3ir+VZ/HCjhdXV1Zbq/PT2Vdu91O+/1eNzc31k6Pak+StFgsbF6AGHb89PRkaUvcHxHGMFma1Esv8vf9/b35jmHdtNMjh3a32x0FRHU1gn8rA2o7L8fy/Dkpn6ZfZxfAxOenInfja51yjzFLbbvPHJCXnpOykk1IqVWfbbVq/bPegO14PNZ+v9dgMNBmszF/q/Ra0EKS+WRhq03TaDab6Uc/+pEmk4n2+73m87kBGoFD5OviG/U5rMjIIQRjlPz0FaAuLy9tbWdnZ9rtdkfyL+zUNybwqTohBNs4sAbkZBj4+fm51TQG6H/xi19osViY/xYQpoAFYJySIKW3M77U2FJfpB9bKkWnrAvA2qTsnKVAsYuxpq7d9qxPAf3S5/jWeapVq/blrDdgC5gdDgcrRAHIUcACdgqD9e33SP3xQOpTeSiViFzsfaywyrjXK2DJMV82kfObprFGBdwHMrD/G/mZ+/Ry9sPDg0nSFKZAHqbVH75bPgdopZeXMcwbK5Uz3+KHbPss5bNNAV4OiONrpH5iXSy4RJ5NAWVufacA6Kl+aH+8a45TwbhatWrfv/UGbJGDkU8JbgLIQgiWUzuZTDSdTs1XeXd3ZwA7nU7Nx+vb0xHFfHFxYek9Iby25cN3i1/Uv9h8oQlfIxnZF1/s1dWVASM1lZHGibT288KAAXpSd5qmOerY4wO0CIryYO5LMqZA8FRW1CbNts2f89+WAl3O2gCvhAmfev9dzP8UBl8yf3xuyTlvmb9atWr9sN6ALYUpttutQniJQL65uTE2SFu6yWSiyWRi/lFABxnY+2JpAk/zAeRnxvkm7DFowYphnPhEiSCGgXNtWDng7tflg5fw28J0SdPxwIpvmhKRviQj81OlStJRgQ2s1Kfadl7u87cAwFuB4HPB5XMYX+l9tjH4ro1AbhOS+zx1P6nvsFq1av2xXoEtlZ9gkMPhUE3TWEELZNz5fK6rqysDN/y3AJskA6TRaGTRwdPpVKPR6OjlxLxIxjBNAJjj+FQZT3Uq6TWymYISrItAK/JxeXl6ny4SOYFPBD8B0LBtUo48o4QxM77tJdv2Qs+BQRtwxMfbZOLcNUok7FN8yLl5cvfyljm6xnXJ2m3KQNu4eHzqmt/F86pWrdr3b70BW6TJi4sLA6PNZiNJuru7MxZHKUfkVlJnRqORptOp9vu9FouFLi8vtVqtLOqX2sZEI+P79C8vz2R5iXIdAB0g9RK0L3KBj9anEhHghQ+a69G1CIb9+PhowMt6YLCesRN05cGenGTm9s8VS/lgU2zWA2oMAm2stQsUuhjdL8NS6yvZJPhjjO0CVz9H2+akS5p+63eYmq9atWr9sN6ALUarPQ+2u91Od3d3xibp4nNzc2MRxuSsAlDIsQRMhRC03W4txWe9XtvY6XR6VNSCaGPYpA+48nI0PWMBQ6RuooqRsn3uK+cxJ4U6NpuNFabYbDbGWEnrIc/Wp/2QCrTdbm0zkmN58edtrDUGzFMCe+Lxqd9zANi1EUit4dRz43tOzRmP9fOlnuVbWGgXgLfNF6/pc2X7atWq/fKsN2B7eXlpqT4hvJQspBwhkilt6mBxIQSLQP7mm2+sdCLBT765gJdyHx4etFqt7KV0fn6uyWRiTNfnyvpCGJRZxHwEc9M0Fh3MixDfLNcHYJGGYdi+GMVut9PFxcVRCz3fMu/5+dkikUlzYnPir52Tidv+Ln1Rt4FK23yngEfbeZ7BdQURdW0wStbWBqZvWX9qjd7a2GkpQKY2LfFn1apV65f1CmwlHfkfV6uVdrudybf4Tp+envThwwdtt1tNJhOTYiVZpSiChnx9YRig7+LDvL48pCRjw1SpYm0hhKPcWZgrf8MwWQ8smBKOvNTJ08Uf7bsL+dZ5/jPKNtInl65BKYn3rfZWQI3PfYu1sUI/d5eMG3/WxpxzTLdLni0Zk7KcjN8lL/t1psZVoK1Wrb/WG7CFcd7f32u322k+n1vAELmwvvsOx3e7nQVSUcaRFB8Y8uPjo1VaAigJciJdxwczISPjS6XqkyRL94Fh+vrJME/kaHKAJZk/Nu5H6wOiuB5+We6VzcJisdByubRGBKzDR1G/5bm3SaEpS4FOKZDkPkv5MNsAN/V3DhRL/87J4/G128akLAegOcbaNV9K7q5WrVp/rDdgS54pvktYLPIsvW6bptFyuTwqHEE3n7OzM/Pn+hxYfKBIsRxvmsZ8viEE6+yDlAu7XSwWVnIRkIRthxCO5GKCpmCxyL0hBK1WK5OQaZFHvWVJNof/R/DV4XDQfD7XarUyOVxSazu9UkuBbAlApkDxFHaVYojxZ12yaQ5YS6+RslM2Eacyy9Q6Puc5VnZbrVo/rRdgywtit9tps9loPp9bnWKkVYpG+FrJgNh0OrV/4/HYABBgJAKZKGN+J6Xm/v5e4/FYg8HAAqdogACDhsnCPJGHAWRKQ7JG/hFZ7BvKw7R9WUbfXQgG7AO7/s2/+TdWVQqm69v7lYBdybhS5pj6HlPS8ilsrYud5WTzEsk3PueUz/y8p8i/befnGHnpd1mtWrUfhvUCbKXXNnRIxvgskVIpedg0jbHWx8dHA1kA1Ptj9/u95b4y78XFyy1TROP5+Vnj8fiotywRx6QZIdlSLvH5+VnD4dDGsSk4OzszPyqM9uHhwdrl4XulATz35hvbMwZgjpvGw3KpItUWmYrlfJzxZ7EUGZ/XxX5zjDce0/Z3LKOWsNY26wKw3D2krBTAU+fk1ti2vrf4qVNzV6tWrR/WK7D1xSPIpfWt8KSXhgW+C9BoNNJkMjHf6Gg00vPzs1arlcnHzA8jpR8uHXUAQ/rmekOuJrWHdB/a5E2nU/OrhhAsRefx8VHb7dYYLqUYaQDv823jylOM9/5ZgN4Hekl5uTQG4Zw0mzq/7ff47xQT7ZJr38Iuu1jtW6/n5yi979Rnb5GB2zY2bdfI+bUr0Far1l/rDdj6wCOClXxNYuRb6iaTkjMej4+auANcHpC8/3W5XOrh4cGYMmwMqRp51gN607zUOvZRzbBu/Mi+Ld96vT6KPF6tViZZ+zQdAqF8Q3h814Czb6MX39cpAU1YSUDUqS/tFODF4PO50q0fV8J4SwKWugKsSkDsFKn9LeenWH/q/GrVqvXPegW2vvISvlWA5fz8XLe3t5Jees/e3t4e9bRFPoYF+kb0nM+5GFLscrm0Mo6kDVF/2b/E8Lc+Pz9bdLIHSq5P1LP08iJcrVZar9dHUrFvegAwN01j8jn+Yc+auQ7zcu8pawOMt4JC6Qs9x5BPAbDU+C7gjsH+FB90LjjrLf7fz3lm8Ryp77BtjV0+72rVqn3/1huwJQ2HyN4QXiJ66WvLC+X29lZnZ2fGbmGK8/lcs9nsqBk8pRzxdT4/P2symWg0Gmm73Wo+nx/5Ryk04SObfUOCEIKlFXlW60EQP63PyV0ulxZ1zPpg0L5ilpeQkdS5HvcgfT6TSZ2fA6ZSdnfK2kqYZ9exUlbZtTlJ+XXb5u261xIm/7nstMrJ1ar9sKw3YAurvLq60t3dnQUO8eKgvvDj46NGo5HJr9JryUOYImk17969swAnJGcCn+i+E0KwUo1I0hcXFyYF03uW4C2ANpaQ8dN6WZjWfpvNxtbqazLDxim/SL6tb5/n03woX9n1ko5f9qUvYT+ua3xp0FXOD1kK4Cl2ewqwMD51TrymHJC2raEkSCn1fHJM9C3fYbVq1fpnvQFbmgUMh0PNZrOjMo2SrITiaDQyKRjG2zSNhsOhAV7TNNaU4OzszIKmQgiWLjMcDg1MCYzCT7vdbrVcLrXf7/WjH/3Iopzj0osEQcWVnpCFCW6KI4xZF40K2oKl6AbUNM1R15/Y2l7eKTDJsbs2gE7ZqYzUr6+UVZesOTdPl2+6i+mmQPetsnyJDJxaf25NlclWq/bDsF6B7Wg00vv3702a9V11ACcvNXMcqRU5t2kaY7MhBE0mE2Oo+/1e0suLi/QdXwHKy9D4jK+urozVAraAH3m1HihhuL4bT9wzF9YqvbwwiXrmPvkcppxqNJDza8aWOy/HQP05bcfj81LAnZOASyXc1PX9Z11A1TZP17Xjz3PPL3efsU+5ba4cgHaBf3yP1apV64f1CmwJOoI1Ao7kow4GA52dnWk6nerh4UHj8dhAyOe9bjYbS+nxxScAL5gj7JZSikjKRELDRKm3TCceL1dfX18bQ/WACuD6NnoYL8izszPzS3uwaZrGgre8vJwDkS5mG1tKiu562Zcw2jZZNbf2eA2nStj+eDxvji133VduM1C6Megak7pGyYapWrVqPxzrFdgCjHTy8cFF/Pzxj39ssjElGAeDgUII1mKPlnkhvFaSohXdarU6al4AUFL9CRAkHxeghm0iMUvSbDazTkA+jQcfsGellHYE6AnuYl6fn4vPmTQjwD3HmKTytJCcpBkf6wLiLum67fd4LV1j4zGp+0mdF6+9BNS7Ngc5iTo311tY+1u+w2rVqvXLegO2V1dX1uaOaGFALYSg6+trY4GAFLLyYDCwco5PT08aj8eSXtJ9ttutgSFgtlgsjCVLMkbK39JLriw9bc/OzjSbzRRCMPBD+gUcvTxMJLOXBX11qxBefcdcE/Cn4QDpP1xLKvPPvYVpeWsD8NzYknWUMuWSjULb9UvA91Sp9RRA9qpDCYNvW3PJWuJjlf1Wq/bDsV6AbQjBpFqCgeioQ4RwDDxEDSPBcv5gMLCcWaRYHzhFFPFgMNB2u7UuP9Pp9AgIiYyGaXs5l4Ar2CyVop6enjSZTNQ0jaX6+E5DsGyYLpHNAPXDw4OVZqSRfMpKAo1SAJMDkhyDygFxalzbRqEUJEqYfJt5IPLA+xafaHy8zefapi6k1peSsUt88fFnFVSrVfvhWC/AFluv19avlShiyiSSEoSPFkC8vLzU9fX1ERASmTwej7VcLo8KREivObhN01gzgPPzc11fX+vh4cFk6fF4bOwWXy2BWz7QilQimDSyM+xUktVu9v108SHTT3e1Wll0s5QHlxJ2Gr+sS1hvbF3gxPVS85Z/mDMZAAAgAElEQVSAagljj9eSY8GlsuspbDeW0kvWmlrLKRuN+F5Ln1W1atX6Zb0B2xCC+VV9kQhJVmxiMBjo48ePFthEFDJg6atQAXSUPWQ+mg4sl0s9Pz+bzBxCsFQgH6AFA5VeyyvCROPGAQRh4fNlrO+T6w1f8n6/N7AFuFMRql0y5FsAtYRFlc4Vn9P2d2rNbeuIg5JKmWnbHF1rzYFgat5TznkraJZuspi3WrVq/bPegC1gCZOkKXwIwQpZnJ2d6Vd+5Vc0Go2soARjzs/PLZp5Pp8f+UCJ6oUJ+6hkCltMp1Orr+w/ByAZCwAD6AAuqUfch/fReinVB01tt1v7t9lsjOVK3w4G+lw2F1sbyJzq//ucIJ1SGbxt7tw628amgDf1vNqeaxsr7rqf3PNt+94+5zuM77datWr9st6A7XA41GQyMV8ngUgEJpH/enNzo9vbW8t5fffunTFHfKWSrLk7PW7x93rpVnqRd4fDoZV/JMCJICtSicbjsdVdppITci8vuOfnZ2t6gAHSvjgHUcbr9drYLF19uqTMUwCu7cXdZp8jTeZ8mbl1pAAmx+JS4Jwa2+bb9NfN+XVz12yb65dluXs+5Zxq1ap9WesN2IYQjiTUy8tLK5t4fX2t6XQq6UUG3m63mkwmur6+1tnZmQaDgQVWwUR9WzzSgPb7vRWhgIkOh0NdX19rsVhYuzw+h2mPRqOj9JuLiwutVitr2+cBFr9uCMHkaBoX4Dder9e6v7+39B7+saHoek45FpXzafpxuXPjebrOS33eZSUBV58jbeek7Pj3twQdnXJOSpXI3X/qHkrVhmrVqvXHegO29KClJjF1hc/Pz3U4HHR/f6/JZGKBSr5hvJdnvd/X+1ulbzMCn8tLPeOLiwvN53PL1aVbj6/FzLzIwYDk4+OjbRJ8NaumacxHPJ/PNZ/PzafcNM0RQOf8fFiX/Np2POdHbJs3xQbjz0pf7imA7PJ7ngo2b7FTmWmpT7rkO0yx/DY5OKUGdJ1XrVq1L2+9AdsQwlGZQyRVmOBsNjsCQgKdkHIBLmReyixKrz1uAW4KTADEm81GV1dXR0AP0+afJAt2urq6slxYv3ZfrcoDMwFZ+GZ9GUYvZzIXP08JCGo7z8/nx8YAm5u/jQHG8/m//TmlwUepuU79O76fruunwLtrA9H13eRk6TY7ZRPzFtm+WrVqX956A7Y+QIqiFQQk3d7e6v3795Yf+6Mf/Ug//vGP9fT0ZOkyy+XS8m594/nn52erSIU/mBxdIpHH47Hl4yLn0n6vaV7SgwBmNgL8o08uUnUcrUwrPfyz+Gub5rWWMlYCeF2f5QJ33iqd5ubIreUUBt52bim79+PaWF6KEb7lecfztK3vFLCLVYO2OUqeWZWPq1XrtxWDbQjhXNL/JennTdP8+RDCb0j6A0nvJf1TSX+laZqHEMJA0t+T9KclfSPpt5um+Zdd85ObCqA+Pj5aB6B3795Z0YnpdGq+1dVqpc1mY1IvIMb51DmGSeJbJaBqOBwaoK5WqyO2CUhKr71nm6axACfAmeCqpnntUPTw8KDVamVs2zeN979/eq6tz6NL5k2NL2U5p7ycU2D1OdZ2XzlJ1Z/Txuy6zvXnlaoFXcfi9bfdX+k1c59/FxuEatWqfVk7hdn+V5L+X0nXn/7+m5L+VtM0fxBC+DuS/pqkv/3p513TNL8ZQvidT+N+u2tyuv5sNhsLJrq5udHNzY0uLy8VQjCZlrSbp6cnrddrY6g+1xYw9AB3dXVlNY+bptHV1ZUOh4PVXWYsjdo3m40xYVKGGPP09GTrov2f9BLdfHd3p/l8flQGEh8y18FO8VnmLAU4qRd9CXCn1pQbm5OS/Tpza3gL6JTeW9d9+zXmNgE5xpxaT9d3GT+bru+w6z6qVavWHzvrHiKFEH5d0n8u6X/69HeQ9FuS/vDTkL8r6S9++v0vfPpbnz7/c6HjDQFQIsNeXV1ZpLFnorTX88UiOO9wOOjm5sYqQ1G2ERkYPyw+1KZp9PHjR3348EHz+Vzb7VZ3d3f6+PGj5vO51uu19aINIRzJ1fv9XiEEy9Fl/YPBQMvl0kouPjw8WIoP5yExv/WFGPtM4+fI8ZQs68el5s2BYPy3l285t4sJtzHwFNPNXb/0s9w1StaVY8ep65yy9rY1lHyHqTkry61WrX9Wymz/e0l/XdLs09/vJd03TUOZp59J+umn338q6V9JUtM0jyGE+afxH3IXAAh5UW02G02nUz09PR118QkhWI4tYDuZTLRarXR/fy/pJT1oNBrZvLBVSieOx2PN53MtFgsrxUgOLQyUso0EO/FyQ4om6pjOQ4xjPiKikZLb7rfNUhJm6pl1HS9hsF3BOCk7lX2Xzlf6dxurzt3HW1jhW1SHNiA8Vbo+9fdq1ar12zrBNoTw5yX9ommafxpC+E++qwuHEH5X0u9K0p/6U3/qyGf7/PxsNY55oQyHQ41GI/PdehBcr9fGivHR0h0IACXwKoRgFaZ8QQmKaAwGA/P1StJkMtHZ2Zk1FACACcSiJjKMG+YMwEtv84/Gx7qkTKwLcFL+zFPXWXJOCbvukpRT12pj+Cng7XpW8fm551LyjN4y5pT7P9XfXK1atS9vJcz2P5b0X4QQ/jNJQ734bP8HSbchhItP7PbXJf380/ifS/qTkn4WQriQdKOXQKkja5rm9yT9niT9mT/zZxpeEOSnDodDXV1dWQDSbDbT9fX1UVEKSiI+Pj4auyXtZ7/f6/7+Xsvl8ihYqmkaY7n4ZMnNDSEcte/jPF+6EVDl2OXlpbXT843uveVAsvQlngMK/zMFzG3yp/+9y+8YX7dtTAkI5ADYj43nL2V+8dgSMO/axLT9/hZVoPQ7TM2VGpvbQFWrVq0f1umzbZrmv22a5tebpvn3JP2OpH/UNM1/KekfS/pLn4b9VUn/4NPv//DT3/r0+T9qChxWAJwfCmu8urrSdDq1bj3j8dha300mE81mM5OOYbp//Md/rA8fPlgnIfJc8ct+/fXXJkVTN1l6rYvsgdz7WWGs5AGzKdjv98aY42pQKeYUg0qp39GDVttLtoQx+fNSL/i2NbatPXcPp4BdfJ0UyJ1iOfk4x4S9pXzVqbG5a7Zduwsou77PrvVWq1bty9vn5Nn+N5L+IITwNyT9M0m//+n470v6+yGEfy7po14AutPwg3oZ9/r62nyjSLfIzD5QCt/pcrnUfD63403zUhAD1unzdz1I+rKL1Ecmenm1WmkymViBjN1upxCC+Yph2svlUovF4qhBAdYl/flxXfY58mEJC02Beal0mQLFt/qFU9Jx7vzS5x3P0cWIP+c7LJGiP0fGr+y2WrV+20lg2zTNP5H0Tz79/i8k/dmWMTtJf/nUhQCe+FXp7DMej3V5efmtFxEBUxSZAGjpGCTpW911kH0fHx/1k5/8xFrvzWYzY7iS7HpPT0+6vr626xEIRaTz09OTMeavv/7aruXbA2KljKTrWInUGZ/fds2UxFnCkkqk5DYAeIuvufQeSyXb+J7a1tp23RSYpb6f3Pq6voPUPabWFq+xMttq1fpnvakgRYAUbe4Gg4Emk4lGo9GRRExOK8FIHz9+1MePH/Wzn/3sKCVIktUf9kFSnA+wcm2AN4RggDqZTI6azvMio2fux48fdTgcLNDq6enJmspjKT9pqb8tfpGn5k6BWWrOHNN6y5ril3xKZo7P72JhJWDWdk7OUqCbu24bmHmg9n+nrldyP12MOifLV0ZbrVp/rVdgC8BRualpXgpPjEYjA1Eihn15RZrLU96RdnVIzDR3J2eW6GKCsbg2INw0jWazmc7Pz01+9s3kz87OtFqtrPxim58WK/XHdQW+eOtigV3sMQUk/N7FCv0cbcD5Fjm07dwSxtp2bimA58al2DqfeZ/2Kd9hF/PMXbftXlNgXa1atX5Zb8DWN1znpy+LSCnExWJhhS5CCBYktVqt9PXXX1uKDnWQqfIEG0Uevri4sPMB4cPhYKALQyUliOAt6iYvFgsDWF8ooxRkSkA1HpsC3tKxKRDms5K1pDYPKcb1OT7ZU1jvWwC+dJ4ulnmqxfOdIqvHn5Uw3mrVqn156xXYAnwwROoRr1YrNc1r1x4CkIhM3u12+vjxo3XUWS6X5vv1pRVpOICcTPnGzWZjxTOQp2lEIMkYcwhBu93O0onwA5/CqKR2X12OxeRexF3ML75mKfDl5myzU6Th1PVK5OI2P3Dq3JxEm/Ind6099xzbPisFzK5nUXrtz9l0VKtW7ZdnvQHbEIL5WrHz83OLIKa3LaUXYb/7/V4fP340ORjWigS9XC5NEkZ+JriKCGPO22639vnFxYV2u501K7i6utJms7FSjYAsa5fKgmPajud8rm3jS+fzz7aEBZaAXdt6u+ZM+SlLZdzc8TZZNgViKXBuu7cSS31Pqfm7NkmnqA65jVu1atX6Z70CW9in9NJjlsYEm83mKOXm4eFBw+HQApoGg4EFOPnKTyG8dAmizjLS8eFwsEAscmmRpkej0VH/Wzr40GAe5rvZbFrvAeuSI3MMNge0bQFJp8q+MUC9BQjbAK7UT3yqZJpaY2ngUNvnKSZ5iiz7ORsIP75Ujo4ZuPcbt629WrVq/bHegO3Z2ZnG47EFSF1eXpqUC8iNRiNjm7BXH+xEQBSs9fHxUe/evdP19bX5eJF+8e36DkKcy9/I1QRbcZ22QKiUlch7pzDZU39PseXcxiAlt6Y+5/cc+KTYWQwcJcysa3PSNjZefxfgt4Fg7rwcg8/93rbG1Maga4OQu+dq1ap9WesV2IYQTM6dz+dqmkbj8ViPj496enqy8orUJKYO8ocPH7Tf7zUej3V1dWVzXFxcWBMDZF98uDBUZGNk56ZprBUe16VRgU/rOcVXGI+LLScdxnN3HTvl89S1ckBQ8nnq+im5t2uenMTadp34eKnPs2tc16al6ztvY79d/1eqD7ZatX83rDdgC8gRAPXw8GB1ji8uLkz2JaeV5gNPT0+6u7tT07yUTqRxwO3trQaDgUUTE9EM68UPS4Qycz8/P1ud5IuLC2O1BGu1yZenMK3UvXcx4Le8cGPZsfScrnWWAF8bM+xicP78kvW0je/62183tpJ5cmz/1A2VP17i8/4uNlbVqlX7MlbUz/b7sBBeAqQIQiJlJ65NfHl5aQUqyHUN4SV3dr1eWx7u7e2tvVR9ag+dgobDocnVvkvPbrez9B+KYdBcwINpqewJo+Z3/9Pfe9vvbTJm6ry3mJ8vtTaOpXy88bhT1/S5m4AUK8wBVHz8VPZ/ykai7bnmnvVbrQJttWr9tl4xW/JiYaTYbrfTdDrVdDrVw8OD7u7u7IVJ+o70IkVPp1O9f/9eIbyk6dCVBx+tB3BSeohq9sAOMOPfLb2HHCttY75dPtHUuC7ptGSNJf4/jqWu3zZfDHQ5lthlqWfRttY2/3FuU9R2/6Vra5u/bUPW9vepCsipLLpatWr9s96ALex0NBpZOcbhcPitSlA+IhggHQwG2u12+ulPf6qzszPN53OtVisD2KZpLGWIxgQw4RCCpfzgC8Y/SzWpOCWpS0b241Ljc4DRxpzanlfqeG5Npay0S9pOgUrqGqk1lV7Hf17Kcv2xeHNwyndY+sy6JOHc+aeAZwXaatV+eNYbsCUaGUZL83eYq3+RkaYzHA6N8VKBarFY2L+4KQEMFqCmrCPlGCVZdDKBWEQvn/pSLfG9loJM6TX5PF5Dycs/93kXo86B11s3DZ9rqXvPsfrUHG+1kufWZblNQu6catWq9ct6B7ar1eqo1jE/CZhCKqZJAZWnCKb68OGD7u/vbTzRxz6KmfkkHdVcBpgBX8aUMKnPYXddwNQmj5ZcN8eaSl/ibfPnzjklwOlzxnZZF8Mvmb8LhHMydtd6/Dy5e4vXX3J+Zb7VqvXPegO2IQSTheMKT+S8Pj8/W3oPxSdWq5U+fvyo7Xar5+dn62f79PSks7MzLRYLa5kHiNITd7/fa7PZGJumMYEvw8ja2izHILperCUyZom0eyr4+eedu268Zj8mBxDxxiHFdrt+77JSGT63jtT9xnPFf6fuMbXOeD05UE/5qEu+w+rLrVatv9YbsJVepGOAdDgc6uPHj9rv92qaxipL3dzc6PHx0aKWN5uNFouFgevDw4Pm87mWy6VFIe92O/t9NBpJkvb7vTUTIK2HXF7MvyTbLAdQqRdq/LMN8HJMpW3+Ugm49LO3yJ1d55Qw7hwAx5uKtvNzAJu7lxRgl95TKYOO/z+95fmXKBlVRq5WrX/WK7AlEAo/LX7UpmnMJytJX3/9tVarlcnDFxcXen5+1v39veXhPj8/a7FYSNJRn9ynpyfd399b0wJ8wPv9vtU/661Las2x1i6W5K1tDo6fAp6n+Pm67ulzxpYwQD9PylLPkc/eypBLpNnc2BTQxiB8imycWk/uGrn/U9WqVfuy1ps8W+m1zR4pNwCk9PIiubu702Kx0H6/t9xX6cXf+/j4aBHIFMWQpKurKytm0TSNde05HA6SXlN8kJIZ51/iXWBRyuK6GEcb6yl9gcZzp0Ap9XfqWO6e42eUusdSAIiflZ8rxVZLGWjq2Z8Kel2W+g793ykG+pbvMP6/VllttWr9tF4x26ZpzG+KT/Xu7k5nZ2e6vLy0ZgQ0a18ulxZNPJ/PLeKYOsej0cheSNQ4JggKyRmgPcXfWeonS70Mc4y25Fib5dZ5inRa+nk8po3dlbDE3LPMredU1u3/jucs+Q5LJeO3fodd/9fe8h1Wq1atP9YrsCXX9fHx0YKe1uu1VXkaDAYKIZgEfHd3ZxHK6/Va0mvKEFHMNBAgN/f5+Vnn5+fGcOPqUNJp0ZzfxYu05Pxfxrpy408B31wAT5ulAOvU7+CtY2IG+F09167v8xT5+NR1vWV8tWrVvj/rDdg2TaPHx0dr/L7ZbLRerw08n56eNJ/PNR6PtdlsdH9/b31sJVmbvBCCxuOxzs7O7HMA16f8hBDsXL+GnE+ubc0p5pobE/+e80PG55xqn+OvLZ3nlLGf4xMvGcd6Ur7OrmcRy+OnrL9rbPz/o/Q5VMZardoP33oHtkQOS7IgJ/Jun56e9G//7b/VbrfTx48fjaVKspZ7+HtXq5W10KPqFAzXg27bOkpeyP5n22c5H2Zb8FPbHKXraRvX5uNsA0XGxODUFZjTdo229cd/54C5C8xLA6hK/Jal86TuJff95tZdwnzj/xu5TVmpnF6tWrUva70BW+m1kftyudRut9N8PrduPeTR0qnn+vrajuGrJSrZd+ih648kA9/n5+eTgoFydioLjK/T9sLOvZxT8m0KoEt9fvE8OXB4ywagiy3y2alSa2pMDgTbNhTx/KfI6l2Kxls2S/G98B22zVsBt1q1/luvwJbyiKvVSovFwsopjsdjNU1j7JXayU3TGAs+Pz83sCbwab1eWxqQJG02GwuywnJgWcKoSlnwKXPkAK4UcEoBLHWdzwW9lITa5Qsu2bicMuaU51/ic227fts6cipCyfj4nFO+/2rVqvXPegW20suL5erqyhq6U2ji4uLCWCppO1SGgrFut1tjxQBvXK6xBNi6ZLvYSgKsTp3n/2vvXIMtK6o7/l/n3NfIWA4oEMLLIKjBMhJDCBqSQqygEg18MGpCkKSwqFh+0CqrfEfLJFbFVEqMKTUxJoLxFTUaCZiUI6JJJaKCImAERQPhPQLzujNz5746H/bubd9mrdWrzz13zr6T9as6dfejH2t3n9v/Xqv32Ztbt5XqKQmSVpdUpkWAtNB1qQ2sWNqt5vrS9FqbSRGE/Lzm4a63PUp9kHrvLsKO0296JbbD4RAzMzPYs2dP95SoeJPUli1bupe6HzhwAFNTU503u3fv3u7ZyFGM45OniKgLNaeeFTeYSmuppXBgyRuq8VylPDGfVJ4lP2eDNZ2VUvraEDTn/Vn60NLmVmoFftQ6ayYTo9bhOM5k6NVDLaKXGr1RIupugIo3PMW12eFwiN27d2P37t3Yt2/fmodcxJ8PRaFdXFzs8td4c+MYyNKQbiyb287zSOctgi+FMLV6S2ucXJo0NFyyW7KtlM466Sh5sfm1WOvPkdoy/77kbVZqcylKoO1r6R3H6Re9EdsQQveTn+XlZUxPT3ev1ot3DocQumcnx4de5K/Hi4P/7Oxs98CKhYWFNe+k1UQh9ZBSIVnPdaVwApEfT+3QyrIihaY5710TeEn4xulFpuKktX8p/J+WN0q41VpvPpnKj3Ntx/V5qQ1r9x3H6Re9CiPHl8PHlwOkdw1HrzR9XGMU2/iC+XSAi2HjwWBQ9NokL1dbq5P247FYhhTa5bznUj6LINdgCVmWQus56WRFS1eyqSY0rq1lW2yoXUPXQtaWvi99fxzHOfzondguLi52P/uJNzlFDh48uOZnPCE0N1BNT093N09FgU6fRpV6tZp45VjEqCSgWjoujSXMPAqWG344W3NR4dZL82tI/1omJ+lxqX+sQivZo1EzCbJcP9eH2vqyFUsZHk52nH7SmzAygE4844Mn4mvzoqd64MABDIdDDAaD7nz8LC8vd2u5+dptKrZcnel27Xpmep4LKZbW7EphZq1MTjClaygJbawrrc8S7pTaL25LYVYJixeap5dCzyURktZBuTpyoeXKkdqL83K1SYfWh2m7ctfoXrLj9JPeeLZxkIjCGJ9rHEKzlhs917m5uS7MHEPL0YuNxLuYQwjdcW29MvdmpLVMS3g0H4zzsKiUlrNPC6Vqnqo1bJp7rJLNnB21SNeX25OjibXWBlIfcmVz0QqpPSzXqfVh3uec/TX1WCMHjuNMlt6ILfDYG4ZCCN0jFkNobo6Kb+iJRG84inN8qEXMo4VENTss+5qAWMrNbeLSciKqDa4lWyRR1gRJKkMSFm4iI01WSiJjmVRoEx/tOuLxfNLBefhaWTV9yJVhmUxI+WomWY7jTI5eie1gMOjeaRvDv9EzjX8XFhbWiHB8NGP6ovnBoImOj+I1aIN7nl8a+LQwIYdVrC02c7ZJ6fOJjTYJ4cShJNylerlyre2tUerDHIuQltCuS6qv9L209GG+Hfcdx+kXvRHbdKCPwjkcDjE1NdWFi+NL3+fn5ztRTQeWGE5OfyqUC4gmNHE/tckqgDVilzOKnXkay1pgbltJyEYJVZe8PK09rXaXQuyj9qFkT+2kKbXdYqcWKSiVF/PXhqEdxzm09O4GqejBLi8vd14uET3mZqcotIPBoHtyVAihe4k8IIfquDCnRK1oavvSOc2rSUVYEyluYC6l0WzK69M8+lq4dpLKiXZzE480v3b9JQ+xxjZpmyvDOqnhznEetdVbdhynf/RGbImo82SnphqHO4aRDxw4gMXFxe4O5Onp6TXn46v2du7cyb46L5/15588bS3cOmSpzPXWq4kTV37MkwulRZQ027SJQrrmmdbPeb0lr5bz9KVrHSWEL9mep7F69+ulJgIQ+5EL0zuO0w96I7ZAM4jEZyLH7fiYxfhzn+jtRpGNj3CMD7iQytUEMB9YOZHgBrB0gJPKSv/WeL4SnNhIadJBmLMjLcMiqFybaW1jCWvmZWplaZOFmj60eLNpWZMgbXPO9txGSwTEcZzJ0RuxjQNEFNEooPGuYqB5QfzWrVu739PGV+nFvzXh4BoPRRKlXPC0MOeoNkgCoZEKU62g5vWW7JWiA5x3W/JA87KktU0ufd7mXF6uHGmyxAl2vm2lNDGR8nB96ELqOJuTXolt/PkOEXW/sZ2amgIRdW/yiT/9ISLMzs52wjw/P2+qRxpArYOgdW1wvWtokkCX0nO2cGuI6w1ba+uVFk+WC3mux6aa0LFWjib2+bZWTro/Sn5pIjeKHY7jTJ7eiC2ALlQ8OzvbPSkqhObRi/FnPgsLC1haWsJgMOj24yMcOaRBSlr/S9NYBi1NuKQ1Sq7s0vqp5JVJ6bm83DFpoqF54TXriXn4V/oreb5WG0uRAQktHF/KL60pWyIZXNm1fThKOY7jTIbeiG30bAGs+Y1t+lo8AN2LCqLAHjx4sPvtrVRuCidQ0lqkddBKB9lcAEprkOm+JjZavRL5ep9Ubm0IW5qMWELeNf1UmmBI5a5nzZXrQ67evA+lMK/WJpZJndaH7sE6zuahd2Ibn3Uc39oTBTc+I3kwGHTebPqighph1I7lnliOJhZa6JarzxLWzdc/S14MJ+CcsKfnNVEthY+1dVJu/ZNroxrP2uJR1wisJfxea482ceDqL52T+lCy2UXYcfpH78Q2ercxfBwHkvhb2vn5+TU3RqWv4cuRBp6adULr4GUJ5VnWPbW68kGXs1ESPM2uUYQgz1vyOEuTDktfpcekaIRkg9Wjls5Zvic15y3fS0sfWiYqjuNMnt6IbfxZD4DOu40/8Yl3JS8uLmJubq777e2uXbvUN/qM6gXl50vprSFnaT3Tml4rp2RXaf0wPZZ7pDXtWAqN5/bV2hSPWfokvY5S/0gCbiEPKaf5NW8/tz1Nw21b+r30nXIcZzL0RmyBZqBI12njb2iJaM2jGDlPprQ2KXk/lnXGPK1UjmVtLU/HhZTzNtGuUbNNCjGXrkUTMikMHD/SOquWVrIxv5Za77kkwnna1MMulaVdsxbmtfSJNSQufa/ds3Wc/tGrZyOnj2CML5JPf0e7sLAAANi3b18nyGl+rkztmOY15Oel9bI0b+rh1HiUkiepDdradY3ifUv1SoN4qe0423IbLKKWX5clj1TnqBEIa52cN69dszTJKU2WNK/YcZx+0hvPNh2k4m9nU4FbWVkBgO5hF3HfgrQ+Jg16UtrUxjRvadAs2cSVa6G0nskJpeQ9caKWpiuFK0trkJINtSFPzrOW6s9tkdq21E+WfKMIuRTelq6Rm/g5jrM56JXY5jdIReL20tIS9uzZw+ZN06UhPot3KoVG0/PSwFbjXWjesVavJCqS96mVbRUrKaRa04ac/XlabvIitUdt/VIfWrCL0AUAABieSURBVOzJ24azS5qg1PShdow7n0/MXHAdZ3PQO7GN20S05re2CwsL2L9/f+fR5sIa86X502P5ec2OUthQGjgtHhInXpr4pnVbwruczZKglSYKkucVz2kTkPS6ShMLbmJU8u606EHJG88FkBNTSYAl+7hzlgmadEzqO6lOF13H6Te9E9vBYNC99QdAd1fycDhcI7ScsHJlltBCrpZyNU/DOqjmYVtt4M7FgPMctWvjznNppHI54eHQRJa7Ri2kapkcaee5/bzfJCGWJl+ajdLkT+uH0jmpL3I7HcfpJ70T2+jFxp/0hBCwuLjYPRM5pk2RPBTL4GPxdrl60r/5NrdvCXOm21r+/Ljk3ZQ8Ws2z5QREstfSzrkXJnlqlpBrjqXvpLqkcrQJUMmuUn9w6bU83ITD0oeO4/SH3ogt0AwWMXQc7z5eWFjAysrKmkcyah5bSTxrvAtu4CsJZI14a5MGi5eXi9Io4cu8fknsLN6lVYBqvVHOTm7bsp+WL02AaoRMq4/Lo00mLG1TwjrJdBzn0NIbsU2FJD6uMX1XbXxSVDogSetaFoGIpGm19JZ02oBcEtI0vxQ6ltKXvEbJlrzs3IuqGfy1iYCUXqs7Tye1X1pOzbVbPEUpr5ZemkDl18lhnahJEZx4/e7hOk7/6I3YAs0gE1+pR9S8Qm9ubm7N+2olQYpwAmEZZCV7LOkkrzgXaKt4ceFeyWORQpWaQFuEWZvM5NeX25KLvxYN4GyVBErqW81TzeuzClHu5ac2SDZrXnSaJ28Pa9/m15GLq4us4/SX3ont8vIyhsNh967avXv3di8bkCh5HPlAuRF2S54aJ/SlkCQ3qEteYy6e6fFaNA8x96C4vFrbc/VIx9br+VnTcLZIbSvZwIlx3k5av+b1aBPDUa7HcZx+0BuxjQNL/PnP4uIiVlZWMDMzw3ozab5ar1NDW0+zXkN+rOTdpGktwpwO6pJwWWznJgjpX87DTL2pWkHjRCfuc2VxbSV58pb0XHvl+WsEnZuUcJ5m3q/SdyK3ibsOrr+sYXTHcSZHb8QWQPcaPQCYnp7uHt8IjHbXpRRmKwleaZurxyLG3GAuCRpHyWPkQouS7ZZQdirqFm+8VMd6+jDPp/Wd1odavZoAavVZ+r/UfpK9+bbVfsdx+kWvxBZ4bEgtfapUTurdWQZHrq40rWXdTBp0JZGU7JBETPNmOFukMCdXF5eOszufFJQG+NLkoBRGHnW9kyuz5A2WkCYP2mRC81RLNtSE2S2TMMdx+klvxDYVrLg9MzMDQF8jlAY6aS0znsvDcaknl5cjhek0r0Q7n3ufmhByf7m20ASlFKaVPGTJthpvXLInrz9v11I4XQuBc3ktnjxXjybuJZs1+/M8mg3x2CgRCsdx+kFvxDaSvtc2hND97jZnlNm8trYlCZu2jpeGWSU4QdXKyYXBOpiO0h41ApznK60zalEHi82S6HH9oqXh0loiBPn59Dq070+NV6qF+2v73UXXcfpN78Q2DuTp6/ZKIVpJEPNQbe7plMRAqi8vu0Z0Leeta5vcxKBkfynUzXmdUlqunDz8zLWP1QbNjtz7tobUpbK067NGGLTjWlSC2y9NDqx1O47TD3oltumAEV8Uv7y8vObRjfmArQ3glnW2VAy4OnLhk8LUXFg4F3XJTs1eznYtxKvVkduYi5QUCrXYWvIOuXSlNil5+mn4XxInzavlJh+SqFsmVNY2SO2wTBBKaazfL8dxJkcvxTY+NWr//v3d4xrj+XyAtXgb3AAN8IKT1xEpraflcKIuDcbcQMkdkzx0iz15fdZ1QU1gtLBqbntumxSN4GzkPH1uQpOnybdL3q/mQXKiztkr9aE2MaqJrqRla98Nx3H6Ra/ENhJC6B5ksbS01D09Kp7jBDSe4yiF97j80qBc8ozScvNrGgWLh1lbdj6xSOFEoRTiLoklJ1SlPtSuW7PREjnI6yiFofPoh1S29fuXX3eNQOaTuBpv2nGcydFLsV1dXe1+8rOystJ5tiWs4ck8jTTA5+G5koBIQlxKW+v1cse1a5Y8Z6vXKqHVpYV/pe2Yr2QH5xVygplfIyeyeZ2lPpRs0jxfboLIlaO1i7VfHcfpJ1PlJIeOOFgNBoNuvdbiVXDUzPg1z1dKo4WTOVHObavJq5VXGzIuhUPzEHXa9pYQLOe9ljxcjVJ4lLNTKlvb5yY8Uvi6VJfUX9K1WL6nlj50L9dx+kuvPNs4iK2urmJ5eRnz8/NrvFrNc5DKKoV5tTW4/O84BL8kvlyIVxJazfNO02vhWotXJYXQc7QJSImS18eVWxIxrqwar5rLU0obz5UmNWkZuX2cjWnZWgTGcZx+0juxjb+xnZ2dxezsLIDyjS2jrrVpAxQnUhah5zwZSUwl+6Xycy8zX7dLJxi5HZKXqgk6165S6LXWw9bKy+1aj5Bofcj1TylPej61TfOKtfLz9ub6lasrJc3jOE4/6ZXYpkSPNn1eckqNJ5QOqpzwpWVYBDZNbwkJcoJh2a/xHiURLR2Xypc85lJ7aIKQH5dEuhSi1ajtw5hG+15I9pYmGVJ7WEWZ60MPFTvO5qRXYpvO0OPdyGkY2SKo1oFSqz/NU/J+RyH1MjXPzuKZc/ktdknh5PR8HgrNhVKy3YKlXaWoQSlv7gWWJjYWm7i0WhumbWeZtEXbS3Di7CFkx+k/vRNboLkbeTgcYsuWLY85n4dMa7B6j2l96xUSLuTICZlmn+SBl/Jb0CYp2oSAqzs9Vjux0WwrHZcmX1wbSeXW2JN//7iJkRRN4WwetQ+tbe04zuTpldgCPx24hsMhlpaWMD09/ZjzOZYByrquNQ4vodbLrPUQpevQvHrLMakuDa0cTmhqbKy1paasmnTWtDUhXutEoqZ+x3H6S6/Eloi639fGbUu4sXZNL82feyDamqa2JlnKI4Vpc/vzetY7+HLXOAqct57ax10DNymwrEXnbaaFgWvXUaU6Ndti2tLEQfK41xuFsUYwXJAdp7/0TmyBZtBYWlrCyspKt3ZrgROEmnUtTQBzGy2DbzwmedXSAGpZr7WEUqVy14u1bmt+riwuJM2F1bk2lcLvGtLkgLO7dqLDTQgkG/K6uPS1XrHjOJOnd2KbDrArKytVA4i0ZpgOdjXrhLWeTAmLl16yR/KecyHg1g4t9UleuEWELOWvZy3XOllIRW5c4XIprXRzlKVsKZ3Wh9ZwtuM4/cIktkR0FxHdSkQ3E9GN7bGjiGg7Ef2w/Xtke5yI6H1EdCcR3UJEz7YaE0PHRM2L4+fm5rrf3eZog1tepoQlXKvlrYWro2bNsyRgNaFtq415OJeLGJTqsHhy6xEIq/c/ShmldJznqk2QSv1Zasta79pxnH5Q49k+L4RwRgjhzHb/TQCuCyGcBuC6dh8AXgTgtPZzOYAPWitIB5LV1VUsLCyw6WpDhKN4SppA5J5kzcBXWm9M/9aEnkvh1TydFl7Py0mjArm4SG1YsiW3g7seblsqx4rkiVrXVaVrlSYf+XJA6TsnRWe4dOm+ZVLmOM7kWE8Y+UIAV7XbVwG4KDn+0dBwA4BtRHScpcDUs40DyOrqqmlg1NZrS5QEJ02TD55pWskL5MrlBkwpBC5hEVdp4JaETmtX7hpyrIJZErdaD87iwedtLH2vNE/eUj733Sl5sdqkQerD9URmHMc5tFjFNgD4EhHdRESXt8eODSE80G4/CODYdvt4APckee9tj5WNGQwwHA4xGAy6N//kXmRE8r5SNM8pT5efl+rNz0mCx4kyV6dkgxSylUgH3RqvNb8erj7Na+PK57x/i/fLeWuaJ5iWIX1HrH0o9ac06bLaz9XLCaTUb1ofltrGcZz+YH3rzzkhhPuI6BgA24no9vRkCCEQUdUiUivalwPASSedBAAYDocYDocgam6Omp6eZgenUuiQG8QkL1LKpx3P7ZA8plEGw7wca35ORC15NY83Fyqrx5a3T16mtX20c+PqQy2t1L8We6TvqvQ91K5H84xdcB1nc2DybEMI97V/dwD4PICzADxEbXi4/bujTX4fgBOT7Ce0x/IyPxRCODOEcObRRx/dGNN6tsPhEFNTU92jGvMBJQ/3lbAOmIltoleaeh9cedwAWCpHs1vKV8prIW/D3CMt2VG6RklYJa9f8ho5z1ryWLk8teR1aN+FtM1KkQTrOevEIG0DKfrgOE4/KIotER1BRI+P2wDOB3AbgKsBXNomuxTAF9rtqwG8khrOBrA7CTerTE1NdSK7srKCAwcOYHV1tTtfCmFqYTvOKysNTJInZ/U4LR6hFqbk7JG8pFFIRY/zQjmkayrlk+rnys/LkcKmFpGz1iFR6sN8ElGDZMco7eihZcfpN5Yw8rEAPt/+A08B+EQI4d+I6FsAPk1ElwG4G8DL2vRfBHABgDsB7AfwB1Zj0gFjdna2CykDfJhNGvBLXqeUXxpY03PS+dwGadCTQtpaqFCrVxP+vGytLi5ykF9Pmq4mxGqxNS9bK4OzVztvPcddR94WUp2j9CH3fU2P5xMJ7bvsOE6/KYptCOHHAJ7FHH8EwPOZ4wHAa0YxZjgcYnp6GsPhECEEzMzMYHZ2Fvv371cH+RzNC+HSaKFfaeDTkAZFSeTygb40KSiVnV+P9FebFGjlSnZy9kntIrWH5Zw2kVpvNGIULN+NksBzoWspX1qn1E+O4/SLXj1BKq7XRqamprowsjQYpefS49z6XppeypMeG8Vzk+zR0mt5LJ6gtq2FTDWhs9jCtbWGJr5c23N50vryPFIIusbjlELSpb7XbLZOCrX2rPluucfrOP2jd2I7GDQmxZ/9RLEtDYYp3OBqGQBHHaSk0HWpTilEWbOeaPGopLKl/LXtkAtNek3SNdbWmbaxNPnRrlWqU+ojTtw027gyrHCRDCk6wtnsIWXH6T+9Etv4xh+geaft8vKyum4lIYVLuW3Ju6ytzyrelsHb4nFq9Wr1aIN6Ka8kQKX+SfuwNsSZ9qUUji9FCDQBtoaq1yO+pXPSxFCapJT2HcfpH70S2zSMPD093T0bmRusawY0aZBOz+XbeV1SOFPb59Jza3QlL5y7jhKawJXEtOSZax665GWl4dxa4S2Fn2v6sDQ5KbU9Z3+N2EltK00SRu1Dx3H6BfXhn5OI9gK4Y9J2HGY8CcDDkzbiMMPbdPx4m44fb9PxY23Tk0MIR3MnrE+Q2mjuCD99wYEzBojoRm/T8eJtOn68TcePt+n4GUeb9iqM7DiO4ziHIy62juM4jrPB9EVsPzRpAw5DvE3Hj7fp+PE2HT/epuNn3W3aixukHMdxHOdwpi+ereM4juMctrjYOo7jOM4GM3GxJaIXEtEdRHQnEb1p0vZsFojo74loBxHdlhw7ioi2E9EP279HtseJiN7XtvEtRPTsyVneX4joRCK6noj+m4i+R0SvbY97u44IEc0R0TeJ6Lttm76zPf5zRPSNtu3+kYhm2uOz7f6d7fknT9L+vkJEQyL6DhFd0+57e64TIrqLiG4lopuJ6Mb22Nj+9ycqtkQ0BPB+AC8CcDqA3yGi0ydp0ybiSgAvzI69CcB1IYTTAFzX7gNN+57Wfi4H8MFDZONmYxnA60MIpwM4G8Br2u+jt+voHARwXgjhWQDOAPBCat5z/W4AV4QQTgWwE8BlbfrLAOxsj1/RpnMey2sBfD/Z9/YcD88LIZyR/KZ2bP/7k/ZszwJwZwjhxyGERQCfAnDhhG3aFIQQ/h3Ao9nhCwFc1W5fBeCi5PhHQ8MNALYR0XGHxtLNQwjhgRDCt9vtvWgGs+Ph7ToybdvMt7vT7ScAOA/AZ9vjeZvGtv4sgOeTP/x5DUR0AoDfBPDhdp/g7blRjO1/f9JiezyAe5L9e9tjzmgcG0J4oN1+EMCx7ba3cyVtuO0XAXwD3q7rog153gxgB4DtAH4EYFcIYblNkrZb16bt+d0AnnhoLe497wXwBgCr7f4T4e05DgKALxHRTUR0eXtsbP/7fXlcozNmQgiBiPx3XSNARFsB/BOA14UQ9mQvPvB2rSSEsALgDCLaBuDzAJ4+YZM2LUT0YgA7Qgg3EdG5k7bnMOOcEMJ9RHQMgO1EdHt6cr3/+5P2bO8DcGKyf0J7zBmNh2Ioo/27oz3u7WyEiKbRCO3HQwifaw97u46BEMIuANcDeA6asFuc7Kft1rVpe/4JAB45xKb2mV8F8FtEdBeaZbfzAPwlvD3XTQjhvvbvDjSTwrMwxv/9SYvttwCc1t5JNwPgFQCunrBNm5mrAVzabl8K4AvJ8Ve2d9CdDWB3EhpxWtq1rL8D8P0QwnuSU96uI0JER7ceLYhoC4DfQLMWfj2Al7bJ8jaNbf1SAF8J/uSdjhDCm0MIJ4QQnoxmvPxKCOFieHuuCyI6gogeH7cBnA/gNozzfz++53NSHwAXAPgBmnWct07ans3yAfBJAA8AWEKzXnAZmrWY6wD8EMCXARzVpiU0d33/CMCtAM6ctP19/AA4B826zS0Abm4/F3i7rqtNfwHAd9o2vQ3A29vjpwD4JoA7AXwGwGx7fK7dv7M9f8qkr6GvHwDnArjG23MsbXkKgO+2n+9FLRrn/74/rtFxHMdxNphJh5Edx3Ec57DHxdZxHMdxNhgXW8dxHMfZYFxsHcdxHGeDcbF1HMdxnA3GxdZxHMdxNhgXW8dxHMfZYFxsHcdxHGeDcbF1HMdxnA3GxdZxHMdxNhgXW8dxHMfZYFxsHecQQESvJqKHiGieiP5fvLy7vdZTJm2H4/QBfxGB4xho3x96LIAVNG9a+i8AfxhCuMeQdxrAHgBnhxC+u5F2Oo7TT9yzdRw7LwkhbAVwHICHAPyVMd+xaF519r3aCtv3ZW7I/2nysnHHcTYYF1vHqSSEsADgswBOj8eIaJaI/oKI/rcNF/81EW0hoqcCuKNNtouIvtKmfy4RfYuIdrd/n5uU9VUiehcR/SeA/QBOIaKnE9F2InqUiO4gopdJ9hHRUUT0ESK6n4h2EtE/t8fPJaJ7ieiNRPQggI+0dr+3TXt/uz2bpX8LET1MRHcR0cVJPVe217mdiPYS0deI6OTkfCCiU5O07yeia9u03yCipyRpz2+vazcRfaAt61Xr6CbH6RUuto5TCRE9DsDLAdyQHP4zAE8FcAaAUwEcj+ZF6T8A8Iw2zbYQwnlEdBSAawG8D83Lqd8D4NpsLfcSAJcDeDyAnwDYDuATAI4B8AoAHyCi08HzDwAe19Z7DIArknM/A+AoACe35b8VwNmt3c8CcBaAt2Xpn9Rez6UAPkRET0vOXwzgT9o0NwP4uGATWrvfCeBINC8zfxcAENGT0Exe3ty2xx0AniuU4Tibk414671//HO4fQDcBWAewC40a7b3A3hme44A7APwlCT9cwD8T7v9ZAABwFS7fwmAb2blfx3A77fbXwXwx8m5lwP4jyz93wB4B2PncQBWARzJnDsXwCKAueTYjwBckOy/AMBdSfplAEck5z8N4I/a7SsBfCo5txXNmvaJ7X4AcGqS9sNJ2gsA3N5uvxLA15NzBOAeAK+adL/7xz/j+viajePYuSiE8GUiGgK4EMDXWu9yFY0neRMRxbQEYCiU87MA7s6O3Y3Ge4ykN16dDOBXiGhXcmwKjQebcyKAR0MIO4W6fxKaMLhky93tscjOEMI+5XxnZwhhnogebc9zN449mGzvRyPO0Ya0nEBE9wr2O86mxMPIjlNJCGElhPA5NF7cOQAeBnAAwDNCCNvazxNCczMVx/1oBDTlJAD3pdUk2/cA+FpS9rYQwtYQwquZsu8BcBQRbZPML9hyUnssciQRHaGcPzFuENFWNCHq9LyFBwCckJRD6b7jHA642DpOJe0dwheiWXv8fghhFcDfAriCiI5p0xxPRC8QivgigKcS0e8S0RQRvRzNzVbXCOmvadNfQkTT7eeXiejn84QhhAcA/CuaNd0j27S/rlzOJwG8jYiObtdO3w7gY1madxLRDBH9GoAXA/hMcu4CIjqHiGbQrN3eEAw/h8q4FsAzieii9g7p16BZK3acwwYXW8ex8y9ENI/mN7PvAnBpCCH+nOeNaG76uYGI9gD4MoCncYWEEB5BI1qvB/AIgDcAeHEI4WEh/V4A56O5weh+NOHYdwOYFey8BM268u0AdgB4nXJNfwrgRgC3ALgVwLfbY5EHAexs6/04mt8W356c/wSAdwB4FMAvAfg9pS6W9rp/G8Cfo2mP01ubDtaW5Th9xR9q4TgOCxGdC+BjIQQ2pEtEVwK4N4TwNu78OuodALgXwMUhhOvHWbbjTAr3bB3HmThE9AIi2tb+xvctaG4wu6GQzXE2DS62juP0geeg+RnSwwBegubO7wOTNclxxoeHkR3HcRxng3HP1nEcx3E2GBdbx3Ecx9lgXGwdx3EcZ4NxsXUcx3GcDcbF1nEcx3E2GBdbx3Ecx9lg/g/K+sbWjlA7vgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize = (50,8))\n",
        "plt.imshow(res_x.numpy(), cmap=\"gray\")\n",
        "plt.title(f\"Before cropping \", x=0.5, y=-0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "pVcmbNaQZDTX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "4102865b-b8f8-40b7-ad39-539d988b9fc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 512, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3600x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize = (50,8))\n",
        "plt.imshow(res_y.numpy()[:,:,0], cmap=\"gray\")\n",
        "plt.title(f\"Before cropping \", x=0.5, y=-0.1)\n",
        "print(res_x.numpy().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "teGKIGb0IhFK"
      },
      "outputs": [],
      "source": [
        "# res_y.numpy()[:,:,0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Qis1l2Zd_1a7"
      },
      "outputs": [],
      "source": [
        "# res_x.numpy().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "qjA1jjBgTnMf"
      },
      "outputs": [],
      "source": [
        "prediction = unet.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Hs8fB-GcJeq5"
      },
      "outputs": [],
      "source": [
        "# type(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "U10ju5R8Jmxn"
      },
      "outputs": [],
      "source": [
        "# prediction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "pIMrBwBPJj24"
      },
      "outputs": [],
      "source": [
        "# prediction[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "X8GIuGP7Jq0I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "baa9863a-973a-4ada-cf1d-6d08cf9650d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 512, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3600x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize = (50,8))\n",
        "plt.imshow(prediction[i][:,:,0], cmap=\"gray\")\n",
        "plt.title(f\"Before cropping \", x=0.5, y=-0.1)\n",
        "print(res_x.numpy().shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Cbisddsm_final_new_19 (8).ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "instance_type": "ml.m5.large",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}