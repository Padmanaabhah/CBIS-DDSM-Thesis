{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xzc7BJKDBX3y"
      },
      "outputs": [],
      "source": [
        "#pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L6wiaECOBX30"
      },
      "outputs": [],
      "source": [
        "#pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "cXp-5N_yBX30"
      },
      "outputs": [],
      "source": [
        "from distutils import extension\n",
        "from logging import exception\n",
        "import os\n",
        "from datetime import datetime as dt\n",
        "from regex import E\n",
        "from sqlalchemy import intersect\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import numpy as np \n",
        "import pathlib\n",
        "from keras.callbacks import ModelCheckpoint   \n",
        "from keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iQkKItqB1-t",
        "outputId": "876181d6-31b9-400e-c419-629b3ac9a582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQYE2sEYB-uE",
        "outputId": "0f0cc615-74e0-4af1-8189-5accd18fc2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_output_full  Test_output_mask  Train_output_full  Train_output_mask\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/gdrive/MyDrive/cbisddsm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2foFHtBFB_U4"
      },
      "outputs": [],
      "source": [
        "# data_dir_train = pathlib.Path(\"/content/gdrive/MyDrive/Images/Train\")\n",
        "# data_dir_test = pathlib.Path('/content/gdrive/MyDrive/Images/Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zYVMXFDEBX31"
      },
      "outputs": [],
      "source": [
        "seed = 43\n",
        "encoder_input_width = 224\n",
        "encode_input_channels = 3\n",
        "encoder_input_shape = (encoder_input_width, encoder_input_width, encode_input_channels)\n",
        "\n",
        "kernsize = 3\n",
        "decoder_kernel_size = (kernsize, kernsize)\n",
        "stride = 2\n",
        "decoder_strides = (stride, stride)\n",
        "decoder_padding = \"same\"\n",
        "decoder_activation = None\n",
        "final_layer_filters = 1\n",
        "final_layer_activation = \"sigmoid\"\n",
        "\n",
        "train_full_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Train_output_full\"\n",
        "train_mask_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Train_output_mask\"\n",
        "\n",
        "test_full_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Test_output_full\"\n",
        "test_mask_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Test_output_mask\"\n",
        "results_dir = \"/content/results/fit\"\n",
        "extension = \".png\"\n",
        "\n",
        "target_size = (224, 224)\n",
        "\n",
        "brightness_delta = 0.3\n",
        "batch_size = 10\n",
        "\n",
        "validate = False\n",
        "loss = \"binary_crossentropy\"\n",
        "learning_rate = 0.0001\n",
        "dropout = 0.5\n",
        "dropout_training = True\n",
        "num_epochs = 80\n",
        "callback_monitor = \"iouMetric\"\n",
        "callback_mode = \"max\"\n",
        "ckpt_save_weights_only = True\n",
        "ckpt_save_best_only = True\n",
        "earlystop_patience = 200\n",
        "restore_best_weights = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WiJw56KyBX32"
      },
      "outputs": [],
      "source": [
        "# x_paths_list = []\n",
        "# for full in os.listdir(train_full_img_dir):\n",
        "#   if full.endswith(extension):\n",
        "#     x_paths_list.append(os.path.join(train_full_img_dir, full))\n",
        "\n",
        "# print(len(x_paths_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B28GisyHBX32"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JGqSf0kQBX32"
      },
      "outputs": [],
      "source": [
        "def datasetPaths(full_img_dir, mask_img_dir):\n",
        "        try:\n",
        "            x_paths_list = []\n",
        "            y_paths_list = []\n",
        "\n",
        "            for full in os.listdir(full_img_dir):\n",
        "                if full.endswith(extension):\n",
        "                    x_paths_list.append(os.path.join(full_img_dir, full))\n",
        "            \n",
        "            for full in os.listdir(mask_img_dir):\n",
        "                if full.endswith(extension):\n",
        "                    y_paths_list.append(os.path.join(mask_img_dir, full))\n",
        "            \n",
        "            x_paths_list.sort()\n",
        "            y_paths_list.sort()\n",
        "\n",
        "            return x_paths_list, y_paths_list\n",
        "        except Exception as e:\n",
        "            print(f\"Error in datasetPaths {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7u3oVaRTBX33"
      },
      "outputs": [],
      "source": [
        "# def loadFullImg(path, dsize):\n",
        "#         try:\n",
        "#             if not isinstance(path, str):\n",
        "#                 path = path.decode()\n",
        "             \n",
        "            \n",
        "#             s3_client = boto3.resource('s3')\n",
        "#             obj = s3_client.get_object(Bucket='cbisddsm', Key=path)\n",
        "#             nparr = np.frombuffer(obj['Body'].read(), np.uint8)\n",
        "#             img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "#             print(f'type type{img}')\n",
        "#             #bucket = s3_resource.Bucket('cbisddsm')\n",
        "#             #print(f'bucket.Object(path) {bucket.Object(path)}')\n",
        "#             #img = bucket.Object(path).get().get('Body').read()\n",
        "#             #print(f'img {img}')\n",
        "#             #img = cv2.imdecode(np.asarray(bytearray(img)), cv2.IMREAD_COLOR)\n",
        "           \n",
        "            \n",
        "#             #img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "#             img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "#             norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "#             full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "#             print(f'done for path {path}')\n",
        "#             return full_img\n",
        "        \n",
        "#         except Exception as e:\n",
        "#             print(f\"There is an error in loadFullImg {e}\")\n",
        "            \n",
        "\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VQf1GqJeBX34"
      },
      "outputs": [],
      "source": [
        "def loadFullImg(path, dsize):\n",
        "        try:\n",
        "            if not isinstance(path, str):\n",
        "                path = path.decode()\n",
        "            \n",
        "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "            #print(type(img))\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "            #print(f'After norm_img')\n",
        "            #print(f'type {norm_img.shape}')\n",
        "            full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "            #print(f'After full_img')\n",
        "            #print(f'type {full_img.shape}')\n",
        "            #print(f'done for path {path} with shape {full_img.shape}')\n",
        "            return full_img\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"There is an error in loadFullImg {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Yfm6JA2rBX34"
      },
      "outputs": [],
      "source": [
        "# s3 = boto3.resource('s3')\n",
        "# my_bucket = s3.Bucket('cbisddsm')\n",
        "# i = 0\n",
        "# for object_summary in my_bucket.objects.filter(Prefix='Train_output_full'):    \n",
        "#     if i == 0:\n",
        "#         pass\n",
        "#     else:\n",
        "#         print(object_summary.key)\n",
        "#         img = loadFullImg(object_summary.key, target_size)\n",
        "#         print(img.shape)\n",
        "#         #break\n",
        "#     i += 1\n",
        "    \n",
        "    \n",
        "#             #print(object_summary.key)\n",
        "        \n",
        "#             #x_paths_list.append(object_summary.key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KYSP3bIaBX35"
      },
      "outputs": [],
      "source": [
        "def loadMaskImg(path, dsize):\n",
        "        try:\n",
        "            if not isinstance(path, str):\n",
        "                path=path.decode()\n",
        "            \n",
        "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "            mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "            #print(f'done for path {path} with shape {mask_img.shape}')\n",
        "            return mask_img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in loadMaskIMG {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Co4SIeY6BX35"
      },
      "outputs": [],
      "source": [
        "# def loadMaskImg(path, dsize):\n",
        "#         try:\n",
        "#             if not isinstance(path, str):\n",
        "#                 path=path.decode()\n",
        "             \n",
        "#             s3_resource = boto3.resource('s3')\n",
        "#             bucket = s3_resource.Bucket('cbisddsm')\n",
        "# #             bucket = s3_resource.Bucket('cbisddsm')\n",
        "#             img = bucket.Object(path).get().get('Body').read()\n",
        "#             img = cv2.imdecode(np.asarray(bytearray(img)), cv2.IMREAD_COLOR)\n",
        "#             print(f'type type(img)')\n",
        "#             #img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "#             img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "#             norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "#             mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "\n",
        "#             return mask_img\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(\"Error in loadMaskIMG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bawafpnnBX36"
      },
      "outputs": [],
      "source": [
        "def tfParse(x_path, y_path):\n",
        "        try:\n",
        "            def _parse(x_path, y_path):\n",
        "                x = loadFullImg(path=x_path, dsize=target_size)\n",
        "                y = loadMaskImg(path=y_path, dsize=target_size)\n",
        "                return x,y\n",
        "\n",
        "            x, y = tf.numpy_function(_parse, [x_path, y_path], [tf.float64, tf.float64])\n",
        "\n",
        "            x.set_shape([target_size[0], target_size[0], 3])\n",
        "            y.set_shape([target_size[0], target_size[1], 1])\n",
        "\n",
        "            return x,y\n",
        "            \n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in tfParse {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tkHDbxVGBX36"
      },
      "outputs": [],
      "source": [
        "def imgAugment(x_img, y_img):\n",
        "        try:\n",
        "            if tf.random.uniform(()) > 0.5:\n",
        "                x_img = tf.image.flip_up_down(image=x_img)\n",
        "                y_img = tf.image.flip_up_down(image=y_img)\n",
        "\n",
        "            x_img = tf.image.random_brightness(\n",
        "                image=x_img, max_delta=brightness_delta\n",
        "            )\n",
        "\n",
        "            return x_img, y_img\n",
        "\n",
        "        except:\n",
        "            print(\"Erro in imgAugument\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Mge3IsdLBX36"
      },
      "outputs": [],
      "source": [
        " def makeTFDataset( shuffle, augument, x_paths_list, y_paths_list, batch_size):\n",
        "        try:\n",
        "            ds = tf.data.Dataset.from_tensor_slices((x_paths_list, y_paths_list))\n",
        "            \n",
        "            if shuffle:\n",
        "                ds = ds.shuffle(buffer_size=len(x_paths_list))\n",
        "\n",
        "            ds = ds.map(tfParse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "            \n",
        "            if augument:\n",
        "                ds = ds.map(imgAugment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "            ds = ds.batch(batch_size=batch_size, drop_remainder=False)\n",
        "            ds = ds.repeat()\n",
        "\n",
        "            return ds\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in make TFDataset {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9RGLX5MnBX37"
      },
      "outputs": [],
      "source": [
        "def buildEncoder():\n",
        "        try:\n",
        "            VGG16_ = keras.applications.VGG16(\n",
        "                include_top=False, weights=\"imagenet\", input_shape=encoder_input_shape,\n",
        "            )\n",
        "\n",
        "            layer_names = [layer.name for layer in VGG16_.layers]\n",
        "\n",
        "            all_layer_outputs = [\n",
        "               VGG16_.get_layer(layer).output for layer in layer_names\n",
        "            ]\n",
        "\n",
        "            encoder_model = keras.Model(inputs=VGG16_.input, outputs=all_layer_outputs)\n",
        "\n",
        "            encoder_model.trainable = False\n",
        "\n",
        "            return encoder_model \n",
        "        \n",
        "        except Exception as e:\n",
        "            print(\"Error in buildEncoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eNHrykF9BX37"
      },
      "outputs": [],
      "source": [
        "def buildUnet():\n",
        "        try:\n",
        "            unet_input = keras.Input(\n",
        "                shape= encoder_input_shape, name=\"unet_input_layer\"\n",
        "            )\n",
        "\n",
        "            x = unet_input\n",
        "            encoder_model = buildEncoder()\n",
        "            all_encoder_layer_outputs = encoder_model(x)\n",
        "\n",
        "            encoded_img = all_encoder_layer_outputs[-1]\n",
        "\n",
        "            #skip_outputs = [all_encoder_layer_outputs[i] for i in [2, 5,9, 13, 17]]\n",
        "            skip_outputs = [all_encoder_layer_outputs[i] for i in [2, 4, 6, 12, 15]]\n",
        "            \n",
        "            decoder_filters = int(encoded_img.shape[-1])\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 5: 7x7 -> 14x14\n",
        "            #  - `encoded_img` as initial input for decoder\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block5_up_convT\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                activation=decoder_activation,\n",
        "            )(encoded_img)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block5_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[4]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block5_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block5_up_conv3\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(0.01),\n",
        "                bias_regularizer=l2(0.01),\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block5_up_conv2\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(0.01),\n",
        "                bias_regularizer=l2(0.01),\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block5_up_conv1\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 4: 14x14 -> 28x28\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block4_up_convT\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block4_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[3]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block4_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block4_up_conv3\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(0.01),\n",
        "                bias_regularizer=l2(0.01),\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block4_up_conv2\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(0.01),\n",
        "                bias_regularizer=l2(0.01),\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block4_up_conv1\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(0.01),\n",
        "                bias_regularizer=l2(0.01),\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 3: 28x28 -> 56x56\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block3_up_convT\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block3_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[2]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block3_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block3_up_conv3\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block3_up_conv2\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block3_up_conv1\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 2: 56x56 -> 112x112\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block2_up_convT\",\n",
        "                filters=int(decoder_filters / 4),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block2_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[1]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block2_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block2_up_conv2\",\n",
        "                filters=int(decoder_filters / 4),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block2_up_conv1\",\n",
        "                filters=int(decoder_filters / 4),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 1: 112x112 -> 224x224\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block1_up_convT\",\n",
        "                filters=int(decoder_filters / 8),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block1_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[0]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block1_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block1_up_conv2\",\n",
        "                filters=int(decoder_filters / 8),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(0.01),\n",
        "                bias_regularizer=l2(0.01),\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            decoded_img = keras.layers.Conv2D(\n",
        "                name=\"block1_up_conv1\",\n",
        "                filters=int(decoder_filters / 8),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(0.01),\n",
        "                bias_regularizer=l2(0.01),\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Final conv layer\n",
        "            final_img = keras.layers.Conv2D(\n",
        "                name=\"final_up_conv\",\n",
        "                filters=final_layer_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(0.01),\n",
        "                bias_regularizer=l2(0.01),\n",
        "                activation=final_layer_activation,\n",
        "            )(decoded_img)\n",
        "\n",
        "            # ======\n",
        "            #  Unet\n",
        "            # ======\n",
        "\n",
        "            unet = keras.Model(inputs=unet_input, outputs=final_img, name=\"Unet_VGG16\")\n",
        "\n",
        "            return unet\n",
        "        except Exception as e:\n",
        "            print(f\"Error in Build Unet {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_sq8aqBYBX38"
      },
      "outputs": [],
      "source": [
        "def iouMetric( y_true, y_pred):\n",
        "        try:\n",
        "            def compute_iou(y_true, y_pred):\n",
        "                intersection = (y_true * y_pred).sum()\n",
        "                union = y_true.sum() + y_pred.sum() - intersection\n",
        "                x = (intersection + 1e-15) / (union + 1e-15)\n",
        "                x = x.astype(np.float32)\n",
        "                return x\n",
        "            \n",
        "            return tf.numpy_function(compute_iou, [y_true, y_pred], tf.float32)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error in iouMetric {E}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xCkCusvKBCuz"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "        try:\n",
        "            # def dice(true, pred, k = 1):\n",
        "            #     intersection = np.sum(pred[true==k]) * 2.0\n",
        "            #     dice = intersection / (np.sum(pred) + np.sum(true))\n",
        "            #     return dice \n",
        "            # return tf.numpy_function(dice, [y_true, y_pred], tf.double)\n",
        "            \n",
        "            y_true_f = tf.reshape(tf.dtypes.cast(y_true, tf.float32), [-1])\n",
        "            y_pred_f = tf.reshape(tf.dtypes.cast(y_pred, tf.float32), [-1])\n",
        "            intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "            return (2. * intersection + 1.) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + 1.)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in dice_coef {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Egz73rd9BX39"
      },
      "outputs": [],
      "source": [
        "def compile_( model):\n",
        "        try:\n",
        "            loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "            metrics = [\"accuracy\", iouMetric, dice_coef]\n",
        "            model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(f\"Failed at compile_ {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jNa9nYOcCV15"
      },
      "outputs": [],
      "source": [
        " test_x, test_y = datasetPaths(\n",
        "            full_img_dir=test_full_img_dir,\n",
        "            mask_img_dir=test_mask_img_dir\n",
        "        )\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wDDyk7GYCWU3"
      },
      "outputs": [],
      "source": [
        "# def evaluate(path,target_size):\n",
        "#   full_img_lst = []\n",
        "#   print(len(path))\n",
        "#   for imgpath in path:\n",
        "#     full_img = loadFullImg(imgpath, target_size)\n",
        "#     full_img_lst.append(full_img)\n",
        "#     #img = cv2.imread(imgpath, cv2.IMREAD_GRAYSCALE)\n",
        "#     #print(full_img.shape)\n",
        "#   return full_img_lst\n",
        "  \n",
        "# full_img_lst = evaluate(test_x, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pbuTQcYXCbvv"
      },
      "outputs": [],
      "source": [
        "# def evaluate_mask(path,target_size):\n",
        "#   mask_img_lst = []\n",
        "#   print(len(path))\n",
        "#   for imgpath in path:\n",
        "#     mask_img = loadMaskImg(imgpath, target_size)\n",
        "#     mask_img_lst.append(mask_img)\n",
        "#     #img = cv2.imread(imgpath, cv2.IMREAD_GRAYSCALE)\n",
        "#     #print(full_img.shape)\n",
        "#   return mask_img_lst\n",
        "  \n",
        "# mask_img_lst = evaluate(test_y, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_WCc1IIBIety"
      },
      "outputs": [],
      "source": [
        "# img = cv2.imread(test_x[0], cv2.IMREAD_GRAYSCALE)\n",
        "# print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VeQ8YyfqHgYW"
      },
      "outputs": [],
      "source": [
        "# actual_x, actual_y =tfParse(test_x, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "c1hGy4M6FyuV"
      },
      "outputs": [],
      "source": [
        "# full_img_lst[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "agKhRncmBX39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d64d40-3a6a-4114-dc86-8bbb41e7d40d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "\n",
            "Size of training set = 1231\n",
            "Size of test set = 361\n",
            "Number of epochs = 80\n",
            "Batch size = 10\n",
            "Number of training steps per epoch = 124\n",
            "Number of test steps per epoch = 37\n",
            "\n",
            "Epoch 1/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 15.3778 - accuracy: 0.9832 - iouMetric: 0.0017 - dice_coef: 0.0037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 379s 3s/step - loss: 15.3778 - accuracy: 0.9832 - iouMetric: 0.0017 - dice_coef: 0.0037\n",
            "Epoch 2/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 3.1659 - accuracy: 0.9959 - iouMetric: 0.0238 - dice_coef: 0.0464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 223s 2s/step - loss: 3.1659 - accuracy: 0.9959 - iouMetric: 0.0238 - dice_coef: 0.0464\n",
            "Epoch 3/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0728 - accuracy: 0.9959 - iouMetric: 0.0503 - dice_coef: 0.0954"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 224s 2s/step - loss: 1.0728 - accuracy: 0.9959 - iouMetric: 0.0503 - dice_coef: 0.0954\n",
            "Epoch 4/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.6811 - accuracy: 0.9960 - iouMetric: 0.0740 - dice_coef: 0.1372"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 224s 2s/step - loss: 0.6810 - accuracy: 0.9960 - iouMetric: 0.0744 - dice_coef: 0.1379\n",
            "Epoch 5/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.5302 - accuracy: 0.9960 - iouMetric: 0.0876 - dice_coef: 0.1599"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 224s 2s/step - loss: 0.5302 - accuracy: 0.9960 - iouMetric: 0.0870 - dice_coef: 0.1589\n",
            "Epoch 6/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.4307 - accuracy: 0.9961 - iouMetric: 0.0861 - dice_coef: 0.1573"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 222s 2s/step - loss: 0.4307 - accuracy: 0.9961 - iouMetric: 0.0856 - dice_coef: 0.1563\n",
            "Epoch 7/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.9962 - iouMetric: 0.1038 - dice_coef: 0.1867"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 225s 2s/step - loss: 0.3559 - accuracy: 0.9962 - iouMetric: 0.1038 - dice_coef: 0.1867\n",
            "Epoch 8/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.2988 - accuracy: 0.9963 - iouMetric: 0.1112 - dice_coef: 0.1971"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 225s 2s/step - loss: 0.2988 - accuracy: 0.9963 - iouMetric: 0.1133 - dice_coef: 0.2000\n",
            "Epoch 9/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.2537 - accuracy: 0.9964 - iouMetric: 0.1216 - dice_coef: 0.2140"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 223s 2s/step - loss: 0.2537 - accuracy: 0.9964 - iouMetric: 0.1210 - dice_coef: 0.2131\n",
            "Epoch 10/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.2180 - accuracy: 0.9963 - iouMetric: 0.1170 - dice_coef: 0.2072"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 224s 2s/step - loss: 0.2179 - accuracy: 0.9963 - iouMetric: 0.1175 - dice_coef: 0.2080\n",
            "Epoch 11/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.1880 - accuracy: 0.9964 - iouMetric: 0.1277 - dice_coef: 0.2233"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 224s 2s/step - loss: 0.1880 - accuracy: 0.9964 - iouMetric: 0.1285 - dice_coef: 0.2245\n",
            "Epoch 12/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.1633 - accuracy: 0.9965 - iouMetric: 0.1390 - dice_coef: 0.2410"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 225s 2s/step - loss: 0.1634 - accuracy: 0.9965 - iouMetric: 0.1380 - dice_coef: 0.2393\n",
            "Epoch 13/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.1430 - accuracy: 0.9964 - iouMetric: 0.1287 - dice_coef: 0.2253"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 224s 2s/step - loss: 0.1430 - accuracy: 0.9964 - iouMetric: 0.1286 - dice_coef: 0.2252\n",
            "Epoch 14/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.1253 - accuracy: 0.9965 - iouMetric: 0.1378 - dice_coef: 0.2389"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 227s 2s/step - loss: 0.1253 - accuracy: 0.9965 - iouMetric: 0.1373 - dice_coef: 0.2381\n",
            "Epoch 15/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.1104 - accuracy: 0.9965 - iouMetric: 0.1441 - dice_coef: 0.2486"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 226s 2s/step - loss: 0.1104 - accuracy: 0.9965 - iouMetric: 0.1436 - dice_coef: 0.2478\n",
            "Epoch 16/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0976 - accuracy: 0.9966 - iouMetric: 0.1489 - dice_coef: 0.2555"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 225s 2s/step - loss: 0.0976 - accuracy: 0.9966 - iouMetric: 0.1477 - dice_coef: 0.2535\n",
            "Epoch 17/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9965 - iouMetric: 0.1365 - dice_coef: 0.2369"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0872 - accuracy: 0.9965 - iouMetric: 0.1365 - dice_coef: 0.2369\n",
            "Epoch 18/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0773 - accuracy: 0.9965 - iouMetric: 0.1411 - dice_coef: 0.2437"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 209s 2s/step - loss: 0.0773 - accuracy: 0.9965 - iouMetric: 0.1412 - dice_coef: 0.2439\n",
            "Epoch 19/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0692 - accuracy: 0.9966 - iouMetric: 0.1517 - dice_coef: 0.2606"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0691 - accuracy: 0.9966 - iouMetric: 0.1505 - dice_coef: 0.2587\n",
            "Epoch 20/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0620 - accuracy: 0.9966 - iouMetric: 0.1515 - dice_coef: 0.2597"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 211s 2s/step - loss: 0.0620 - accuracy: 0.9966 - iouMetric: 0.1506 - dice_coef: 0.2582\n",
            "Epoch 21/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0558 - accuracy: 0.9966 - iouMetric: 0.1477 - dice_coef: 0.2538"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 21: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0558 - accuracy: 0.9966 - iouMetric: 0.1489 - dice_coef: 0.2555\n",
            "Epoch 22/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0504 - accuracy: 0.9966 - iouMetric: 0.1563 - dice_coef: 0.2663"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 22: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0504 - accuracy: 0.9966 - iouMetric: 0.1560 - dice_coef: 0.2660\n",
            "Epoch 23/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0456 - accuracy: 0.9966 - iouMetric: 0.1554 - dice_coef: 0.2645"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 23: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 208s 2s/step - loss: 0.0456 - accuracy: 0.9966 - iouMetric: 0.1541 - dice_coef: 0.2626\n",
            "Epoch 24/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0416 - accuracy: 0.9966 - iouMetric: 0.1587 - dice_coef: 0.2707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 24: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 208s 2s/step - loss: 0.0416 - accuracy: 0.9966 - iouMetric: 0.1575 - dice_coef: 0.2686\n",
            "Epoch 25/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0379 - accuracy: 0.9966 - iouMetric: 0.1538 - dice_coef: 0.2634"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 25: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0379 - accuracy: 0.9966 - iouMetric: 0.1526 - dice_coef: 0.2614\n",
            "Epoch 26/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0347 - accuracy: 0.9966 - iouMetric: 0.1542 - dice_coef: 0.2638"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 26: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0346 - accuracy: 0.9966 - iouMetric: 0.1541 - dice_coef: 0.2637\n",
            "Epoch 27/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0320 - accuracy: 0.9965 - iouMetric: 0.1519 - dice_coef: 0.2600"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 27: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0320 - accuracy: 0.9965 - iouMetric: 0.1523 - dice_coef: 0.2606\n",
            "Epoch 28/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9967 - iouMetric: 0.1679 - dice_coef: 0.2843"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 28: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0292 - accuracy: 0.9967 - iouMetric: 0.1679 - dice_coef: 0.2843\n",
            "Epoch 29/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0272 - accuracy: 0.9967 - iouMetric: 0.1625 - dice_coef: 0.2760"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 29: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 207s 2s/step - loss: 0.0272 - accuracy: 0.9967 - iouMetric: 0.1641 - dice_coef: 0.2780\n",
            "Epoch 30/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9967 - iouMetric: 0.1636 - dice_coef: 0.2762"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 30: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 207s 2s/step - loss: 0.0253 - accuracy: 0.9967 - iouMetric: 0.1636 - dice_coef: 0.2762\n",
            "Epoch 31/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0235 - accuracy: 0.9967 - iouMetric: 0.1634 - dice_coef: 0.2771"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 31: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 208s 2s/step - loss: 0.0235 - accuracy: 0.9967 - iouMetric: 0.1634 - dice_coef: 0.2772\n",
            "Epoch 32/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0221 - accuracy: 0.9966 - iouMetric: 0.1664 - dice_coef: 0.2815"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 32: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 206s 2s/step - loss: 0.0221 - accuracy: 0.9966 - iouMetric: 0.1651 - dice_coef: 0.2793\n",
            "Epoch 33/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0207 - accuracy: 0.9967 - iouMetric: 0.1684 - dice_coef: 0.2835"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 33: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 208s 2s/step - loss: 0.0207 - accuracy: 0.9967 - iouMetric: 0.1691 - dice_coef: 0.2845\n",
            "Epoch 34/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9967 - iouMetric: 0.1662 - dice_coef: 0.2803"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 34: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0195 - accuracy: 0.9967 - iouMetric: 0.1662 - dice_coef: 0.2803\n",
            "Epoch 35/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0185 - accuracy: 0.9967 - iouMetric: 0.1686 - dice_coef: 0.2842"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 35: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 214s 2s/step - loss: 0.0185 - accuracy: 0.9967 - iouMetric: 0.1689 - dice_coef: 0.2848\n",
            "Epoch 36/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0175 - accuracy: 0.9967 - iouMetric: 0.1716 - dice_coef: 0.2889"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 36: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0175 - accuracy: 0.9967 - iouMetric: 0.1703 - dice_coef: 0.2868\n",
            "Epoch 37/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0167 - accuracy: 0.9967 - iouMetric: 0.1715 - dice_coef: 0.2882"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 37: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0167 - accuracy: 0.9967 - iouMetric: 0.1705 - dice_coef: 0.2866\n",
            "Epoch 38/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0158 - accuracy: 0.9967 - iouMetric: 0.1789 - dice_coef: 0.2991"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 38: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 211s 2s/step - loss: 0.0158 - accuracy: 0.9967 - iouMetric: 0.1775 - dice_coef: 0.2968\n",
            "Epoch 39/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0155 - accuracy: 0.9967 - iouMetric: 0.1719 - dice_coef: 0.2896"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 39: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 209s 2s/step - loss: 0.0155 - accuracy: 0.9967 - iouMetric: 0.1712 - dice_coef: 0.2885\n",
            "Epoch 40/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0149 - accuracy: 0.9967 - iouMetric: 0.1733 - dice_coef: 0.2918"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 40: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 207s 2s/step - loss: 0.0149 - accuracy: 0.9967 - iouMetric: 0.1745 - dice_coef: 0.2933\n",
            "Epoch 41/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0142 - accuracy: 0.9967 - iouMetric: 0.1785 - dice_coef: 0.2990"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 41: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0142 - accuracy: 0.9967 - iouMetric: 0.1774 - dice_coef: 0.2973\n",
            "Epoch 42/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0138 - accuracy: 0.9968 - iouMetric: 0.1861 - dice_coef: 0.3092"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 42: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 209s 2s/step - loss: 0.0138 - accuracy: 0.9968 - iouMetric: 0.1847 - dice_coef: 0.3069\n",
            "Epoch 43/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9967 - iouMetric: 0.1764 - dice_coef: 0.2950"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 43: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0137 - accuracy: 0.9967 - iouMetric: 0.1764 - dice_coef: 0.2950\n",
            "Epoch 44/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0133 - accuracy: 0.9968 - iouMetric: 0.1827 - dice_coef: 0.3043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 44: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0133 - accuracy: 0.9968 - iouMetric: 0.1820 - dice_coef: 0.3032\n",
            "Epoch 45/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0128 - accuracy: 0.9968 - iouMetric: 0.1819 - dice_coef: 0.3037"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 45: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0128 - accuracy: 0.9968 - iouMetric: 0.1809 - dice_coef: 0.3021\n",
            "Epoch 46/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0125 - accuracy: 0.9967 - iouMetric: 0.1841 - dice_coef: 0.3069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 46: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 211s 2s/step - loss: 0.0125 - accuracy: 0.9967 - iouMetric: 0.1838 - dice_coef: 0.3066\n",
            "Epoch 47/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9968 - iouMetric: 0.1864 - dice_coef: 0.3109"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 47: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0124 - accuracy: 0.9968 - iouMetric: 0.1864 - dice_coef: 0.3109\n",
            "Epoch 48/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0120 - accuracy: 0.9968 - iouMetric: 0.1880 - dice_coef: 0.3123"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 48: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0120 - accuracy: 0.9968 - iouMetric: 0.1871 - dice_coef: 0.3110\n",
            "Epoch 49/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9968 - iouMetric: 0.1961 - dice_coef: 0.3240"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 49: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 213s 2s/step - loss: 0.0117 - accuracy: 0.9968 - iouMetric: 0.1961 - dice_coef: 0.3240\n",
            "Epoch 50/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9967 - iouMetric: 0.1839 - dice_coef: 0.3060"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 50: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0118 - accuracy: 0.9967 - iouMetric: 0.1839 - dice_coef: 0.3060\n",
            "Epoch 51/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0116 - accuracy: 0.9968 - iouMetric: 0.1887 - dice_coef: 0.3130"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 51: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 211s 2s/step - loss: 0.0116 - accuracy: 0.9968 - iouMetric: 0.1887 - dice_coef: 0.3131\n",
            "Epoch 52/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0115 - accuracy: 0.9968 - iouMetric: 0.1928 - dice_coef: 0.3191"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 52: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0115 - accuracy: 0.9968 - iouMetric: 0.1912 - dice_coef: 0.3165\n",
            "Epoch 53/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0115 - accuracy: 0.9968 - iouMetric: 0.1869 - dice_coef: 0.3104"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 53: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 213s 2s/step - loss: 0.0115 - accuracy: 0.9968 - iouMetric: 0.1854 - dice_coef: 0.3080\n",
            "Epoch 54/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0111 - accuracy: 0.9968 - iouMetric: 0.1978 - dice_coef: 0.3263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 54: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 211s 2s/step - loss: 0.0111 - accuracy: 0.9968 - iouMetric: 0.1968 - dice_coef: 0.3248\n",
            "Epoch 55/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9968 - iouMetric: 0.1966 - dice_coef: 0.3247"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 55: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 214s 2s/step - loss: 0.0111 - accuracy: 0.9968 - iouMetric: 0.1966 - dice_coef: 0.3247\n",
            "Epoch 56/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0109 - accuracy: 0.9969 - iouMetric: 0.2041 - dice_coef: 0.3345"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 56: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 214s 2s/step - loss: 0.0109 - accuracy: 0.9969 - iouMetric: 0.2052 - dice_coef: 0.3360\n",
            "Epoch 57/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0109 - accuracy: 0.9969 - iouMetric: 0.2054 - dice_coef: 0.3372"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 57: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 217s 2s/step - loss: 0.0109 - accuracy: 0.9969 - iouMetric: 0.2051 - dice_coef: 0.3368\n",
            "Epoch 58/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9969 - iouMetric: 0.1985 - dice_coef: 0.3275"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 58: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 215s 2s/step - loss: 0.0110 - accuracy: 0.9969 - iouMetric: 0.1985 - dice_coef: 0.3275\n",
            "Epoch 59/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0108 - accuracy: 0.9969 - iouMetric: 0.2018 - dice_coef: 0.3315"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 59: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 216s 2s/step - loss: 0.0108 - accuracy: 0.9969 - iouMetric: 0.2003 - dice_coef: 0.3291\n",
            "Epoch 60/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0109 - accuracy: 0.9969 - iouMetric: 0.1987 - dice_coef: 0.3272"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 60: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 214s 2s/step - loss: 0.0109 - accuracy: 0.9969 - iouMetric: 0.1971 - dice_coef: 0.3247\n",
            "Epoch 61/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969 - iouMetric: 0.2068 - dice_coef: 0.3377"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 61: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 216s 2s/step - loss: 0.0106 - accuracy: 0.9969 - iouMetric: 0.2068 - dice_coef: 0.3377\n",
            "Epoch 62/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0106 - accuracy: 0.9969 - iouMetric: 0.2085 - dice_coef: 0.3400"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 62: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0106 - accuracy: 0.9969 - iouMetric: 0.2097 - dice_coef: 0.3415\n",
            "Epoch 63/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0103 - accuracy: 0.9969 - iouMetric: 0.2154 - dice_coef: 0.3504"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 63: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 216s 2s/step - loss: 0.0103 - accuracy: 0.9969 - iouMetric: 0.2169 - dice_coef: 0.3523\n",
            "Epoch 64/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0102 - accuracy: 0.9970 - iouMetric: 0.2177 - dice_coef: 0.3533"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 64: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0102 - accuracy: 0.9970 - iouMetric: 0.2184 - dice_coef: 0.3542\n",
            "Epoch 65/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0104 - accuracy: 0.9969 - iouMetric: 0.2190 - dice_coef: 0.3548"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 65: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 216s 2s/step - loss: 0.0104 - accuracy: 0.9969 - iouMetric: 0.2196 - dice_coef: 0.3556\n",
            "Epoch 66/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9970 - iouMetric: 0.2241 - dice_coef: 0.3614"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 66: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 211s 2s/step - loss: 0.0101 - accuracy: 0.9970 - iouMetric: 0.2241 - dice_coef: 0.3614\n",
            "Epoch 67/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0102 - accuracy: 0.9969 - iouMetric: 0.2199 - dice_coef: 0.3554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 67: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 214s 2s/step - loss: 0.0102 - accuracy: 0.9969 - iouMetric: 0.2182 - dice_coef: 0.3526\n",
            "Epoch 68/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0101 - accuracy: 0.9970 - iouMetric: 0.2317 - dice_coef: 0.3717"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 68: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 213s 2s/step - loss: 0.0101 - accuracy: 0.9970 - iouMetric: 0.2299 - dice_coef: 0.3689\n",
            "Epoch 69/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9970 - iouMetric: 0.2262 - dice_coef: 0.3645"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 69: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 213s 2s/step - loss: 0.0100 - accuracy: 0.9970 - iouMetric: 0.2262 - dice_coef: 0.3645\n",
            "Epoch 70/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0098 - accuracy: 0.9970 - iouMetric: 0.2344 - dice_coef: 0.3755"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 70: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 217s 2s/step - loss: 0.0098 - accuracy: 0.9970 - iouMetric: 0.2355 - dice_coef: 0.3768\n",
            "Epoch 71/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9970 - iouMetric: 0.2299 - dice_coef: 0.3687"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 71: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 218s 2s/step - loss: 0.0100 - accuracy: 0.9970 - iouMetric: 0.2299 - dice_coef: 0.3687\n",
            "Epoch 72/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0097 - accuracy: 0.9970 - iouMetric: 0.2370 - dice_coef: 0.3786"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 72: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 215s 2s/step - loss: 0.0097 - accuracy: 0.9970 - iouMetric: 0.2383 - dice_coef: 0.3801\n",
            "Epoch 73/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9970 - iouMetric: 0.2356 - dice_coef: 0.3769"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 73: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 211s 2s/step - loss: 0.0097 - accuracy: 0.9970 - iouMetric: 0.2356 - dice_coef: 0.3769\n",
            "Epoch 74/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0096 - accuracy: 0.9971 - iouMetric: 0.2438 - dice_coef: 0.3878"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 74: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 211s 2s/step - loss: 0.0096 - accuracy: 0.9971 - iouMetric: 0.2419 - dice_coef: 0.3849\n",
            "Epoch 75/80\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9971 - iouMetric: 0.2464 - dice_coef: 0.3905"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 75: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0094 - accuracy: 0.9971 - iouMetric: 0.2464 - dice_coef: 0.3905\n",
            "Epoch 76/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0092 - accuracy: 0.9972 - iouMetric: 0.2556 - dice_coef: 0.4029"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 76: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 213s 2s/step - loss: 0.0092 - accuracy: 0.9972 - iouMetric: 0.2578 - dice_coef: 0.4052\n",
            "Epoch 77/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0092 - accuracy: 0.9971 - iouMetric: 0.2586 - dice_coef: 0.4058"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 77: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 213s 2s/step - loss: 0.0092 - accuracy: 0.9971 - iouMetric: 0.2571 - dice_coef: 0.4036\n",
            "Epoch 78/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0092 - accuracy: 0.9971 - iouMetric: 0.2592 - dice_coef: 0.4062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 78: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 211s 2s/step - loss: 0.0092 - accuracy: 0.9971 - iouMetric: 0.2586 - dice_coef: 0.4055\n",
            "Epoch 79/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0090 - accuracy: 0.9972 - iouMetric: 0.2604 - dice_coef: 0.4068"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 79: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 212s 2s/step - loss: 0.0090 - accuracy: 0.9972 - iouMetric: 0.2590 - dice_coef: 0.4048\n",
            "Epoch 80/80\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0090 - accuracy: 0.9972 - iouMetric: 0.2635 - dice_coef: 0.4111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 80: saving model to model.weights.best.hdf5\n",
            "124/124 [==============================] - 210s 2s/step - loss: 0.0090 - accuracy: 0.9972 - iouMetric: 0.2628 - dice_coef: 0.4101\n",
            "Completed\n"
          ]
        }
      ],
      "source": [
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1)  \n",
        "model_time = dt.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_folder = os.path.join(results_dir, model_time)\n",
        "os.makedirs(model_folder)\n",
        "\n",
        "tensorboard_folder = os.path.join(model_folder, \"tensorlogs\")\n",
        "os.makedirs(tensorboard_folder)\n",
        "\n",
        "ckpt_folder = os.path.join(model_folder, \"checkpoints\")\n",
        "os.makedirs(ckpt_folder)\n",
        "\n",
        "csv_logger_folder = os.path.join(model_folder, \"csv_logger\")\n",
        "os.makedirs(csv_logger_folder)\n",
        "\n",
        "hist_folder = os.path.join(model_folder, \"model_history\")\n",
        "os.makedirs(hist_folder)\n",
        "\n",
        "saved_model_folder = os.path.join(model_folder, \"Saved_model\")\n",
        "os.makedirs(saved_model_folder)\n",
        "\n",
        "model_params_folder = os.path.join(model_folder, \"model_params\")\n",
        "os.makedirs(model_params_folder)\n",
        "\n",
        "train_x, train_y = datasetPaths(\n",
        "    full_img_dir=train_full_img_dir,\n",
        "    mask_img_dir=train_mask_img_dir \n",
        ")\n",
        "\n",
        "test_x, test_y = datasetPaths(\n",
        "    full_img_dir=test_full_img_dir,\n",
        "    mask_img_dir=test_mask_img_dir\n",
        ")\n",
        "\n",
        "train_ds = makeTFDataset(shuffle=True, augument=True,\n",
        "x_paths_list = train_x, y_paths_list=train_y, batch_size=batch_size)\n",
        "\n",
        "\n",
        "test_ds = makeTFDataset(\n",
        "    shuffle=False,\n",
        "    augument=False,\n",
        "    x_paths_list=test_x,\n",
        "    y_paths_list=test_y,\n",
        "    batch_size=batch_size)      \n",
        "    \n",
        "unet = buildUnet()\n",
        "\n",
        "unet = compile_(model=unet)\n",
        "\n",
        "# ckpt_path = (ckpt_folder + f\"/{model_time}\" + \"_Epoch-{epoch:03d}\" + \"_IOU-{iouMetric:.8f\")\n",
        "ckpt_path = (ckpt_folder + f\"/{model_time}\")\n",
        "\n",
        "ckpt_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath= ckpt_path,\n",
        "    monitors= callback_monitor,\n",
        "    mode= callback_mode,\n",
        "    save_weights_only= ckpt_save_weights_only,\n",
        "    save_best_only=ckpt_save_best_only,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "es_callback = keras.callbacks.EarlyStopping(\n",
        "    patience= earlystop_patience,\n",
        "    monitor= callback_monitor,\n",
        "    mode= callback_mode,\n",
        "    restore_best_weights= restore_best_weights,\n",
        ")\n",
        "\n",
        "# TensorBoard\n",
        "tb_callback = keras.callbacks.TensorBoard(\n",
        "    log_dir=tensorboard_folder, histogram_freq=1, profile_batch=0\n",
        ")\n",
        "\n",
        "# CSV Logger\n",
        "csv_logger_path = os.path.join(csv_logger_folder, \"csv_logger.csv\")\n",
        "csv_logger = keras.callbacks.CSVLogger(\n",
        "    filename=csv_logger_path, separator=\",\", append=True\n",
        ")\n",
        "\n",
        "# Putting them together\n",
        "callbacks = [ckpt_callback, es_callback, tb_callback, csv_logger, checkpointer]\n",
        "\n",
        "train_steps = len(train_x) // batch_size\n",
        "test_steps = len(test_x) // batch_size\n",
        "\n",
        "if len(train_x) % batch_size != 0:\n",
        "    train_steps += 1\n",
        "if len(test_x) % batch_size != 0:\n",
        "    test_steps += 1\n",
        "\n",
        "print()\n",
        "print(f\"Size of training set = {len(train_x)}\")\n",
        "print(f\"Size of test set = {len(test_x)}\")\n",
        "print(f\"Number of epochs = {num_epochs}\")\n",
        "print(f\"Batch size = {batch_size}\")\n",
        "print(f\"Number of training steps per epoch = {train_steps}\")\n",
        "print(f\"Number of test steps per epoch = {test_steps}\")\n",
        "print()\n",
        "\n",
        "if validate:\n",
        "        history = unet.fit(\n",
        "            train_ds,\n",
        "            validation_data=test_ds,\n",
        "            epochs=num_epochs,\n",
        "            steps_per_epoch=train_steps,\n",
        "            validation_steps=test_steps,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1,\n",
        "        )\n",
        "elif not validate:\n",
        "    history = unet.fit(\n",
        "        train_ds,\n",
        "        epochs=num_epochs,\n",
        "        steps_per_epoch=train_steps,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "#y_hat = unet.evaluate(test_ds)\n",
        "\n",
        "print(\"Completed\")     \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " def makeTFDataset1( shuffle, augument, x_paths_list, y_paths_list, batch_size):\n",
        "        try:\n",
        "            ds = tf.data.Dataset.from_tensor_slices((x_paths_list, y_paths_list))\n",
        "            \n",
        "            if shuffle:\n",
        "                ds = ds.shuffle(buffer_size=len(x_paths_list))\n",
        "\n",
        "            ds = ds.map(tfParse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "            \n",
        "            if augument:\n",
        "                ds = ds.map(imgAugment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "            ds = ds.batch(batch_size=batch_size, drop_remainder=False)\n",
        "            #ds = ds.repeat()\n",
        "\n",
        "            return ds\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in make TFDataset {e}\")"
      ],
      "metadata": {
        "id": "MBPWHo79s1Hz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LCumD8yCBX3-"
      },
      "outputs": [],
      "source": [
        "test_ds = makeTFDataset1(\n",
        "    shuffle=False,\n",
        "    augument=False,\n",
        "    x_paths_list=test_x,\n",
        "    y_paths_list=test_y,\n",
        "    batch_size=batch_size)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "MGkGHRtCIlcu"
      },
      "outputs": [],
      "source": [
        "unet.load_weights('model.weights.best.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = unet.evaluate(test_ds, verbose=0)\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRy91OTxNnym",
        "outputId": "f03ea198-63ab-460a-9b46-ec0087bfdafa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01257326640188694,\n",
              " 0.9966688752174377,\n",
              " 0.1951829493045807,\n",
              " 0.320146381855011]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dtht3dayvWSI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/results/fit.zip /content/results/fit /content/model.weights.best.hdf5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVeEZIevwLzg",
        "outputId": "d061f7f9-0d4c-4025-fe9b-160bbb968601"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results/fit/ (stored 0%)\n",
            "  adding: content/results/fit/20220816_055334/ (stored 0%)\n",
            "  adding: content/results/fit/20220816_055334/csv_logger/ (stored 0%)\n",
            "  adding: content/results/fit/20220816_055334/csv_logger/csv_logger.csv (deflated 51%)\n",
            "  adding: content/results/fit/20220816_055334/model_params/ (stored 0%)\n",
            "  adding: content/results/fit/20220816_055334/model_history/ (stored 0%)\n",
            "  adding: content/results/fit/20220816_055334/tensorlogs/ (stored 0%)\n",
            "  adding: content/results/fit/20220816_055334/tensorlogs/train/ (stored 0%)\n",
            "  adding: content/results/fit/20220816_055334/tensorlogs/train/events.out.tfevents.1660629223.87be539935ef.70.0.v2 (deflated 64%)\n",
            "  adding: content/results/fit/20220816_055334/checkpoints/ (stored 0%)\n",
            "  adding: content/results/fit/20220816_055334/Saved_model/ (stored 0%)\n",
            "  adding: content/model.weights.best.hdf5 (deflated 14%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/results/fit.zip\")\n",
        "#files.download('model.weights.best.hdf5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Ms8fiADKwq6i",
        "outputId": "68f1272b-be9e-4844-ff5e-9ecb2ff332ca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_81510d71-4901-4422-a38d-fee2e3290e5f\", \"fit.zip\", 337769203)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadFullImg_1(path, dsize):\n",
        "        try:\n",
        "             \n",
        "            print(path)\n",
        "            img = cv2.imread(\"/content/gdrive/MyDrive/cbisddsm/Test_output_full/Mass-Test_P_00016_LEFT_CC_FULL__PRE.png\", cv2.IMREAD_GRAYSCALE)\n",
        "            print(type(img))\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "      \n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "            print(f'After norm_img')\n",
        "            print(f'type {norm_img.shape}')\n",
        "            full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "            print(f'After full_img')\n",
        "            print(f'type {full_img.shape}')\n",
        "            print(f'done for path {path} with shape {full_img.shape}')\n",
        "            return full_img\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"There is an error in loadFullImg {e}\")"
      ],
      "metadata": {
        "id": "A2Hu8b8_UMD2"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadMaskImg_1(path, dsize):\n",
        "        try:\n",
        "            # if not isinstance(path, str):\n",
        "            #     path=path.decode()\n",
        "            print(path)\n",
        "            img = cv2.imread(\"/content/gdrive/MyDrive/cbisddsm/Test_output_mask/Mass-Test_P_00016_LEFT_CC_MASK_1__PRE.png\", cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "            mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "            print(f'done for path {path} with shape {mask_img.shape}')\n",
        "            return mask_img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in loadMaskIMG {e}\")"
      ],
      "metadata": {
        "id": "MN8ydZ_-UV74"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tfParse_1(x_path, y_path):\n",
        "        try:\n",
        "            def _parse(x_path, y_path):\n",
        "                x = loadFullImg_1(path=x_path, dsize=target_size)\n",
        "                y = loadMaskImg_1(path=y_path, dsize=target_size)\n",
        "                return x,y\n",
        "\n",
        "            x, y = tf.numpy_function(_parse, [x_path, y_path], [tf.float64, tf.float64])\n",
        "              \n",
        "            x.set_shape([target_size[0], target_size[0], 3])\n",
        "            y.set_shape([target_size[0], target_size[1], 1])\n",
        "\n",
        "            return x,y\n",
        "            \n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in tfParse {e}\")"
      ],
      "metadata": {
        "id": "wb2fsrPDUMK1"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06CumsaLV6JC",
        "outputId": "d3f27dbd-a70b-411a-cbc2-5022a56d3d85"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_x, res_y = tfParse_1(test_x[0], test_y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRVx-4W1T0jO",
        "outputId": "fa41216d-3929-4f65-8df5-04b8e42555c1"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/cbisddsm/Test_output_full/Mass-Test_P_00016_LEFT_CC_FULL__PRE.png\n",
            "<class 'numpy.ndarray'>\n",
            "After norm_img\n",
            "type (224, 224)\n",
            "After full_img\n",
            "type (224, 224, 3)\n",
            "done for path /content/gdrive/MyDrive/cbisddsm/Test_output_full/Mass-Test_P_00016_LEFT_CC_FULL__PRE.png with shape (224, 224, 3)\n",
            "/content/gdrive/MyDrive/cbisddsm/Test_output_mask/Mass-Test_P_00016_LEFT_CC_MASK_1__PRE.png\n",
            "done for path /content/gdrive/MyDrive/cbisddsm/Test_output_mask/Mass-Test_P_00016_LEFT_CC_MASK_1__PRE.png with shape (224, 224, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res_x.shape)\n",
        "print(res_y.shape)\n",
        "print(type(res_y.numpy())) \n",
        "print(res_y.numpy().shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMaOVHjUT6He",
        "outputId": "4d7b2158-ae67-4f28-ba3c-9f9055c98efa"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n",
            "(224, 224, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "(224, 224, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (50,8))\n",
        "plt.imshow(res_x.numpy(), cmap=\"gray\")\n",
        "plt.title(f\"Before cropping \", x=0.5, y=-0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "hh-whdVrYM4j",
        "outputId": "66c23b7f-d953-4cd6-8faa-508de08e6a2a"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, -0.1, 'Before cropping ')"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3600x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize = (50,8))\n",
        "# plt.imshow(res_y.numpy(), cmap=\"gray\")\n",
        "# plt.title(f\"Before cropping \", x=0.5, y=-0.1)\n",
        "print(res_x.numpy().shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVcmbNaQZDTX",
        "outputId": "32c861df-b582-4b10-f9e3-c262d9e823aa"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = unet.predict(res_x.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "qjA1jjBgTnMf",
        "outputId": "e1683f78-2a05-4ba7-9f02-aede479eccb0"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-412aeafa4501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"Unet_VGG16\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, 224, 3)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Cbisddsm_final_new_1.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "instance_type": "ml.m5.large",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}