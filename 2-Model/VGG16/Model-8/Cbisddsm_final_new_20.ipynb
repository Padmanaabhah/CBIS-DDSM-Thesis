{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xzc7BJKDBX3y"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L6wiaECOBX30"
      },
      "outputs": [],
      "source": [
        "#pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cXp-5N_yBX30"
      },
      "outputs": [],
      "source": [
        "from distutils import extension\n",
        "from logging import exception\n",
        "import os\n",
        "from datetime import datetime as dt\n",
        "from regex import E\n",
        "from sqlalchemy import intersect\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import numpy as np \n",
        "import pathlib\n",
        "from keras.callbacks import ModelCheckpoint   \n",
        "from keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iQkKItqB1-t",
        "outputId": "45d38f52-9fe9-4ceb-f6cb-d37fa44328e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wQYE2sEYB-uE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8686cad-694f-4f2c-e7df-5f982ba27065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_output_full  Test_output_mask  Train_output_full  Train_output_mask\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/gdrive/MyDrive/cbisddsm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2foFHtBFB_U4"
      },
      "outputs": [],
      "source": [
        "# data_dir_train = pathlib.Path(\"/content/gdrive/MyDrive/Images/Train\")\n",
        "# data_dir_test = pathlib.Path('/content/gdrive/MyDrive/Images/Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zYVMXFDEBX31"
      },
      "outputs": [],
      "source": [
        "seed = 43\n",
        "encoder_input_width = 224\n",
        "encode_input_channels = 3\n",
        "encoder_input_shape = (encoder_input_width, encoder_input_width, encode_input_channels)\n",
        "\n",
        "kernsize = 3\n",
        "decoder_kernel_size = (kernsize, kernsize)\n",
        "stride = 2\n",
        "decoder_strides = (stride, stride)\n",
        "decoder_padding = \"same\"\n",
        "decoder_activation = None\n",
        "final_layer_filters = 1\n",
        "final_layer_activation = \"sigmoid\"\n",
        "\n",
        "train_full_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Train_output_full\"\n",
        "train_mask_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Train_output_mask\"\n",
        "\n",
        "test_full_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Test_output_full\"\n",
        "test_mask_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Test_output_mask\"\n",
        "results_dir = \"/content/results/fit\"\n",
        "extension = \".png\"\n",
        "\n",
        "target_size = (224, 224)\n",
        "\n",
        "brightness_delta = 0.3\n",
        "batch_size = 10\n",
        "\n",
        "weight_decay = 1e-5\n",
        "\n",
        "validate = False\n",
        "loss = \"binary_crossentropy\"\n",
        "learning_rate = 0.0001\n",
        "dropout = 0.5\n",
        "dropout_training = True\n",
        "num_epochs = 100\n",
        "callback_monitor = \"iouMetric\"\n",
        "callback_mode = \"max\"\n",
        "ckpt_save_weights_only = True\n",
        "ckpt_save_best_only = True\n",
        "earlystop_patience = 200\n",
        "restore_best_weights = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WiJw56KyBX32"
      },
      "outputs": [],
      "source": [
        "# x_paths_list = []\n",
        "# for full in os.listdir(train_full_img_dir):\n",
        "#   if full.endswith(extension):\n",
        "#     x_paths_list.append(os.path.join(train_full_img_dir, full))\n",
        "\n",
        "# print(len(x_paths_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B28GisyHBX32"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JGqSf0kQBX32"
      },
      "outputs": [],
      "source": [
        "def datasetPaths(full_img_dir, mask_img_dir):\n",
        "        try:\n",
        "            x_paths_list = []\n",
        "            y_paths_list = []\n",
        "\n",
        "            for full in os.listdir(full_img_dir):\n",
        "                if full.endswith(extension):\n",
        "                    x_paths_list.append(os.path.join(full_img_dir, full))\n",
        "            \n",
        "            for full in os.listdir(mask_img_dir):\n",
        "                if full.endswith(extension):\n",
        "                    y_paths_list.append(os.path.join(mask_img_dir, full))\n",
        "            \n",
        "            x_paths_list.sort()\n",
        "            y_paths_list.sort()\n",
        "\n",
        "            return x_paths_list, y_paths_list\n",
        "        except Exception as e:\n",
        "            print(f\"Error in datasetPaths {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7u3oVaRTBX33"
      },
      "outputs": [],
      "source": [
        "# def loadFullImg(path, dsize):\n",
        "#         try:\n",
        "#             if not isinstance(path, str):\n",
        "#                 path = path.decode()\n",
        "             \n",
        "            \n",
        "#             s3_client = boto3.resource('s3')\n",
        "#             obj = s3_client.get_object(Bucket='cbisddsm', Key=path)\n",
        "#             nparr = np.frombuffer(obj['Body'].read(), np.uint8)\n",
        "#             img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "#             print(f'type type{img}')\n",
        "#             #bucket = s3_resource.Bucket('cbisddsm')\n",
        "#             #print(f'bucket.Object(path) {bucket.Object(path)}')\n",
        "#             #img = bucket.Object(path).get().get('Body').read()\n",
        "#             #print(f'img {img}')\n",
        "#             #img = cv2.imdecode(np.asarray(bytearray(img)), cv2.IMREAD_COLOR)\n",
        "           \n",
        "            \n",
        "#             #img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "#             img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "#             norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "#             full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "#             print(f'done for path {path}')\n",
        "#             return full_img\n",
        "        \n",
        "#         except Exception as e:\n",
        "#             print(f\"There is an error in loadFullImg {e}\")\n",
        "            \n",
        "\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VQf1GqJeBX34"
      },
      "outputs": [],
      "source": [
        "def loadFullImg(path, dsize):\n",
        "        try:\n",
        "            if not isinstance(path, str):\n",
        "                path = path.decode()\n",
        "            \n",
        "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "            #print(type(img))\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "            #print(f'After norm_img')\n",
        "            #print(f'type {norm_img.shape}')\n",
        "            full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "            #print(f'After full_img')\n",
        "            #print(f'type {full_img.shape}')\n",
        "            #print(f'done for path {path} with shape {full_img.shape}')\n",
        "            return full_img\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"There is an error in loadFullImg {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Yfm6JA2rBX34"
      },
      "outputs": [],
      "source": [
        "# s3 = boto3.resource('s3')\n",
        "# my_bucket = s3.Bucket('cbisddsm')\n",
        "# i = 0\n",
        "# for object_summary in my_bucket.objects.filter(Prefix='Train_output_full'):    \n",
        "#     if i == 0:\n",
        "#         pass\n",
        "#     else:\n",
        "#         print(object_summary.key)\n",
        "#         img = loadFullImg(object_summary.key, target_size)\n",
        "#         print(img.shape)\n",
        "#         #break\n",
        "#     i += 1\n",
        "    \n",
        "    \n",
        "#             #print(object_summary.key)\n",
        "        \n",
        "#             #x_paths_list.append(object_summary.key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KYSP3bIaBX35"
      },
      "outputs": [],
      "source": [
        "def loadMaskImg(path, dsize):\n",
        "        try:\n",
        "            if not isinstance(path, str):\n",
        "                path=path.decode()\n",
        "            \n",
        "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "            mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "            #print(f'done for path {path} with shape {mask_img.shape}')\n",
        "            return mask_img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in loadMaskIMG {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Co4SIeY6BX35"
      },
      "outputs": [],
      "source": [
        "# def loadMaskImg(path, dsize):\n",
        "#         try:\n",
        "#             if not isinstance(path, str):\n",
        "#                 path=path.decode()\n",
        "             \n",
        "#             s3_resource = boto3.resource('s3')\n",
        "#             bucket = s3_resource.Bucket('cbisddsm')\n",
        "# #             bucket = s3_resource.Bucket('cbisddsm')\n",
        "#             img = bucket.Object(path).get().get('Body').read()\n",
        "#             img = cv2.imdecode(np.asarray(bytearray(img)), cv2.IMREAD_COLOR)\n",
        "#             print(f'type type(img)')\n",
        "#             #img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "#             img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "#             norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "#             mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "\n",
        "#             return mask_img\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(\"Error in loadMaskIMG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bawafpnnBX36"
      },
      "outputs": [],
      "source": [
        "def tfParse(x_path, y_path):\n",
        "        try:\n",
        "            def _parse(x_path, y_path):\n",
        "                x = loadFullImg(path=x_path, dsize=target_size)\n",
        "                y = loadMaskImg(path=y_path, dsize=target_size)\n",
        "                return x,y\n",
        "\n",
        "            x, y = tf.numpy_function(_parse, [x_path, y_path], [tf.float64, tf.float64])\n",
        "\n",
        "            x.set_shape([target_size[0], target_size[0], 3])\n",
        "            y.set_shape([target_size[0], target_size[1], 1])\n",
        "\n",
        "            return x,y\n",
        "            \n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in tfParse {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tkHDbxVGBX36"
      },
      "outputs": [],
      "source": [
        "def imgAugment(x_img, y_img):\n",
        "        try:\n",
        "            if tf.random.uniform(()) > 0.5:\n",
        "                x_img = tf.image.flip_up_down(image=x_img)\n",
        "                y_img = tf.image.flip_up_down(image=y_img)\n",
        "\n",
        "            x_img = tf.image.random_brightness(\n",
        "                image=x_img, max_delta=brightness_delta\n",
        "            )\n",
        "\n",
        "            return x_img, y_img\n",
        "\n",
        "        except:\n",
        "            print(\"Erro in imgAugument\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Mge3IsdLBX36"
      },
      "outputs": [],
      "source": [
        " def makeTFDataset( shuffle, augument, x_paths_list, y_paths_list, batch_size):\n",
        "        try:\n",
        "            ds = tf.data.Dataset.from_tensor_slices((x_paths_list, y_paths_list))\n",
        "            \n",
        "            if shuffle:\n",
        "                ds = ds.shuffle(buffer_size=len(x_paths_list))\n",
        "\n",
        "            ds = ds.map(tfParse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "            \n",
        "            if augument:\n",
        "                ds = ds.map(imgAugment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "            ds = ds.batch(batch_size=batch_size, drop_remainder=False)\n",
        "            ds = ds.repeat()\n",
        "\n",
        "            return ds\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in make TFDataset {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9RGLX5MnBX37"
      },
      "outputs": [],
      "source": [
        "def buildEncoder():\n",
        "        try:\n",
        "            VGG16_ = keras.applications.VGG16(\n",
        "                include_top=False, weights=\"imagenet\", input_shape=encoder_input_shape,\n",
        "            )\n",
        "\n",
        "            layer_names = [layer.name for layer in VGG16_.layers]\n",
        "\n",
        "            all_layer_outputs = [\n",
        "               VGG16_.get_layer(layer).output for layer in layer_names\n",
        "            ]\n",
        "\n",
        "            encoder_model = keras.Model(inputs=VGG16_.input, outputs=all_layer_outputs)\n",
        "\n",
        "            encoder_model.trainable = False\n",
        "\n",
        "            return encoder_model \n",
        "        \n",
        "        except Exception as e:\n",
        "            print(\"Error in buildEncoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eNHrykF9BX37"
      },
      "outputs": [],
      "source": [
        "def buildUnet():\n",
        "        try:\n",
        "            unet_input = keras.Input(\n",
        "                shape= encoder_input_shape, name=\"unet_input_layer\"\n",
        "            )\n",
        "\n",
        "            x = unet_input\n",
        "            encoder_model = buildEncoder()\n",
        "            all_encoder_layer_outputs = encoder_model(x)\n",
        "\n",
        "            encoded_img = all_encoder_layer_outputs[-1]\n",
        "\n",
        "            #skip_outputs = [all_encoder_layer_outputs[i] for i in [2, 5,9, 13, 17]]\n",
        "            skip_outputs = [all_encoder_layer_outputs[i] for i in [2, 4, 6, 12, 15]]\n",
        "            \n",
        "            decoder_filters = int(encoded_img.shape[-1])\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 5: 7x7 -> 14x14\n",
        "            #  - `encoded_img` as initial input for decoder\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block5_up_convT\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=decoder_activation,\n",
        "            )(encoded_img)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block5_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[4]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block5_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block5_up_conv3\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block5_up_conv2\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block5_up_conv1\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 4: 14x14 -> 28x28\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block4_up_convT\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block4_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[3]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block4_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block4_up_conv3\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block4_up_conv2\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block4_up_conv1\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 3: 28x28 -> 56x56\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block3_up_convT\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block3_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[2]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block3_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block3_up_conv3\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block3_up_conv2\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block3_up_conv1\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 2: 56x56 -> 112x112\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block2_up_convT\",\n",
        "                filters=int(decoder_filters / 4),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block2_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[1]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block2_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block2_up_conv2\",\n",
        "                filters=int(decoder_filters / 4),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block2_up_conv1\",\n",
        "                filters=int(decoder_filters / 4),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 1: 112x112 -> 224x224\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block1_up_convT\",\n",
        "                filters=int(decoder_filters / 8),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block1_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[0]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block1_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block1_up_conv2\",\n",
        "                filters=int(decoder_filters / 8),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            decoded_img = keras.layers.Conv2D(\n",
        "                name=\"block1_up_conv1\",\n",
        "                filters=int(decoder_filters / 8),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Final conv layer\n",
        "            final_img = keras.layers.Conv2D(\n",
        "                name=\"final_up_conv\",\n",
        "                filters=final_layer_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=final_layer_activation,\n",
        "            )(decoded_img)\n",
        "\n",
        "            # ======\n",
        "            #  Unet\n",
        "            # ======\n",
        "\n",
        "            unet = keras.Model(inputs=unet_input, outputs=final_img, name=\"Unet_VGG16\")\n",
        "\n",
        "            return unet\n",
        "        except Exception as e:\n",
        "            print(f\"Error in Build Unet {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_sq8aqBYBX38"
      },
      "outputs": [],
      "source": [
        "def iouMetric( y_true, y_pred):\n",
        "        try:\n",
        "            def compute_iou(y_true, y_pred):\n",
        "                intersection = (y_true * y_pred).sum()\n",
        "                union = y_true.sum() + y_pred.sum() - intersection\n",
        "                x = (intersection + 1e-15) / (union + 1e-15)\n",
        "                x = x.astype(np.float32)\n",
        "                return x\n",
        "            \n",
        "            return tf.numpy_function(compute_iou, [y_true, y_pred], tf.float32)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error in iouMetric {E}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xCkCusvKBCuz"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "        try:\n",
        "            # def dice(true, pred, k = 1):\n",
        "            #     intersection = np.sum(pred[true==k]) * 2.0\n",
        "            #     dice = intersection / (np.sum(pred) + np.sum(true))\n",
        "            #     return dice \n",
        "            # return tf.numpy_function(dice, [y_true, y_pred], tf.double)\n",
        "            \n",
        "            y_true_f = tf.reshape(tf.dtypes.cast(y_true, tf.float32), [-1])\n",
        "            y_pred_f = tf.reshape(tf.dtypes.cast(y_pred, tf.float32), [-1])\n",
        "            intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "            return (2. * intersection + 1.) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + 1.)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in dice_coef {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Egz73rd9BX39"
      },
      "outputs": [],
      "source": [
        "def compile_( model):\n",
        "        try:\n",
        "            loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "            metrics = [\"accuracy\", iouMetric, dice_coef]\n",
        "            model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(f\"Failed at compile_ {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jNa9nYOcCV15"
      },
      "outputs": [],
      "source": [
        " test_x, test_y = datasetPaths(\n",
        "            full_img_dir=test_full_img_dir,\n",
        "            mask_img_dir=test_mask_img_dir\n",
        "        )\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wDDyk7GYCWU3"
      },
      "outputs": [],
      "source": [
        "# def evaluate(path,target_size):\n",
        "#   full_img_lst = []\n",
        "#   print(len(path))\n",
        "#   for imgpath in path:\n",
        "#     full_img = loadFullImg(imgpath, target_size)\n",
        "#     full_img_lst.append(full_img)\n",
        "#     #img = cv2.imread(imgpath, cv2.IMREAD_GRAYSCALE)\n",
        "#     #print(full_img.shape)\n",
        "#   return full_img_lst\n",
        "  \n",
        "# full_img_lst = evaluate(test_x, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pbuTQcYXCbvv"
      },
      "outputs": [],
      "source": [
        "# def evaluate_mask(path,target_size):\n",
        "#   mask_img_lst = []\n",
        "#   print(len(path))\n",
        "#   for imgpath in path:\n",
        "#     mask_img = loadMaskImg(imgpath, target_size)\n",
        "#     mask_img_lst.append(mask_img)\n",
        "#     #img = cv2.imread(imgpath, cv2.IMREAD_GRAYSCALE)\n",
        "#     #print(full_img.shape)\n",
        "#   return mask_img_lst\n",
        "  \n",
        "# mask_img_lst = evaluate(test_y, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_WCc1IIBIety"
      },
      "outputs": [],
      "source": [
        "# img = cv2.imread(test_x[0], cv2.IMREAD_GRAYSCALE)\n",
        "# print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VeQ8YyfqHgYW"
      },
      "outputs": [],
      "source": [
        "# actual_x, actual_y =tfParse(test_x, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "c1hGy4M6FyuV"
      },
      "outputs": [],
      "source": [
        "# full_img_lst[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "agKhRncmBX39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b07d9ea-69c8-425e-ab00-13a0b8120cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "\n",
            "Size of training set = 1231\n",
            "Size of test set = 361\n",
            "Number of epochs = 100\n",
            "Batch size = 10\n",
            "Number of training steps per epoch = 124\n",
            "Number of test steps per epoch = 37\n",
            "\n",
            "Epoch 1/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9883 - iouMetric: 0.0078 - dice_coef: 0.0156"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 384s 3s/step - loss: 0.1023 - accuracy: 0.9883 - iouMetric: 0.0078 - dice_coef: 0.0156\n",
            "Epoch 2/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0526 - accuracy: 0.9959 - iouMetric: 0.0793 - dice_coef: 0.1453"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 200s 2s/step - loss: 0.0525 - accuracy: 0.9958 - iouMetric: 0.0787 - dice_coef: 0.1442\n",
            "Epoch 3/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0397 - accuracy: 0.9961 - iouMetric: 0.1141 - dice_coef: 0.2023"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 200s 2s/step - loss: 0.0397 - accuracy: 0.9961 - iouMetric: 0.1139 - dice_coef: 0.2019\n",
            "Epoch 4/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9962 - iouMetric: 0.1273 - dice_coef: 0.2220"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 200s 2s/step - loss: 0.0337 - accuracy: 0.9962 - iouMetric: 0.1273 - dice_coef: 0.2220\n",
            "Epoch 5/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9963 - iouMetric: 0.1465 - dice_coef: 0.2501"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 200s 2s/step - loss: 0.0303 - accuracy: 0.9963 - iouMetric: 0.1465 - dice_coef: 0.2501\n",
            "Epoch 6/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9964 - iouMetric: 0.1502 - dice_coef: 0.2575"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 200s 2s/step - loss: 0.0279 - accuracy: 0.9964 - iouMetric: 0.1502 - dice_coef: 0.2575\n",
            "Epoch 7/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0263 - accuracy: 0.9965 - iouMetric: 0.1625 - dice_coef: 0.2742"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 201s 2s/step - loss: 0.0263 - accuracy: 0.9965 - iouMetric: 0.1619 - dice_coef: 0.2734\n",
            "Epoch 8/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0250 - accuracy: 0.9965 - iouMetric: 0.1684 - dice_coef: 0.2829"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 200s 2s/step - loss: 0.0250 - accuracy: 0.9965 - iouMetric: 0.1671 - dice_coef: 0.2808\n",
            "Epoch 9/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0241 - accuracy: 0.9966 - iouMetric: 0.1701 - dice_coef: 0.2862"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 201s 2s/step - loss: 0.0241 - accuracy: 0.9966 - iouMetric: 0.1697 - dice_coef: 0.2856\n",
            "Epoch 10/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0232 - accuracy: 0.9966 - iouMetric: 0.1808 - dice_coef: 0.3010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 200s 2s/step - loss: 0.0232 - accuracy: 0.9966 - iouMetric: 0.1815 - dice_coef: 0.3020\n",
            "Epoch 11/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0225 - accuracy: 0.9966 - iouMetric: 0.1828 - dice_coef: 0.3049"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 201s 2s/step - loss: 0.0225 - accuracy: 0.9966 - iouMetric: 0.1816 - dice_coef: 0.3030\n",
            "Epoch 12/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0217 - accuracy: 0.9967 - iouMetric: 0.1857 - dice_coef: 0.3086"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 201s 2s/step - loss: 0.0217 - accuracy: 0.9967 - iouMetric: 0.1844 - dice_coef: 0.3066\n",
            "Epoch 13/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0209 - accuracy: 0.9967 - iouMetric: 0.1949 - dice_coef: 0.3202"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 201s 2s/step - loss: 0.0209 - accuracy: 0.9967 - iouMetric: 0.1935 - dice_coef: 0.3180\n",
            "Epoch 14/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0205 - accuracy: 0.9967 - iouMetric: 0.1932 - dice_coef: 0.3190"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 201s 2s/step - loss: 0.0205 - accuracy: 0.9967 - iouMetric: 0.1935 - dice_coef: 0.3195\n",
            "Epoch 15/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0200 - accuracy: 0.9968 - iouMetric: 0.1992 - dice_coef: 0.3278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 201s 2s/step - loss: 0.0200 - accuracy: 0.9968 - iouMetric: 0.1999 - dice_coef: 0.3288\n",
            "Epoch 16/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9969 - iouMetric: 0.2217 - dice_coef: 0.3574"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 202s 2s/step - loss: 0.0191 - accuracy: 0.9969 - iouMetric: 0.2217 - dice_coef: 0.3574\n",
            "Epoch 17/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0187 - accuracy: 0.9969 - iouMetric: 0.2304 - dice_coef: 0.3693"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 201s 2s/step - loss: 0.0187 - accuracy: 0.9969 - iouMetric: 0.2301 - dice_coef: 0.3690\n",
            "Epoch 18/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9970 - iouMetric: 0.2378 - dice_coef: 0.3792"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 202s 2s/step - loss: 0.0181 - accuracy: 0.9970 - iouMetric: 0.2378 - dice_coef: 0.3792\n",
            "Epoch 19/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9969 - iouMetric: 0.2326 - dice_coef: 0.3717"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 201s 2s/step - loss: 0.0178 - accuracy: 0.9969 - iouMetric: 0.2326 - dice_coef: 0.3717\n",
            "Epoch 20/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0173 - accuracy: 0.9971 - iouMetric: 0.2522 - dice_coef: 0.3974"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 202s 2s/step - loss: 0.0173 - accuracy: 0.9971 - iouMetric: 0.2508 - dice_coef: 0.3952\n",
            "Epoch 21/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0169 - accuracy: 0.9971 - iouMetric: 0.2540 - dice_coef: 0.3977"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 205s 2s/step - loss: 0.0169 - accuracy: 0.9971 - iouMetric: 0.2535 - dice_coef: 0.3970\n",
            "Epoch 22/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9971 - iouMetric: 0.2561 - dice_coef: 0.4024"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 206s 2s/step - loss: 0.0167 - accuracy: 0.9971 - iouMetric: 0.2561 - dice_coef: 0.4024\n",
            "Epoch 23/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0162 - accuracy: 0.9973 - iouMetric: 0.2707 - dice_coef: 0.4185"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 207s 2s/step - loss: 0.0162 - accuracy: 0.9973 - iouMetric: 0.2712 - dice_coef: 0.4192\n",
            "Epoch 24/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0158 - accuracy: 0.9972 - iouMetric: 0.2758 - dice_coef: 0.4254"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 206s 2s/step - loss: 0.0158 - accuracy: 0.9972 - iouMetric: 0.2771 - dice_coef: 0.4268\n",
            "Epoch 25/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0158 - accuracy: 0.9972 - iouMetric: 0.2631 - dice_coef: 0.4097"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 207s 2s/step - loss: 0.0158 - accuracy: 0.9972 - iouMetric: 0.2659 - dice_coef: 0.4125\n",
            "Epoch 26/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0151 - accuracy: 0.9974 - iouMetric: 0.2963 - dice_coef: 0.4515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 208s 2s/step - loss: 0.0151 - accuracy: 0.9974 - iouMetric: 0.2951 - dice_coef: 0.4499\n",
            "Epoch 27/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0149 - accuracy: 0.9974 - iouMetric: 0.2974 - dice_coef: 0.4522"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 208s 2s/step - loss: 0.0149 - accuracy: 0.9974 - iouMetric: 0.2962 - dice_coef: 0.4507\n",
            "Epoch 28/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0149 - accuracy: 0.9973 - iouMetric: 0.2896 - dice_coef: 0.4429"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 212s 2s/step - loss: 0.0149 - accuracy: 0.9973 - iouMetric: 0.2909 - dice_coef: 0.4444\n",
            "Epoch 29/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0144 - accuracy: 0.9974 - iouMetric: 0.3107 - dice_coef: 0.4678"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0144 - accuracy: 0.9974 - iouMetric: 0.3082 - dice_coef: 0.4643\n",
            "Epoch 30/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9974 - iouMetric: 0.2998 - dice_coef: 0.4536"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 209s 2s/step - loss: 0.0144 - accuracy: 0.9974 - iouMetric: 0.2998 - dice_coef: 0.4536\n",
            "Epoch 31/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0138 - accuracy: 0.9975 - iouMetric: 0.3254 - dice_coef: 0.4844"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0138 - accuracy: 0.9975 - iouMetric: 0.3232 - dice_coef: 0.4816\n",
            "Epoch 32/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9976 - iouMetric: 0.3273 - dice_coef: 0.4865"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0135 - accuracy: 0.9976 - iouMetric: 0.3273 - dice_coef: 0.4865\n",
            "Epoch 33/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0133 - accuracy: 0.9975 - iouMetric: 0.3291 - dice_coef: 0.4888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0133 - accuracy: 0.9975 - iouMetric: 0.3283 - dice_coef: 0.4878\n",
            "Epoch 34/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0131 - accuracy: 0.9976 - iouMetric: 0.3418 - dice_coef: 0.5029"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 208s 2s/step - loss: 0.0131 - accuracy: 0.9976 - iouMetric: 0.3407 - dice_coef: 0.5016\n",
            "Epoch 35/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9976 - iouMetric: 0.3417 - dice_coef: 0.5031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 214s 2s/step - loss: 0.0129 - accuracy: 0.9976 - iouMetric: 0.3417 - dice_coef: 0.5031\n",
            "Epoch 36/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0127 - accuracy: 0.9977 - iouMetric: 0.3523 - dice_coef: 0.5149"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 204s 2s/step - loss: 0.0127 - accuracy: 0.9977 - iouMetric: 0.3518 - dice_coef: 0.5144\n",
            "Epoch 37/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0122 - accuracy: 0.9978 - iouMetric: 0.3752 - dice_coef: 0.5390"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 207s 2s/step - loss: 0.0122 - accuracy: 0.9978 - iouMetric: 0.3731 - dice_coef: 0.5362\n",
            "Epoch 38/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0124 - accuracy: 0.9977 - iouMetric: 0.3573 - dice_coef: 0.5205"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 206s 2s/step - loss: 0.0124 - accuracy: 0.9977 - iouMetric: 0.3589 - dice_coef: 0.5220\n",
            "Epoch 39/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0121 - accuracy: 0.9977 - iouMetric: 0.3653 - dice_coef: 0.5289"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 209s 2s/step - loss: 0.0121 - accuracy: 0.9977 - iouMetric: 0.3669 - dice_coef: 0.5305\n",
            "Epoch 40/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0118 - accuracy: 0.9978 - iouMetric: 0.3829 - dice_coef: 0.5484"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 208s 2s/step - loss: 0.0118 - accuracy: 0.9978 - iouMetric: 0.3826 - dice_coef: 0.5481\n",
            "Epoch 41/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0115 - accuracy: 0.9979 - iouMetric: 0.3908 - dice_coef: 0.5563"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 207s 2s/step - loss: 0.0115 - accuracy: 0.9979 - iouMetric: 0.3919 - dice_coef: 0.5574\n",
            "Epoch 42/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0116 - accuracy: 0.9978 - iouMetric: 0.3802 - dice_coef: 0.5457"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 203s 2s/step - loss: 0.0116 - accuracy: 0.9978 - iouMetric: 0.3784 - dice_coef: 0.5436\n",
            "Epoch 43/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9978 - iouMetric: 0.3812 - dice_coef: 0.5462"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 203s 2s/step - loss: 0.0115 - accuracy: 0.9978 - iouMetric: 0.3812 - dice_coef: 0.5462\n",
            "Epoch 44/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9979 - iouMetric: 0.3921 - dice_coef: 0.5586"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 203s 2s/step - loss: 0.0112 - accuracy: 0.9979 - iouMetric: 0.3921 - dice_coef: 0.5586\n",
            "Epoch 45/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0111 - accuracy: 0.9979 - iouMetric: 0.3991 - dice_coef: 0.5654"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 214s 2s/step - loss: 0.0111 - accuracy: 0.9979 - iouMetric: 0.3976 - dice_coef: 0.5637\n",
            "Epoch 46/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9979 - iouMetric: 0.3999 - dice_coef: 0.5654"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 202s 2s/step - loss: 0.0110 - accuracy: 0.9979 - iouMetric: 0.3999 - dice_coef: 0.5654\n",
            "Epoch 47/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0108 - accuracy: 0.9979 - iouMetric: 0.3997 - dice_coef: 0.5650"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0108 - accuracy: 0.9979 - iouMetric: 0.3999 - dice_coef: 0.5653\n",
            "Epoch 48/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0107 - accuracy: 0.9979 - iouMetric: 0.4072 - dice_coef: 0.5732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 204s 2s/step - loss: 0.0107 - accuracy: 0.9979 - iouMetric: 0.4086 - dice_coef: 0.5745\n",
            "Epoch 49/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0108 - accuracy: 0.9979 - iouMetric: 0.3971 - dice_coef: 0.5636"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0108 - accuracy: 0.9979 - iouMetric: 0.3958 - dice_coef: 0.5622\n",
            "Epoch 50/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0106 - accuracy: 0.9979 - iouMetric: 0.4039 - dice_coef: 0.5702"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 207s 2s/step - loss: 0.0106 - accuracy: 0.9979 - iouMetric: 0.4024 - dice_coef: 0.5685\n",
            "Epoch 51/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9979 - iouMetric: 0.4112 - dice_coef: 0.5770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 208s 2s/step - loss: 0.0104 - accuracy: 0.9979 - iouMetric: 0.4112 - dice_coef: 0.5770\n",
            "Epoch 52/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0102 - accuracy: 0.9980 - iouMetric: 0.4233 - dice_coef: 0.5907"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 207s 2s/step - loss: 0.0102 - accuracy: 0.9980 - iouMetric: 0.4239 - dice_coef: 0.5914\n",
            "Epoch 53/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9980 - iouMetric: 0.4360 - dice_coef: 0.6020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0099 - accuracy: 0.9980 - iouMetric: 0.4360 - dice_coef: 0.6020\n",
            "Epoch 54/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0099 - accuracy: 0.9980 - iouMetric: 0.4308 - dice_coef: 0.5968"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 207s 2s/step - loss: 0.0099 - accuracy: 0.9980 - iouMetric: 0.4274 - dice_coef: 0.5920\n",
            "Epoch 55/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0098 - accuracy: 0.9981 - iouMetric: 0.4286 - dice_coef: 0.5942"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 207s 2s/step - loss: 0.0098 - accuracy: 0.9981 - iouMetric: 0.4287 - dice_coef: 0.5942\n",
            "Epoch 56/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0098 - accuracy: 0.9980 - iouMetric: 0.4300 - dice_coef: 0.5964"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 207s 2s/step - loss: 0.0098 - accuracy: 0.9980 - iouMetric: 0.4285 - dice_coef: 0.5947\n",
            "Epoch 57/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0102 - accuracy: 0.9979 - iouMetric: 0.4008 - dice_coef: 0.5663"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 207s 2s/step - loss: 0.0102 - accuracy: 0.9979 - iouMetric: 0.4041 - dice_coef: 0.5689\n",
            "Epoch 58/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0095 - accuracy: 0.9981 - iouMetric: 0.4438 - dice_coef: 0.6102"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0095 - accuracy: 0.9981 - iouMetric: 0.4415 - dice_coef: 0.6075\n",
            "Epoch 59/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0094 - accuracy: 0.9981 - iouMetric: 0.4389 - dice_coef: 0.6052"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 211s 2s/step - loss: 0.0094 - accuracy: 0.9981 - iouMetric: 0.4403 - dice_coef: 0.6064\n",
            "Epoch 60/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0092 - accuracy: 0.9981 - iouMetric: 0.4584 - dice_coef: 0.6249"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 212s 2s/step - loss: 0.0092 - accuracy: 0.9981 - iouMetric: 0.4595 - dice_coef: 0.6258\n",
            "Epoch 61/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0093 - accuracy: 0.9981 - iouMetric: 0.4413 - dice_coef: 0.6075"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 204s 2s/step - loss: 0.0093 - accuracy: 0.9981 - iouMetric: 0.4412 - dice_coef: 0.6075\n",
            "Epoch 62/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0092 - accuracy: 0.9981 - iouMetric: 0.4467 - dice_coef: 0.6130"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 204s 2s/step - loss: 0.0092 - accuracy: 0.9981 - iouMetric: 0.4464 - dice_coef: 0.6127\n",
            "Epoch 63/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0090 - accuracy: 0.9982 - iouMetric: 0.4539 - dice_coef: 0.6193"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 203s 2s/step - loss: 0.0090 - accuracy: 0.9982 - iouMetric: 0.4552 - dice_coef: 0.6205\n",
            "Epoch 64/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0091 - accuracy: 0.9981 - iouMetric: 0.4433 - dice_coef: 0.6100"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 204s 2s/step - loss: 0.0091 - accuracy: 0.9981 - iouMetric: 0.4438 - dice_coef: 0.6104\n",
            "Epoch 65/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0087 - accuracy: 0.9982 - iouMetric: 0.4632 - dice_coef: 0.6281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 205s 2s/step - loss: 0.0088 - accuracy: 0.9982 - iouMetric: 0.4626 - dice_coef: 0.6275\n",
            "Epoch 66/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0098 - accuracy: 0.9979 - iouMetric: 0.3991 - dice_coef: 0.5643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 215s 2s/step - loss: 0.0098 - accuracy: 0.9979 - iouMetric: 0.4005 - dice_coef: 0.5656\n",
            "Epoch 67/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9981 - iouMetric: 0.4410 - dice_coef: 0.6063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 215s 2s/step - loss: 0.0090 - accuracy: 0.9981 - iouMetric: 0.4410 - dice_coef: 0.6063\n",
            "Epoch 68/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9982 - iouMetric: 0.4584 - dice_coef: 0.6245"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 213s 2s/step - loss: 0.0087 - accuracy: 0.9982 - iouMetric: 0.4584 - dice_coef: 0.6245\n",
            "Epoch 69/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0086 - accuracy: 0.9982 - iouMetric: 0.4671 - dice_coef: 0.6316"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 214s 2s/step - loss: 0.0086 - accuracy: 0.9982 - iouMetric: 0.4675 - dice_coef: 0.6320\n",
            "Epoch 70/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0084 - accuracy: 0.9982 - iouMetric: 0.4710 - dice_coef: 0.6354"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 204s 2s/step - loss: 0.0084 - accuracy: 0.9982 - iouMetric: 0.4731 - dice_coef: 0.6371\n",
            "Epoch 71/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0083 - accuracy: 0.9983 - iouMetric: 0.4777 - dice_coef: 0.6426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0083 - accuracy: 0.9983 - iouMetric: 0.4770 - dice_coef: 0.6420\n",
            "Epoch 72/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0084 - accuracy: 0.9982 - iouMetric: 0.4737 - dice_coef: 0.6391"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 212s 2s/step - loss: 0.0084 - accuracy: 0.9982 - iouMetric: 0.4746 - dice_coef: 0.6400\n",
            "Epoch 73/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0083 - accuracy: 0.9982 - iouMetric: 0.4765 - dice_coef: 0.6408"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 206s 2s/step - loss: 0.0083 - accuracy: 0.9982 - iouMetric: 0.4764 - dice_coef: 0.6408\n",
            "Epoch 74/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0081 - accuracy: 0.9982 - iouMetric: 0.4830 - dice_coef: 0.6472"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 205s 2s/step - loss: 0.0081 - accuracy: 0.9982 - iouMetric: 0.4803 - dice_coef: 0.6442\n",
            "Epoch 75/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9981 - iouMetric: 0.4409 - dice_coef: 0.6057"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 214s 2s/step - loss: 0.0086 - accuracy: 0.9981 - iouMetric: 0.4409 - dice_coef: 0.6057\n",
            "Epoch 76/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9982 - iouMetric: 0.4848 - dice_coef: 0.6491"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 214s 2s/step - loss: 0.0080 - accuracy: 0.9982 - iouMetric: 0.4848 - dice_coef: 0.6491\n",
            "Epoch 77/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0079 - accuracy: 0.9983 - iouMetric: 0.4883 - dice_coef: 0.6529"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 208s 2s/step - loss: 0.0079 - accuracy: 0.9983 - iouMetric: 0.4871 - dice_coef: 0.6517\n",
            "Epoch 78/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0079 - accuracy: 0.9983 - iouMetric: 0.4903 - dice_coef: 0.6539"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0079 - accuracy: 0.9983 - iouMetric: 0.4866 - dice_coef: 0.6492\n",
            "Epoch 79/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0078 - accuracy: 0.9983 - iouMetric: 0.4899 - dice_coef: 0.6544"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 211s 2s/step - loss: 0.0078 - accuracy: 0.9983 - iouMetric: 0.4895 - dice_coef: 0.6541\n",
            "Epoch 80/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9983 - iouMetric: 0.4876 - dice_coef: 0.6502"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 209s 2s/step - loss: 0.0078 - accuracy: 0.9983 - iouMetric: 0.4876 - dice_coef: 0.6502\n",
            "Epoch 81/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0079 - accuracy: 0.9983 - iouMetric: 0.4858 - dice_coef: 0.6500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 208s 2s/step - loss: 0.0079 - accuracy: 0.9983 - iouMetric: 0.4862 - dice_coef: 0.6504\n",
            "Epoch 82/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9983 - iouMetric: 0.4919 - dice_coef: 0.6549"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 209s 2s/step - loss: 0.0076 - accuracy: 0.9983 - iouMetric: 0.4919 - dice_coef: 0.6549\n",
            "Epoch 83/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0077 - accuracy: 0.9983 - iouMetric: 0.4898 - dice_coef: 0.6538"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 209s 2s/step - loss: 0.0077 - accuracy: 0.9983 - iouMetric: 0.4900 - dice_coef: 0.6540\n",
            "Epoch 84/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0074 - accuracy: 0.9984 - iouMetric: 0.5077 - dice_coef: 0.6704"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0074 - accuracy: 0.9984 - iouMetric: 0.5081 - dice_coef: 0.6708\n",
            "Epoch 85/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0074 - accuracy: 0.9983 - iouMetric: 0.5071 - dice_coef: 0.6699"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0074 - accuracy: 0.9983 - iouMetric: 0.5072 - dice_coef: 0.6701\n",
            "Epoch 86/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9983 - iouMetric: 0.4964 - dice_coef: 0.6592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0075 - accuracy: 0.9983 - iouMetric: 0.4964 - dice_coef: 0.6592\n",
            "Epoch 87/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0073 - accuracy: 0.9984 - iouMetric: 0.5108 - dice_coef: 0.6727"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 211s 2s/step - loss: 0.0073 - accuracy: 0.9984 - iouMetric: 0.5111 - dice_coef: 0.6730\n",
            "Epoch 88/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9983 - iouMetric: 0.4929 - dice_coef: 0.6566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 208s 2s/step - loss: 0.0075 - accuracy: 0.9983 - iouMetric: 0.4929 - dice_coef: 0.6566\n",
            "Epoch 89/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9984 - iouMetric: 0.4996 - dice_coef: 0.6616"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 208s 2s/step - loss: 0.0073 - accuracy: 0.9984 - iouMetric: 0.4996 - dice_coef: 0.6616\n",
            "Epoch 90/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0073 - accuracy: 0.9983 - iouMetric: 0.5062 - dice_coef: 0.6692"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 208s 2s/step - loss: 0.0073 - accuracy: 0.9983 - iouMetric: 0.5063 - dice_coef: 0.6693\n",
            "Epoch 91/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0072 - accuracy: 0.9984 - iouMetric: 0.5107 - dice_coef: 0.6730"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 208s 2s/step - loss: 0.0072 - accuracy: 0.9984 - iouMetric: 0.5114 - dice_coef: 0.6737\n",
            "Epoch 92/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0070 - accuracy: 0.9984 - iouMetric: 0.5167 - dice_coef: 0.6781"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 211s 2s/step - loss: 0.0070 - accuracy: 0.9984 - iouMetric: 0.5182 - dice_coef: 0.6793\n",
            "Epoch 93/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0071 - accuracy: 0.9984 - iouMetric: 0.5153 - dice_coef: 0.6775"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 211s 2s/step - loss: 0.0071 - accuracy: 0.9984 - iouMetric: 0.5154 - dice_coef: 0.6776\n",
            "Epoch 94/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0071 - accuracy: 0.9984 - iouMetric: 0.5071 - dice_coef: 0.6696"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 211s 2s/step - loss: 0.0071 - accuracy: 0.9984 - iouMetric: 0.5063 - dice_coef: 0.6689\n",
            "Epoch 95/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0071 - accuracy: 0.9984 - iouMetric: 0.5117 - dice_coef: 0.6740"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0071 - accuracy: 0.9984 - iouMetric: 0.5102 - dice_coef: 0.6726\n",
            "Epoch 96/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9984 - iouMetric: 0.5168 - dice_coef: 0.6775"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 210s 2s/step - loss: 0.0070 - accuracy: 0.9984 - iouMetric: 0.5168 - dice_coef: 0.6775\n",
            "Epoch 97/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9984 - iouMetric: 0.5231 - dice_coef: 0.6837"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 211s 2s/step - loss: 0.0069 - accuracy: 0.9984 - iouMetric: 0.5231 - dice_coef: 0.6837\n",
            "Epoch 98/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0068 - accuracy: 0.9984 - iouMetric: 0.5267 - dice_coef: 0.6865"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 211s 2s/step - loss: 0.0068 - accuracy: 0.9984 - iouMetric: 0.5265 - dice_coef: 0.6864\n",
            "Epoch 99/100\n",
            "124/124 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9984 - iouMetric: 0.5239 - dice_coef: 0.6845"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 212s 2s/step - loss: 0.0068 - accuracy: 0.9984 - iouMetric: 0.5239 - dice_coef: 0.6845\n",
            "Epoch 100/100\n",
            "123/124 [============================>.] - ETA: 1s - loss: 0.0068 - accuracy: 0.9984 - iouMetric: 0.5250 - dice_coef: 0.6846"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/124 [==============================] - 214s 2s/step - loss: 0.0068 - accuracy: 0.9984 - iouMetric: 0.5259 - dice_coef: 0.6853\n",
            "Completed\n"
          ]
        }
      ],
      "source": [
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)  \n",
        "model_time = dt.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_folder = os.path.join(results_dir, model_time)\n",
        "os.makedirs(model_folder)\n",
        "\n",
        "tensorboard_folder = os.path.join(model_folder, \"tensorlogs\")\n",
        "os.makedirs(tensorboard_folder)\n",
        "\n",
        "ckpt_folder = os.path.join(model_folder, \"checkpoints\")\n",
        "os.makedirs(ckpt_folder)\n",
        "\n",
        "csv_logger_folder = os.path.join(model_folder, \"csv_logger\")\n",
        "os.makedirs(csv_logger_folder)\n",
        "\n",
        "hist_folder = os.path.join(model_folder, \"model_history\")\n",
        "os.makedirs(hist_folder)\n",
        "\n",
        "saved_model_folder = os.path.join(model_folder, \"Saved_model\")\n",
        "os.makedirs(saved_model_folder)\n",
        "\n",
        "model_params_folder = os.path.join(model_folder, \"model_params\")\n",
        "os.makedirs(model_params_folder)\n",
        "\n",
        "train_x, train_y = datasetPaths(\n",
        "    full_img_dir=train_full_img_dir,\n",
        "    mask_img_dir=train_mask_img_dir \n",
        ")\n",
        "\n",
        "test_x, test_y = datasetPaths(\n",
        "    full_img_dir=test_full_img_dir,\n",
        "    mask_img_dir=test_mask_img_dir\n",
        ")\n",
        "\n",
        "train_ds = makeTFDataset(shuffle=True, augument=True,\n",
        "x_paths_list = train_x, y_paths_list=train_y, batch_size=batch_size)\n",
        "\n",
        "\n",
        "test_ds = makeTFDataset(\n",
        "    shuffle=False,\n",
        "    augument=False,\n",
        "    x_paths_list=test_x,\n",
        "    y_paths_list=test_y,\n",
        "    batch_size=batch_size)      \n",
        "    \n",
        "unet = buildUnet()\n",
        "\n",
        "unet = compile_(model=unet)\n",
        "\n",
        "# ckpt_path = (ckpt_folder + f\"/{model_time}\" + \"_Epoch-{epoch:03d}\" + \"_IOU-{iouMetric:.8f\")\n",
        "ckpt_path = (ckpt_folder + f\"/{model_time}\")\n",
        "\n",
        "ckpt_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath= ckpt_path,\n",
        "    monitors= callback_monitor,\n",
        "    mode= callback_mode,\n",
        "    save_weights_only= ckpt_save_weights_only,\n",
        "    save_best_only=ckpt_save_best_only,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "es_callback = keras.callbacks.EarlyStopping(\n",
        "    patience= earlystop_patience,\n",
        "    monitor= callback_monitor,\n",
        "    mode= callback_mode,\n",
        "    restore_best_weights= restore_best_weights,\n",
        ")\n",
        "\n",
        "# TensorBoard\n",
        "tb_callback = keras.callbacks.TensorBoard(\n",
        "    log_dir=tensorboard_folder, histogram_freq=1, profile_batch=0\n",
        ")\n",
        "\n",
        "# CSV Logger\n",
        "csv_logger_path = os.path.join(csv_logger_folder, \"csv_logger.csv\")\n",
        "csv_logger = keras.callbacks.CSVLogger(\n",
        "    filename=csv_logger_path, separator=\",\", append=True\n",
        ")\n",
        "\n",
        "# Putting them together\n",
        "callbacks = [ckpt_callback, es_callback, tb_callback, csv_logger, checkpointer]\n",
        "\n",
        "train_steps = len(train_x) // batch_size\n",
        "test_steps = len(test_x) // batch_size\n",
        "\n",
        "if len(train_x) % batch_size != 0:\n",
        "    train_steps += 1\n",
        "if len(test_x) % batch_size != 0:\n",
        "    test_steps += 1\n",
        "\n",
        "print()\n",
        "print(f\"Size of training set = {len(train_x)}\")\n",
        "print(f\"Size of test set = {len(test_x)}\")\n",
        "print(f\"Number of epochs = {num_epochs}\")\n",
        "print(f\"Batch size = {batch_size}\")\n",
        "print(f\"Number of training steps per epoch = {train_steps}\")\n",
        "print(f\"Number of test steps per epoch = {test_steps}\")\n",
        "print()\n",
        "\n",
        "if validate:\n",
        "        history = unet.fit(\n",
        "            train_ds,\n",
        "            validation_data=test_ds,\n",
        "            epochs=num_epochs,\n",
        "            steps_per_epoch=train_steps,\n",
        "            validation_steps=test_steps,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1,\n",
        "        )\n",
        "elif not validate:\n",
        "    history = unet.fit(\n",
        "        train_ds,\n",
        "        epochs=num_epochs,\n",
        "        steps_per_epoch=train_steps,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "#y_hat = unet.evaluate(test_ds)\n",
        "\n",
        "print(\"Completed\")     \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " def makeTFDataset1( shuffle, augument, x_paths_list, y_paths_list, batch_size):\n",
        "        try:\n",
        "            ds = tf.data.Dataset.from_tensor_slices((x_paths_list, y_paths_list))\n",
        "            \n",
        "            if shuffle:\n",
        "                ds = ds.shuffle(buffer_size=len(x_paths_list))\n",
        "\n",
        "            ds = ds.map(tfParse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "            \n",
        "            if augument:\n",
        "                ds = ds.map(imgAugment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "            ds = ds.batch(batch_size=batch_size, drop_remainder=False)\n",
        "            #ds = ds.repeat()\n",
        "\n",
        "            return ds\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in make TFDataset {e}\")"
      ],
      "metadata": {
        "id": "MBPWHo79s1Hz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LCumD8yCBX3-"
      },
      "outputs": [],
      "source": [
        "test_ds = makeTFDataset1(\n",
        "    shuffle=False,\n",
        "    augument=False,\n",
        "    x_paths_list=test_x,\n",
        "    y_paths_list=test_y,\n",
        "    batch_size=batch_size)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "MGkGHRtCIlcu"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_ds = makeTFDataset1(shuffle=True, augument=True,\n",
        "x_paths_list = train_x, y_paths_list=train_y, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = unet.evaluate(test_ds, verbose=0)\n",
        "score "
      ],
      "metadata": {
        "id": "bRy91OTxNnym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed4dfe32-3ebb-4bc3-9e61-e8b387f32172"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.020543409511446953,\n",
              " 0.9967955350875854,\n",
              " 0.24503499269485474,\n",
              " 0.38203364610671997]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy {score[1]}\")\n",
        "print(f\"IOU Metrics {score[2]}\")\n",
        "print(f\"dice_coef {score[3]}\")"
      ],
      "metadata": {
        "id": "ihfzEvA6NAS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635f41de-9698-431e-a72f-37b474a20052"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.9967955350875854\n",
            "IOU Metrics 0.24503499269485474\n",
            "dice_coef 0.38203364610671997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 10"
      ],
      "metadata": {
        "id": "dtht3dayvWSI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/results/fit.zip /content/results/fit "
      ],
      "metadata": {
        "id": "IVeEZIevwLzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf6f8fc-a724-4b75-c6e2-8d568a970486"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results/fit/ (stored 0%)\n",
            "  adding: content/results/fit/20220820_221301/ (stored 0%)\n",
            "  adding: content/results/fit/20220820_221301/checkpoints/ (stored 0%)\n",
            "  adding: content/results/fit/20220820_221301/Saved_model/ (stored 0%)\n",
            "  adding: content/results/fit/20220820_221301/model_history/ (stored 0%)\n",
            "  adding: content/results/fit/20220820_221301/model_params/ (stored 0%)\n",
            "  adding: content/results/fit/20220820_221301/csv_logger/ (stored 0%)\n",
            "  adding: content/results/fit/20220820_221301/csv_logger/csv_logger.csv (deflated 52%)\n",
            "  adding: content/results/fit/20220820_221301/tensorlogs/ (stored 0%)\n",
            "  adding: content/results/fit/20220820_221301/tensorlogs/train/ (stored 0%)\n",
            "  adding: content/results/fit/20220820_221301/tensorlogs/train/events.out.tfevents.1661033590.485d4c6dd14f.76.0.v2 (deflated 64%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/results/fit.zip\")\n",
        "# files.download('model.weights.best.hdf5')"
      ],
      "metadata": {
        "id": "Ms8fiADKwq6i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "185eb64c-c32e-4919-fc03-4edfd528a1a1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_56adfa75-291d-4853-9e21-a67021ca7f13\", \"fit.zip\", 2016206)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadFullImg_1(path, dsize):\n",
        "        try:\n",
        "             \n",
        "            print(path)\n",
        "            img = cv2.imread(\"/content/gdrive/MyDrive/cbisddsm/Test_output_full/Mass-Test_P_00016_LEFT_CC_FULL__PRE.png\", cv2.IMREAD_GRAYSCALE)\n",
        "            print(type(img))\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "      \n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "            print(f'After norm_img')\n",
        "            print(f'type {norm_img.shape}')\n",
        "            full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "            print(f'After full_img')\n",
        "            print(f'type {full_img.shape}')\n",
        "            print(f'done for path {path} with shape {full_img.shape}')\n",
        "            return full_img\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"There is an error in loadFullImg {e}\")"
      ],
      "metadata": {
        "id": "A2Hu8b8_UMD2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadMaskImg_1(path, dsize):\n",
        "        try:\n",
        "            # if not isinstance(path, str):\n",
        "            #     path=path.decode()\n",
        "            print(path)\n",
        "            img = cv2.imread(\"/content/gdrive/MyDrive/cbisddsm/Test_output_mask/Mass-Test_P_00016_LEFT_CC_MASK_1__PRE.png\", cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "            mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "            print(f'done for path {path} with shape {mask_img.shape}')\n",
        "            return mask_img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in loadMaskIMG {e}\")"
      ],
      "metadata": {
        "id": "MN8ydZ_-UV74"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tfParse_1(x_path, y_path):\n",
        "        try:\n",
        "            def _parse(x_path, y_path):\n",
        "                x = loadFullImg_1(path=x_path, dsize=target_size)\n",
        "                y = loadMaskImg_1(path=y_path, dsize=target_size)\n",
        "                return x,y\n",
        "\n",
        "            x, y = tf.numpy_function(_parse, [x_path, y_path], [tf.float64, tf.float64])\n",
        "              \n",
        "            x.set_shape([target_size[0], target_size[0], 3])\n",
        "            y.set_shape([target_size[0], target_size[1], 1])\n",
        "\n",
        "            return x,y\n",
        "            \n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in tfParse {e}\")"
      ],
      "metadata": {
        "id": "wb2fsrPDUMK1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #model.load_weights('model.weights.best.hdf5')"
      ],
      "metadata": {
        "id": "06CumsaLV6JC"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_x, res_y = tfParse_1(test_x[i], test_y[i])"
      ],
      "metadata": {
        "id": "aRVx-4W1T0jO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05170921-86a5-4cc4-e1b5-7d355bf1d92e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/cbisddsm/Test_output_full/Mass-Test_P_00066_LEFT_MLO_FULL__PRE.png\n",
            "<class 'numpy.ndarray'>\n",
            "After norm_img\n",
            "type (224, 224)\n",
            "After full_img\n",
            "type (224, 224, 3)\n",
            "done for path /content/gdrive/MyDrive/cbisddsm/Test_output_full/Mass-Test_P_00066_LEFT_MLO_FULL__PRE.png with shape (224, 224, 3)\n",
            "/content/gdrive/MyDrive/cbisddsm/Test_output_mask/Mass-Test_P_00066_LEFT_MLO_MASK_1__PRE.png\n",
            "done for path /content/gdrive/MyDrive/cbisddsm/Test_output_mask/Mass-Test_P_00066_LEFT_MLO_MASK_1__PRE.png with shape (224, 224, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res_x.shape)\n",
        "print(res_y.shape)\n",
        "print(type(res_y.numpy())) \n",
        "print(res_x.numpy().shape)\n",
        "print(res_y.numpy().shape)"
      ],
      "metadata": {
        "id": "XMaOVHjUT6He",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b4db53d-f486-4ca3-dfbd-eded30b09d42"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n",
            "(224, 224, 1)\n",
            "<class 'numpy.ndarray'>\n",
            "(224, 224, 3)\n",
            "(224, 224, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (50,8))\n",
        "plt.imshow(res_x.numpy(), cmap=\"gray\")\n",
        "plt.title(f\"Before cropping \", x=0.5, y=-0.1)"
      ],
      "metadata": {
        "id": "hh-whdVrYM4j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "11948100-4a17-4fed-f2b3-21509a3f99ce"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, -0.1, 'Before cropping ')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3600x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (50,8))\n",
        "plt.imshow(res_y.numpy()[:,:,0], cmap=\"gray\")\n",
        "plt.title(f\"Before cropping \", x=0.5, y=-0.1)\n",
        "print(res_x.numpy().shape)"
      ],
      "metadata": {
        "id": "pVcmbNaQZDTX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "312cb66a-bc42-45f4-c286-9114f0fa0831"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3600x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# res_y.numpy()[:,:,0].shape"
      ],
      "metadata": {
        "id": "teGKIGb0IhFK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# res_x.numpy().shape"
      ],
      "metadata": {
        "id": "Qis1l2Zd_1a7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = unet.predict(test_ds)"
      ],
      "metadata": {
        "id": "qjA1jjBgTnMf"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type(prediction)"
      ],
      "metadata": {
        "id": "Hs8fB-GcJeq5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction.shape"
      ],
      "metadata": {
        "id": "U10ju5R8Jmxn"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction[0].shape"
      ],
      "metadata": {
        "id": "pIMrBwBPJj24"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (50,8))\n",
        "plt.imshow(prediction[i][:,:,0], cmap=\"gray\")\n",
        "plt.title(f\"Before cropping \", x=0.5, y=-0.1)\n",
        "print(res_x.numpy().shape)"
      ],
      "metadata": {
        "id": "X8GIuGP7Jq0I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "aa257fda-4397-4ca0-9299-e9c89cb65baf"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3600x576 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAHsCAYAAACaBQchAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5BkZ3nn+e+TWde+qbqR1G7rgpAt2IGZXRlrGcYLBHMzoMAWno3FYlksX2ZlJkyEHesNDwav8djriLHHlw3vjO0Vaw14BnOZBWyNLzOWWQ84dkcYCctCgAAB0urSdKtpWt2trltmPvtHnpOcSmV1VXfVq8qs/n4iMvLke05mvlnZVb9+L+c9kZlIkqRyWjtdAUmSdjvDVpKkwgxbSZIKM2wlSSrMsJUkqTDDVpKkwoqFbUS8NiK+EBEPR8TbS72PJEnjLkqcZxsRbeCLwD8EHgc+BbwpMz+37W8mSdKYmyr0ui8DHs7MrwBExAeAW4CRYRsRrqwhSZp0JzLzilE7SnUjXwU81nj8eFU2EBG3R8S9EXEvQLvdJiIKVUeSpDJarRbtdhvg0fWOKdWy3VBm3gHcAf2Wba/Xw6UjJUmTptfrbdhYLNWyfQK4pvH46qpsXQatJGlSbZRhpcL2U8ANEfGCiJgBbgXuKvRekiSNtSLdyJnZiYi3Af8RaAN3ZuZnS7yXJEnjrsipPxdcCWcjS5Im332ZedOoHa4gJUlSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVNhFh21EXBMRfx4Rn4uIz0bEj1flPxcRT0TE/dXt5u2rriRJk2dqC8/tAD+ZmZ+OiP3AfRFxd7Xv1zPzV7ZePUmSJt9Fh21mHgWOVttnIuLzwFXbVTFJknaLbRmzjYjrgO8APlkVvS0iHoiIOyPi4DrPuT0i7o2Ie7ejDpIkjavIzK29QMQ+4OPAL2bmRyLiMHACSOAXgCOZ+cMbvMbWKiFJ0s67LzNvGrVjSy3biJgGPgy8LzM/ApCZxzKzm5k94N3Ay7byHpIkTbqtzEYO4HeAz2fmrzXKjzQO+z7gwYuvniRJk28rs5H/G+AtwGci4v6q7B3AmyLiRvrdyI8AP7qlGkqSNOG2PGa7LZVwzFaSNPnKjNlKkqSNGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVNjUVl8gIh4BzgBdoJOZN0XEIeCDwHXAI8AbM/MbW30vSZIm0Xa1bP9uZt6YmTdVj98OfCwzbwA+Vj2WJOmSVKob+RbgvdX2e4E3FHofSZLG3naEbQJ/GhH3RcTtVdnhzDxabX8NODz8pIi4PSLujYh7t6EOkiSNrS2P2QKvyMwnIuJK4O6IeKi5MzMzInL4SZl5B3AHwKj9kiTtFltu2WbmE9X9ceCjwMuAYxFxBKC6P77V95EkaVJtKWwjYm9E7K+3ge8GHgTuAm6rDrsN+IOtvI8kSZNsq93Ih4GPRkT9Wr+Xmf8hIj4FfCgifgR4FHjjFt9HkqSJFZk7P1zqmK0kaRe4r3EK7BquICVJUmGGrSRJhRm2kiQVth3n2U6MaiLXeY3DGLYkaXe5ZMJ2OGhHBW9mEhEGriRpW+36sF2vNVuX1/ejgtbQlSRth10btsNh2gzdiFi3pZuZZCa9Xs9WriRpW+zqsG3eaq1Wa839cJjWYTu8LUnSxdp1YdtsyUYErVaLVqu15nHzuG63O+hChm8GbLN1W5dLknQxdl3YwtqgnZqaGgRuq9Wi3W4PuoebLdhm67fX6w1ep95fM3QlSRdq14XtcPdxM2RHhW2v1xuEazOA6+c2jzNoJUkXY1eF7XDQ1oHZbrfXhG2r1RqEZ91V3O12ByE8Kmjr1zdwJUkXateE7Xot2nq8tg7culu5Ds2ZmRkyk06nQ7fbZWVlZU2Ltx7jrcPZMVxJ0oXaNWFbG+46Hm7dTk9PDwKzHtMFWF5eptPpDEI2MwdBK0nSVuyasB1u2dbhOjc3x8zMDNPT07Tbbebn52m322u6h+tg7XQ6rK6u0ul0njWeW7eG68c1W7iSpI3smrCFtaf91K3Z2dlZ5ubmmJqaot1us2fPHqampgat1+XlZQCmp6fpdDosLi4CrAnV5rm6diNLki7UxIft8Hm1wxOjpqamBuO0wCB0m7OLO53O4NacONUM1LplGxFrzr8Fg1eSdH67YlByVMtzOHBrzXFa+GZQrq6usrq6uiZkmyE6HOSbuYKQJEmwC1q2TaNO9+l2uywtLQ3GYetJUsBgFnKn02F5eXkQtM1zbZvn5DZvkiRt1q4M2+aM5F6vtyZMp6enmZ2dHbRuu90u3W6XXq83WLqx+XrNe3j2eskGryRpI7sibIcvHJCZdLvdwRhsRAzCNiJYWlpiz549tFotFhcX6XQ6LC0trbnSTx28zVnJtnAlSRdjV4Qt8KwQrFuq9aziuht5ZWWFbrc7mChVn+pT71+v29iAlSRdrIkP22ZANmcJ16FaL2wxvDzj4uLioLxeKarucm62Zke1aOv3lSRpMyY+bOHZV+VpdgMDa9Y5roO00+kAzz51aLjbuLnwxaj3kyRpI7sibGvN82Pr1up6i1A0W8T14/Var+uFq6ErSdqMXRO2w+Otdbdwc9JTfdyokNxM0NqNLEm6GLsmbGFtADaXW+x0OoNu4rrFO7wwxfDpPxfT0pUkaZRdFbbw7CCsW7bNVaZ6vd5g4lStDtk6pIfHag1aSdLF2nVhO6w5Q7lu2UI/XIePg/VD1ZCVJF2sXRu2zSUXh8dzm2O4zePXG8uVJGkrdm3Y1pot1c1cHs9wlSRtt10ftk0GqSRpJ+yKS+xJkjTODFtJkgozbCVJKsywlSSpMMNWkqTCDFtJkgozbCVJKuySOs9Wfc01oYd5LrIkbb+LDtuIeBHwwUbR9cDPAgvA/wg8VZW/IzP/+KJrqG1xvoA933GGryRtXWzHH9OIaANPAH8b+CHgbGb+ygU837/oBY0K2o3C16scSdIFuy8zbxq1Y7u6kf8+8OXMfHSzLSg9N5rfx/B307wakutFS1I52zVB6lbg/Y3Hb4uIByLizog4OOoJEXF7RNwbEfduUx00ZDhom7dWq7Xmfviav+cLaUnShdlyN3JEzABPAi/JzGMRcRg4ASTwC8CRzPzhDV7DptM2awYnMAjV5v6m4X8HvV5vzWUHbd1K0oaKdiO/Dvh0Zh4DqO8BIuLdwB9uw3tok5ot02bgDoftqOv5NrcNV0naPtvRjfwmGl3IEXGkse/7gAe34T10AUZ1Gde34RCGtZOhbM1K0vbbUss2IvYC/xD40UbxL0fEjfS7kR8Z2qdCRo211o/X6z6uJ0ZFBN1uF7BVK0klbClsM/MZ4HlDZW/ZUo10wYaDdr1TfdYrH+5CHrUtSbp4riC1y4yaVTw86xi+GaS9Xm9wnEErSWUYtrvYeqf71IbHaCVJZXghgl1q1CSouhXbbOU2w3a9rmZJ0tYYtrvAZlqmtmAlaefYjbxLjFqUYtR5tnXodrvdNfeGsSSVY9juMqMWq4gIer0erVZrTbAOrxI16vmSpK0zbHeROlibi1LUj1utFr1ej06n86xjbNVKUlmG7S7TDNjhe/hm93LzeINWksoybHeh9YK23uc6yJL03DJsLzFet1aSnnuG7S61Xqt21KX1zncFIEnS1hm2l4j1AtSglaTyDNtdbLPBacBKUlmG7SXGYJWk557LNUqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVJhhK0lSYYatJEmFGbaSJBVm2EqSVNimwjYi7oyI4xHxYKPsUETcHRFfqu4PVuUREb8REQ9HxAMR8dJSlZckaRJstmX7HuC1Q2VvBz6WmTcAH6seA7wOuKG63Q781tarKUnS5NpU2GbmJ4CTQ8W3AO+ttt8LvKFR/rvZdw+wEBFHtqOykiRNoq2M2R7OzKPV9teAw9X2VcBjjeMer8okSbokTW3Hi2RmRkReyHMi4nb63cySJO1qW2nZHqu7h6v741X5E8A1jeOursrWyMw7MvOmzLxpC3WQJGnsbSVs7wJuq7ZvA/6gUf4D1azklwNPN7qbJUm65GyqGzki3g+8Grg8Ih4H3gX8c+BDEfEjwKPAG6vD/xi4GXgYOAf80DbXWZKkiRKZFzTUWqYSFzjeK0nSGLpvvaFRV5CSJKkww1aSpMIMW0mSCjNsJUkqzLCVJKkww1aSpMIMW0mSCjNsJUkqzLCVJKkww1aSpMIMW0mSCjNsJUkqzLCVJKkww1aSpMIMW0mSCjNsJUkqzLCVJKkww1aSpMIMW0mSCjNsJUkqzLCVJKkww1aSpMIMW0mSCjNsJUkqzLCVJKkww1aSpMIMW0mSCjNsJUkqzLCVJKkww1aSpMIMW0mSCjNsJUkqzLCVJKkww1aSpMIMW0mSCjNsJUkqzLCVJKkww1aSpMIMW0mSCjNsJUkqbMOwjYg7I+J4RDzYKPsXEfFQRDwQER+NiIWq/LqIWIyI+6vbb5esvCRJk2AzLdv3AK8dKrsb+JuZ+V8CXwR+urHvy5l5Y3V76/ZUU5KkybVh2GbmJ4CTQ2V/mpmd6uE9wNUF6iZJ0q6wHWO2Pwz8SePxCyLiryLi4xHxyvWeFBG3R8S9EXHvNtRBkqSxNbWVJ0fEO4EO8L6q6ChwbWZ+PSK+E/j9iHhJZp4efm5m3gHcUb1ObqUekiSNs4tu2UbEDwKvB96cmQmQmcuZ+fVq+z7gy8ALt6GekiRNrIsK24h4LfBTwPdm5rlG+RUR0a62rwduAL6yHRWVJGlSbdiNHBHvB14NXB4RjwPvoj/7eBa4OyIA7qlmHr8K+PmIWAV6wFsz8+TIF5Yk6RIRVQ/wzlbCMVtJ0uS7LzNvGrXDFaQkSSrMsJUkqTDDVpKkwgxbSZIKM2wlSSrMsK1EBNVpTJIkbSvDVpKkwra0NvKlqNn6HYdzlCVJ48+WbSUzLzg87XaWJG2GYStJUmF2I18ku5AlSZtly1aSpMJs2W5g1LisrVpJ0oWwZStJUmG2bDdgK1aStFW2bCVJKsywlSSpMMNWkqTCDNuCvLiBJAkMW0mSijNsC2m2aG3dStKlzbB9Dnj6kCRd2jzPthADVpJUs2UrSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJU2IZhGxF3RsTxiHiwUfZzEfFERNxf3W5u7PvpiHg4Ir4QEa8pVXFJkibFZlq27wFeO6L81zPzxur2xwAR8WLgVuAl1XN+MyLa21VZSZIm0YZhm5mfAE5u8vVuAT6QmcuZ+VXgYeBlW6ifJEkTbytjtm+LiAeqbuaDVdlVwGONYx6vyiRJumRdbNj+FvBtwI3AUeBXL/QFIuL2iLg3Iu69yDpIkjQRLipsM/NYZnYzswe8m292FT8BXNM49OqqbNRr3JGZN2XmTRdTB0mSJsVFhW1EHGk8/D6gnql8F3BrRMxGxAuAG4C/3FoVJUmabFMbHRAR7wdeDVweEY8D7wJeHRE3Agk8AvwoQGZ+NiI+BHwO6AA/lpndMlWXJGkyRGbudB2IiJ2vhCRJW3PfekOjriAlSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJU2NROV2C3i4hNHZeZhWsiSdophm1Bw0G7XvBm5pp9Bq8k7S6GbWF1iA7fj1KHbK/XW/NYkjTZDNvnQEQ869bUavWHznu93qCVm5mGriTtEhuGbUTcCbweOJ6Zf7Mq+yDwouqQBeBUZt4YEdcBnwe+UO27JzPfut2VngTNYG21WrRaLdrt9pr7OlhnZmaICFZXV+n1eqyurtLtdlldXSUzB2E7fC9Jmgybadm+B/iXwO/WBZn5/fV2RPwq8HTj+C9n5o3bVcFJ1OwybrVaTE1N0W63mZmZGTxutVqDluvc3BwAU1NT9Ho9Wq0W3W4X6Ld26xZvfXzN0JWkybBh2GbmJ6oW67NEP1XeCPy97a3WZGqGbEQMQnZ+fp6ZmRn279/PzMwM7XZ70JIFmJ+fB6DT6ZCZLC4u0ul0OHv27KCFW9/X4dtk6ErSeNvqmO0rgWOZ+aVG2Qsi4q+A08DPZOZfjHpiRNwO3L7F9x8bzXHYutt4amqKqakpZmdnmZmZYc+ePczNzdFutwEG4Tk3N0er1WJlZYXMpN1u0+l0BsfU4dvr9da8j6ErSZNhq2H7JuD9jcdHgWsz8+sR8Z3A70fESzLz9PATM/MO4A6AiJjolBjVop2enmZubo7p6WkOHDjAnj17uOKKK9izZ8/geSsrK/R6PaanpweP69fJTM6ePcvS0hInT55keXl50JXc7Xbp9XqDljCwZmKVJGm8XHTYRsQU8I+A76zLMnMZWK6274uILwMvBO7dYj0nRnNC1NzcHHv27OF5z3see/fuZWFhgdnZ2cEEqWbLtNfrsby8PGi99no9pqamWFxcZHFxkYhgeXl5MJYLDF6jGbQGriSNn620bP8B8FBmPl4XRMQVwMnM7EbE9cANwFe2WMeJ0Zx93G63ueyyyzh06BDXXnstCwsLTE9PMz09zfz8PFNTU8zPzxMRnDt3jk6nM7ivx2Xrcdvl5WXOnj3L6uoqq6urLC0tDQK55kxlSRpfmzn15/3Aq4HLI+Jx4F2Z+TvAraztQgZ4FfDzEbEK9IC3ZubJ7a3yeGq2aOvbzMwM8/Pz7N+/n0OHDjE/P8/09PRgglTdCp2a6n8N8/PzzwrLubk5zp49y/z8PJ1Oh6WlpcF4bn1+rkErSeNtM7OR37RO+Q+OKPsw8OGtV2tyDJ9LW0+Kqmch79+/n8OHD/Mt3/ItHDx4kNnZ2cGEp2eeeYbV1dVBANcTpWZmZpiammJmZoZz587RarU4deoUmcmpU6cGLdtut0u32x15WpAkaXy4gtQWjJoYVc863rNnDwcPHuTQoUNrZiBn5iCY6+7iOihnZ2eZnp7msssuG4zRTk9Ps7CwQERw6tQpgMHEqXoBjOa4bc1WriSND8P2Io26yEA9A3lhYYEDBw5w+PBhjhw5wt69e2m322Qm3W530BLudrt0Oh263S6tVov5+Xnm5uY4cuQI3W6Xo0ePMjMzw5VXXsns7CzPPPMMU1NTnD17lrNnz9LpdJ61AAY4M1mSxo1he5GaLcnhlu3c3Bz79u0brBi1sLDAFVdcMVh6sV6kYmFhYXAeLfRbtnNzc8zOzg4mQy0vL7O4uDho5c7Pz3PgwAGgfw5uRAxOGapPCTJoJWm8GLZbUAduc1nG2dlZ9u3bx4EDB5idnaXVanHllVdy9dVXc+bMGZaXlwen8ExPTw/Op+12u8zOzjI7OzuYpbyyssLi4iJnzpyh0+kM9l122WVrFsFYWloadE/bnSxJ48ew3QbN9Ysjgssuu4xv/dZv5YorruDAgQODNY8PHjxIq9Vas2jFysoKs7OzrKysDCY7HTt2jJWVlcH5uPU++ObqVHVLunlhg+bFDwxZSRofhu0W1V3DzdnABw4c4MiRIxw6dIh9+/YNWrALCwvs2bNn0HJ96qmn1ixYcebMGVZWVjh+/PhgHLfdbg9asM3TiuqgrWc/dzqdZ13Gz8CVpPFg2G6Tujv3zJkzHD16dHDxgcsuu4x9+/axsLAwWKTi5MmTdLtdlpaWBuO33W6XU6dODcZhM3PQ7dxut2m324OJVidPnhw5QavuRm4Gv6ErSTvPsN0Gdeu2nqh04sQJpqenueaaa4iIwfm2Z8+eZXFxkW984xusrKwMFqWoZyTXq0Tt37+fzBych9tut5mdnWX//v2DGcjD6rCtJ0jZupWk8WHYblEdatCfDVx3Ay8tLTEzM8OTTz7J8vIyz3/+8weTpurZxM8888xgecZ2u83ll1++ZrnG+tq2+/btY3V1lUcffXRw2s/i4iIrKyuDixHUY8aGqySNH8N2G9Xdt6dPn2ZpaYmpqSlOnTo1OO3nuuuuY2Fhgb179zI1NcXS0tLgdJ06VDudziBIoR/m9QSqp556iqWlJZaWlgZBW4etQStJ48uw3QbNkGuu6vTUU09x9uxZHnroIRYXF5mdnaXX63HixIk1Y7T1ReSbs4zr4F5ZWeHUqVMsLy8PwrW+GMHp06dZWVnh3LlzgwUymq1iw1eSxoNhu43qcKtbq/UVe44dO0a73eb6669nfn6ec+fOsbKywunTpwfjtdBf1GJqaoq9e/cOTgNaXV3l6aefXjORqtPpsLy8zMrKCsvLy4NwH9WVbOBK0s4zbLfJcKjVQdnr9fjqV7/KiRMn6PV6gwvIt9vtQaDWt7pVe+DAAVZWVvjKV74yuLxeHaaLi4ucPHlyMG5bt4xHjdsatJI0HgzbLTrfik11V/CpU6c4d+4c+/fv5/Tp01x++eWDi8g3r0ubmYM1lJeXlzl58uRgxan69ZaWljh37tygRdtsGRu0kjSeDNttUAfb8FrJzVnKq6urHD9+fHDFnrm5OaanpwcLWkD/erbAYAWp+r6+wk89Zlu3aFdWVmzNStIEMGy32ajArbt4FxcX6fV6zM3NDa5j22q1WFpaAhicI7uyssLKysrgyj71rOW6FVsv32jQStJkMGy3wair/wwvPFF3Adddv/XF4utu5F6vx9RU/+vIzMFqU3W4NmcZNy8Yb9BK0vgzbAupl05shmAdkufOnRtch7Y+Dhh0J9fXvV1eXh6cStQMV1u0kjRZDNstGNVlXJc1Jz01TwlqHr+0tLTmObU6TIdbsM3XbN5LksabYXuRhgNylOHzXZuPI2LNZfOa6xjXoTp8b8hK0mQybC9S88Lxw63TulU66jnrBebw80ctTGHIStJkMmwLaJ5722yxrnc/vL2Zx5KkyWHYbtFw13CzvO4ebh7XvF8vQA1WSdpdDNsdYMhK0qXFsN2C8y3VCN9cpGKj15Ak7W6tjQ/RZmxmEpPnxkrSpcmw3YLzjcc2Nc+RPd9xkqTdybAtzNasJMkx24vUHIsdHpddr8UrSbo02bLdRucL4JrBK0mXHlu2F2l4JnJtuGxUN7KBK0mXFlu222DUQhX1tkErSbJluwV1cNZLMtb355uVLEm69Bi226AZtOvtlyRdugzbbWKgSpLW45itJEmFGbaSJBVm2EqSVJhhK0lSYRuGbURcExF/HhGfi4jPRsSPV+WHIuLuiPhSdX+wKo+I+I2IeDgiHoiIl5b+EJIkjbPNtGw7wE9m5ouBlwM/FhEvBt4OfCwzbwA+Vj0GeB1wQ3W7Hfitba+1JEkTZMOwzcyjmfnpavsM8HngKuAW4L3VYe8F3lBt3wL8bvbdAyxExJFtr7kkSRPigsZsI+I64DuATwKHM/NotetrwOFq+yrgscbTHq/KJEm6JG16UYuI2Ad8GPiJzDzdXHA/MzMiLmhVh4i4nX43syRJu9qmWrYRMU0/aN+XmR+pio/V3cPV/fGq/AngmsbTr67K1sjMOzLzpsy86WIrL0nSJNjMbOQAfgf4fGb+WmPXXcBt1fZtwB80yn+gmpX8cuDpRnezJEmXnNhoTd+IeAXwF8BngF5V/A7647YfAq4FHgXemJknq3D+l8BrgXPAD2XmvRu8hwsLS5Im3X3r9dZuGLbPBcNWkrQLrBu2riAlSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYUZtpIkFWbYSpJUmGErSVJhhq0kSYWNTdi2WmNTFUmSNi0iiIjzHmPCSZJU2NROV6ByotfrPQOc2OmKbNHlTPZnmPT6w+R/hkmvP/gZxsGk1x8m6DNkZr35/PWOicZBOyoi7s3Mm3a6Hlsx6Z9h0usPk/8ZJr3+4GcYB5Nef9gdn6HJbmRJkgozbCVJKmycwvaOna7ANpj0zzDp9YfJ/wyTXn/wM4yDSa8/7I7PMDA2Y7aSJO1W49SylSRpVzJsJUkqbCzCNiJeGxFfiIiHI+LtO12fjUTENRHx5xHxuYj4bET8eFX+cxHxRETcX91u3um6nk9EPBIRn6nqem9Vdigi7o6IL1X3B3e6nqNExIsaP+f7I+J0RPzEuH8HEXFnRByPiAcbZSN/5tH3G9XvxQMR8dKdq/k3rfMZ/kVEPFTV86MRsVCVXxcRi43v47d3ruaDuo6q/9DiJIQAAAkmSURBVLr/biLip6vv4AsR8ZqdqfVa63yGDzbq/0hE3F+Vj+N3sN7f0In6XbggmbmjN6ANfBm4HpgB/hp48U7Xa4M6HwFeWm3vB74IvBj4OeB/3un6XcDneAS4fKjsl4G3V9tvB35pp+u5yX9DX6N/QvlYfwfAq4CXAg9u9DMHbgb+BAjg5cAnd7r+5/kM3w1MVdu/1PgM1zWPG4fbOvUf+e+m+r3+a2AWeEH1t6o9jp9haP+vAj87xt/Ben9DJ+p34UJu49CyfRnwcGZ+JTNXgA8At+xwnc4rM49m5qer7TPA54GrdrZW2+YW4L3V9nuBN+xgXTbr7wNfzsxHd7oiG8nMTwAnh4rX+5nfAvxu9t0DLETEkeempusb9Rky808zs1M9vAe4+jmv2Cat8x2s5xbgA5m5nJlfBR6m/zdrR53vM0R/kd43Au9/Tit1Ac7zN3SifhcuxDiE7VXAY43HjzNBwRUR1wHfAXyyKnpb1c1x57h2wTYk8KcRcV9E3F6VHc7Mo9X214DDO1O1C3Ira/+wTNJ3AOv/zCf1d+OH6bdCai+IiL+KiI9HxCt3qlKbMOrfzSR+B68EjmXmlxplY/sdDP0N3W2/CwPjELYTKyL2AR8GfiIzTwO/BXwbcCNwlH5Xzjh7RWa+FHgd8GMR8armzuz334z1uWERMQN8L/DvqqJJ+w7WmISf+flExDuBDvC+qugocG1mfgfwPwG/FxEHdqp+5zHR/26GvIm1//kc2+9gxN/QgUn/XRg2DmH7BHBN4/HVVdlYi4hp+v9I3peZHwHIzGOZ2c3MHvBuxqC76Xwy84nq/jjwUfr1PVZ3z1T3x3euhpvyOuDTmXkMJu87qKz3M5+o342I+EHg9cCbqz+UVN2vX6+276M/5vnCHavkOs7z72bSvoMp4B8BH6zLxvU7GPU3lF3yuzDKOITtp4AbIuIFVSvlVuCuHa7TeVVjIr8DfD4zf61R3hxD+D7gweHnjouI2BsR++tt+hNcHqT/s7+tOuw24A92poabtuZ/8ZP0HTSs9zO/C/iBaibmy4GnG11sYyUiXgv8FPC9mXmuUX5FRLSr7euBG4Cv7Ewt13eefzd3AbdGxGxEvIB+/f/yua7fBfgHwEOZ+XhdMI7fwXp/Q9kFvwvr2ukZWvnNmWZfpP8/rnfudH02Ud9X0O/eeAC4v7rdDPwb4DNV+V3AkZ2u63k+w/X0Z1n+NfDZ+ucOPA/4GPAl4M+AQztd1/N8hr3A14HLGmVj/R3Q/4/BUWCV/rjTj6z3M6c/8/JfVb8XnwFu2un6n+czPEx/TK3+ffjt6tj/tvr3dT/waeB7xrT+6/67Ad5ZfQdfAF630/Vf7zNU5e8B3jp07Dh+B+v9DZ2o34ULublcoyRJhY1DN7IkSbuaYStJUmGGrSRJhRm2kiQVZthKklSYYStJUmGGrSRJhRm2kiQVZthKklSYYStJUmGGrSRJhRm2kiQVZthKz4GI+CcRcSwizkbE83a6Ps+F6rNev9P1kMaBV/2RNiEiHgEOA136lzX7f+lfyuyxTTx3GjgNvDwz/7pkPSWNJ1u20uZ9T2buA44Ax4D/fZPPOwzM0b+m6AWpLpZd5Pc0IqZKvK6kZzNspQuUmUvA/wW8uC6LiNmI+JWI+P+q7uLfjoj5iHgh/YuOA5yKiP+7Ov67IuJTEfF0df9djdf6TxHxixHx/wDngOsj4r+IiLsj4mREfCEi3rhe/SLiUET864h4MiK+ERG/X5W/OiIej4h/GhFfA/51Ve//rTr2yWp7duj4d0TEiYh4JCLe3Hif91Sf8+6IOBMRH4+I5zf2Z0R8e+PYfxURf1Qd+8mI+LbGsd9dfa6nI+I3q9f6x1v4mqSxYthKFygi9gDfD9zTKP7nwAuBG4FvB64CfjYzvwi8pDpmITP/XkQcAv4I+A3gecCvAX80NJb7FuB2YD/wFHA38HvAlcCtwG9GxIsZ7d8Ae6r3vRL49ca+bwEOAc+vXv+dwMurev9XwMuAnxk6/vLq89wG3BERL2rsfzPwC9Ux9wPvW6dOVPX+Z8BB4GHgFwEi4nL6/3n56ern8QXgu9Z5DWkyZaY3b942uAGPAGeBU/THbJ8E/la1L4BngG9rHP93gK9W29cBCUxVj98C/OXQ6/9n4Aer7f8E/Hxj3/cDfzF0/P8BvGtEPY8APeDgiH2vBlaAuUbZl4GbG49fAzzSOL4D7G3s/xDwv1Tb7wE+0Ni3j/6Y9jXV4wS+vXHs/9k49mbgoWr7B4D/3NgXwGPAP97p792bt+26OWYjbd4bMvPPIqIN3AJ8vGpd9ui3JO+LiPrYANrrvM63Ao8OlT1Kv/VYa068ej7wtyPiVKNsin4Ldtg1wMnM/MY67/1U9rvB16vLo1VZ7RuZ+cx59g/qmZlnI+JktX/UxLGvNbbP0Q/nug7N18mIeHyd+ksTyW5k6QJlZjczP0K/FfcK4ASwCLwkMxeq22XZn0w1ypP0A7TpWuCJ5ts0th8DPt547YXM3JeZ/2TEaz8GHIqIhfWqv0Fdrq3KagcjYu959l9Tb0TEPvpd1M39m3EUuLrxOtF8LO0Ghq10gaoZwrfQH3v8fGb2gHcDvx4RV1bHXBURr1nnJf4YeGFE/PcRMRUR309/stUfrnP8H1bHvyUipqvbfx0Rf2P4wMw8CvwJ/THdg9WxrzrPx3k/8DMRcUU1dvqzwL8dOuafRcRMRLwSeD3w7xr7bo6IV0TEDP2x23tyE6dDDfkj4G9FxBuqGdI/Rn+sWNo1DFtp8/59RJylf87sLwK3ZWZ9Os8/pT/p556IOA38GfCiUS+SmV+nH1o/CXwd+Cng9Zl5Yp3jzwDfTX+C0ZP0u2N/CZhdp55voT+u/BBwHPiJ83ym/xW4F3gA+Azw6aqs9jXgG9X7vo/+ucUPNfb/HvAu4CTwncD/cJ73Gqn63P8d8Mv0fx4vruq0fKGvJY0rF7WQNFJEvBr4t5k5sks3It4DPJ6ZPzNq/xbetwU8Drw5M/98O19b2im2bCXtuIh4TUQsVOf4voP+BLN7NniaNDEMW0nj4O/QPw3pBPA99Gd+L+5slaTtYzeyJEmF2bKVJKkww1aSpMIMW0mSCjNsJUkqzLCVJKmw/x9DbzqKKacuzwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Cbisddsm_final_new_19.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "instance_type": "ml.m5.large",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}