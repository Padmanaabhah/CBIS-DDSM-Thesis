{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xzc7BJKDBX3y"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L6wiaECOBX30"
      },
      "outputs": [],
      "source": [
        "#pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cXp-5N_yBX30"
      },
      "outputs": [],
      "source": [
        "from distutils import extension\n",
        "from logging import exception\n",
        "import os\n",
        "from datetime import datetime as dt\n",
        "from regex import E\n",
        "from sqlalchemy import intersect\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import numpy as np \n",
        "import pathlib\n",
        "from keras.callbacks import ModelCheckpoint   \n",
        "from keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold , KFold ,RepeatedKFold\n",
        "from operator import itemgetter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iQkKItqB1-t",
        "outputId": "c08a9dd4-10dc-4f5d-ccbe-9d027279221b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQYE2sEYB-uE",
        "outputId": "93e09c73-3b9d-41c1-c89e-66d1768687b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test_output_full  Test_output_mask  Train_output_full  Train_output_mask\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/gdrive/MyDrive/cbisddsm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2foFHtBFB_U4"
      },
      "outputs": [],
      "source": [
        "# data_dir_train = pathlib.Path(\"/content/gdrive/MyDrive/Images/Train\")\n",
        "# data_dir_test = pathlib.Path('/content/gdrive/MyDrive/Images/Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zYVMXFDEBX31"
      },
      "outputs": [],
      "source": [
        "seed = 43\n",
        "encoder_input_width = 224\n",
        "encode_input_channels = 3\n",
        "encoder_input_shape = (encoder_input_width, encoder_input_width, encode_input_channels)\n",
        "\n",
        "kernsize = 3\n",
        "decoder_kernel_size = (kernsize, kernsize)\n",
        "stride = 2\n",
        "decoder_strides = (stride, stride)\n",
        "decoder_padding = \"same\"\n",
        "decoder_activation = None\n",
        "final_layer_filters = 1\n",
        "final_layer_activation = \"sigmoid\"\n",
        "\n",
        "train_full_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Train_output_full\"\n",
        "train_mask_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Train_output_mask\"\n",
        "\n",
        "test_full_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Test_output_full\"\n",
        "test_mask_img_dir = \"/content/gdrive/MyDrive/cbisddsm/Test_output_mask\"\n",
        "results_dir = \"/content/results/fit\"\n",
        "extension = \".png\"\n",
        "\n",
        "target_size = (224, 224)\n",
        "\n",
        "brightness_delta = 0.3\n",
        "batch_size = 10\n",
        "\n",
        "weight_decay = 1e-5\n",
        "\n",
        "validate = True\n",
        "loss = \"binary_crossentropy\"\n",
        "learning_rate = 0.0001\n",
        "dropout = 0.5\n",
        "dropout_training = True\n",
        "num_epochs = 50\n",
        "callback_monitor = \"iouMetric\"\n",
        "callback_mode = \"max\"\n",
        "ckpt_save_weights_only = True\n",
        "ckpt_save_best_only = True\n",
        "earlystop_patience = 200\n",
        "restore_best_weights = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WiJw56KyBX32"
      },
      "outputs": [],
      "source": [
        "# x_paths_list = []\n",
        "# for full in os.listdir(train_full_img_dir):\n",
        "#   if full.endswith(extension):\n",
        "#     x_paths_list.append(os.path.join(train_full_img_dir, full))\n",
        "\n",
        "# print(len(x_paths_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B28GisyHBX32"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JGqSf0kQBX32"
      },
      "outputs": [],
      "source": [
        "def datasetPaths(full_img_dir, mask_img_dir):\n",
        "        try:\n",
        "            x_paths_list = []\n",
        "            y_paths_list = []\n",
        "\n",
        "            for full in os.listdir(full_img_dir):\n",
        "                if full.endswith(extension):\n",
        "                    x_paths_list.append(os.path.join(full_img_dir, full))\n",
        "            \n",
        "            for full in os.listdir(mask_img_dir):\n",
        "                if full.endswith(extension):\n",
        "                    y_paths_list.append(os.path.join(mask_img_dir, full))\n",
        "            \n",
        "            x_paths_list.sort()\n",
        "            y_paths_list.sort()\n",
        "\n",
        "            return x_paths_list, y_paths_list\n",
        "        except Exception as e:\n",
        "            print(f\"Error in datasetPaths {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7u3oVaRTBX33"
      },
      "outputs": [],
      "source": [
        "# def loadFullImg(path, dsize):\n",
        "#         try:\n",
        "#             if not isinstance(path, str):\n",
        "#                 path = path.decode()\n",
        "             \n",
        "            \n",
        "#             s3_client = boto3.resource('s3')\n",
        "#             obj = s3_client.get_object(Bucket='cbisddsm', Key=path)\n",
        "#             nparr = np.frombuffer(obj['Body'].read(), np.uint8)\n",
        "#             img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "#             print(f'type type{img}')\n",
        "#             #bucket = s3_resource.Bucket('cbisddsm')\n",
        "#             #print(f'bucket.Object(path) {bucket.Object(path)}')\n",
        "#             #img = bucket.Object(path).get().get('Body').read()\n",
        "#             #print(f'img {img}')\n",
        "#             #img = cv2.imdecode(np.asarray(bytearray(img)), cv2.IMREAD_COLOR)\n",
        "           \n",
        "            \n",
        "#             #img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "#             img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "#             norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "#             full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "#             print(f'done for path {path}')\n",
        "#             return full_img\n",
        "        \n",
        "#         except Exception as e:\n",
        "#             print(f\"There is an error in loadFullImg {e}\")\n",
        "            \n",
        "\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VQf1GqJeBX34"
      },
      "outputs": [],
      "source": [
        "def loadFullImg(path, dsize):\n",
        "        try:\n",
        "            if not isinstance(path, str):\n",
        "                path = path.decode()\n",
        "            \n",
        "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "            #print(type(img))\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "            #print(f'After norm_img')\n",
        "            #print(f'type {norm_img.shape}')\n",
        "            full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "            #print(f'After full_img')\n",
        "            #print(f'type {full_img.shape}')\n",
        "            #print(f'done for path {path} with shape {full_img.shape}')\n",
        "            return full_img\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"There is an error in loadFullImg {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Yfm6JA2rBX34"
      },
      "outputs": [],
      "source": [
        "# s3 = boto3.resource('s3')\n",
        "# my_bucket = s3.Bucket('cbisddsm')\n",
        "# i = 0\n",
        "# for object_summary in my_bucket.objects.filter(Prefix='Train_output_full'):    \n",
        "#     if i == 0:\n",
        "#         pass\n",
        "#     else:\n",
        "#         print(object_summary.key)\n",
        "#         img = loadFullImg(object_summary.key, target_size)\n",
        "#         print(img.shape)\n",
        "#         #break\n",
        "#     i += 1\n",
        "    \n",
        "    \n",
        "#             #print(object_summary.key)\n",
        "        \n",
        "#             #x_paths_list.append(object_summary.key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KYSP3bIaBX35"
      },
      "outputs": [],
      "source": [
        "def loadMaskImg(path, dsize):\n",
        "        try:\n",
        "            if not isinstance(path, str):\n",
        "                path=path.decode()\n",
        "            \n",
        "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "            mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "            #print(f'done for path {path} with shape {mask_img.shape}')\n",
        "            return mask_img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in loadMaskIMG {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Co4SIeY6BX35"
      },
      "outputs": [],
      "source": [
        "# def loadMaskImg(path, dsize):\n",
        "#         try:\n",
        "#             if not isinstance(path, str):\n",
        "#                 path=path.decode()\n",
        "             \n",
        "#             s3_resource = boto3.resource('s3')\n",
        "#             bucket = s3_resource.Bucket('cbisddsm')\n",
        "# #             bucket = s3_resource.Bucket('cbisddsm')\n",
        "#             img = bucket.Object(path).get().get('Body').read()\n",
        "#             img = cv2.imdecode(np.asarray(bytearray(img)), cv2.IMREAD_COLOR)\n",
        "#             print(f'type type(img)')\n",
        "#             #img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "#             img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "#             norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "#             mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "\n",
        "#             return mask_img\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(\"Error in loadMaskIMG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bawafpnnBX36"
      },
      "outputs": [],
      "source": [
        "def tfParse(x_path, y_path):\n",
        "        try:\n",
        "            def _parse(x_path, y_path):\n",
        "                x = loadFullImg(path=x_path, dsize=target_size)\n",
        "                y = loadMaskImg(path=y_path, dsize=target_size)\n",
        "                return x,y\n",
        "\n",
        "            x, y = tf.numpy_function(_parse, [x_path, y_path], [tf.float64, tf.float64])\n",
        "\n",
        "            x.set_shape([target_size[0], target_size[0], 3])\n",
        "            y.set_shape([target_size[0], target_size[1], 1])\n",
        "\n",
        "            return x,y\n",
        "            \n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in tfParse {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tkHDbxVGBX36"
      },
      "outputs": [],
      "source": [
        "def imgAugment(x_img, y_img):\n",
        "        try:\n",
        "            if tf.random.uniform(()) > 0.5:\n",
        "                x_img = tf.image.flip_up_down(image=x_img)\n",
        "                y_img = tf.image.flip_up_down(image=y_img)\n",
        "\n",
        "            x_img = tf.image.random_brightness(\n",
        "                image=x_img, max_delta=brightness_delta\n",
        "            )\n",
        "\n",
        "            return x_img, y_img\n",
        "\n",
        "        except:\n",
        "            print(\"Erro in imgAugument\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Mge3IsdLBX36"
      },
      "outputs": [],
      "source": [
        " def makeTFDataset( shuffle, augument, x_paths_list, y_paths_list, batch_size):\n",
        "        try:\n",
        "            ds = tf.data.Dataset.from_tensor_slices((x_paths_list, y_paths_list))\n",
        "            \n",
        "            if shuffle:\n",
        "                ds = ds.shuffle(buffer_size=len(x_paths_list))\n",
        "\n",
        "            ds = ds.map(tfParse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "            \n",
        "            if augument:\n",
        "                ds = ds.map(imgAugment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "            ds = ds.batch(batch_size=batch_size, drop_remainder=False)\n",
        "            ds = ds.repeat()\n",
        "\n",
        "            return ds\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in make TFDataset {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9RGLX5MnBX37"
      },
      "outputs": [],
      "source": [
        "def buildEncoder():\n",
        "        try:\n",
        "            VGG16_ = keras.applications.VGG16(\n",
        "                include_top=False, weights=\"imagenet\", input_shape=encoder_input_shape,\n",
        "            )\n",
        "\n",
        "            layer_names = [layer.name for layer in VGG16_.layers]\n",
        "\n",
        "            all_layer_outputs = [\n",
        "               VGG16_.get_layer(layer).output for layer in layer_names\n",
        "            ]\n",
        "\n",
        "            encoder_model = keras.Model(inputs=VGG16_.input, outputs=all_layer_outputs)\n",
        "\n",
        "            encoder_model.trainable = False\n",
        "\n",
        "            return encoder_model \n",
        "        \n",
        "        except Exception as e:\n",
        "            print(\"Error in buildEncoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eNHrykF9BX37"
      },
      "outputs": [],
      "source": [
        "def buildUnet():\n",
        "        try:\n",
        "            unet_input = keras.Input(\n",
        "                shape= encoder_input_shape, name=\"unet_input_layer\"\n",
        "            )\n",
        "\n",
        "            x = unet_input\n",
        "            encoder_model = buildEncoder()\n",
        "            all_encoder_layer_outputs = encoder_model(x)\n",
        "\n",
        "            encoded_img = all_encoder_layer_outputs[-1]\n",
        "\n",
        "            skip_outputs = [all_encoder_layer_outputs[i] for i in [2, 5,9, 13, 17]]\n",
        "            #skip_outputs = [all_encoder_layer_outputs[i] for i in [2, 4, 6, 12, 15]]\n",
        "            \n",
        "            decoder_filters = int(encoded_img.shape[-1])\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 5: 7x7 -> 14x14\n",
        "            #  - `encoded_img` as initial input for decoder\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block5_up_convT\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=decoder_activation,\n",
        "            )(encoded_img)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block5_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[4]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block5_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block5_up_conv3\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block5_up_conv2\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block5_up_conv1\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 4: 14x14 -> 28x28\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block4_up_convT\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block4_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[3]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block4_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block4_up_conv3\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block4_up_conv2\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block4_up_conv1\",\n",
        "                filters=decoder_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 3: 28x28 -> 56x56\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block3_up_convT\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block3_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[2]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block3_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block3_up_conv3\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block3_up_conv2\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block3_up_conv1\",\n",
        "                filters=int(decoder_filters / 2),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 2: 56x56 -> 112x112\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block2_up_convT\",\n",
        "                filters=int(decoder_filters / 4),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block2_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[1]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block2_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block2_up_conv2\",\n",
        "                filters=int(decoder_filters / 4),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block2_up_conv1\",\n",
        "                filters=int(decoder_filters / 4),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                padding=\"same\",\n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Block 1: 112x112 -> 224x224\n",
        "            x = keras.layers.Conv2DTranspose(\n",
        "                name=\"block1_up_convT\",\n",
        "                filters=int(decoder_filters / 8),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=decoder_strides,\n",
        "                padding=decoder_padding,\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=decoder_activation,\n",
        "            )(x)\n",
        "\n",
        "            x = keras.layers.Concatenate(name=\"block1_up_concat\", axis=-1)(\n",
        "                [x, skip_outputs[0]]\n",
        "            )\n",
        "\n",
        "            x = keras.layers.Dropout(\n",
        "                name=\"block1_up_dropout\", rate=dropout, seed=seed\n",
        "            )(x, training=dropout_training)\n",
        "\n",
        "            x = keras.layers.Conv2D(\n",
        "                name=\"block1_up_conv2\",\n",
        "                filters=int(decoder_filters / 8),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "            decoded_img = keras.layers.Conv2D(\n",
        "                name=\"block1_up_conv1\",\n",
        "                filters=int(decoder_filters / 8),\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=\"relu\",\n",
        "            )(x)\n",
        "\n",
        "            # ------------------------------------------\n",
        "            # Final conv layer\n",
        "            final_img = keras.layers.Conv2D(\n",
        "                name=\"final_up_conv\",\n",
        "                filters=final_layer_filters,\n",
        "                kernel_size=decoder_kernel_size,\n",
        "                strides=(1, 1),\n",
        "                padding=\"same\",\n",
        "                kernel_regularizer=l2(weight_decay), \n",
        "                activation=final_layer_activation,\n",
        "            )(decoded_img)\n",
        "\n",
        "            # ======\n",
        "            #  Unet\n",
        "            # ======\n",
        "\n",
        "            unet = keras.Model(inputs=unet_input, outputs=final_img, name=\"Unet_VGG16\")\n",
        "\n",
        "            return unet\n",
        "        except Exception as e:\n",
        "            print(f\"Error in Build Unet {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_sq8aqBYBX38"
      },
      "outputs": [],
      "source": [
        "def iouMetric( y_true, y_pred):\n",
        "        try:\n",
        "            def compute_iou(y_true, y_pred):\n",
        "                intersection = (y_true * y_pred).sum()\n",
        "                union = y_true.sum() + y_pred.sum() - intersection\n",
        "                x = (intersection + 1e-15) / (union + 1e-15)\n",
        "                x = x.astype(np.float32)\n",
        "                return x\n",
        "            \n",
        "            return tf.numpy_function(compute_iou, [y_true, y_pred], tf.float32)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error in iouMetric {E}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xCkCusvKBCuz"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "        try:\n",
        "            # def dice(true, pred, k = 1):\n",
        "            #     intersection = np.sum(pred[true==k]) * 2.0\n",
        "            #     dice = intersection / (np.sum(pred) + np.sum(true))\n",
        "            #     return dice \n",
        "            # return tf.numpy_function(dice, [y_true, y_pred], tf.double)\n",
        "            \n",
        "            y_true_f = tf.reshape(tf.dtypes.cast(y_true, tf.float32), [-1])\n",
        "            y_pred_f = tf.reshape(tf.dtypes.cast(y_pred, tf.float32), [-1])\n",
        "            intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "            return (2. * intersection + 1.) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + 1.)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in dice_coef {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Egz73rd9BX39"
      },
      "outputs": [],
      "source": [
        "def compile_( model):\n",
        "        try:\n",
        "            loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "            metrics = [\"accuracy\", iouMetric, dice_coef]\n",
        "            model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(f\"Failed at compile_ {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jNa9nYOcCV15"
      },
      "outputs": [],
      "source": [
        " test_x, test_y = datasetPaths(\n",
        "            full_img_dir=test_full_img_dir,\n",
        "            mask_img_dir=test_mask_img_dir\n",
        "        )\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wDDyk7GYCWU3"
      },
      "outputs": [],
      "source": [
        "# def evaluate(path,target_size):\n",
        "#   full_img_lst = []\n",
        "#   print(len(path))\n",
        "#   for imgpath in path:\n",
        "#     full_img = loadFullImg(imgpath, target_size)\n",
        "#     full_img_lst.append(full_img)\n",
        "#     #img = cv2.imread(imgpath, cv2.IMREAD_GRAYSCALE)\n",
        "#     #print(full_img.shape)\n",
        "#   return full_img_lst\n",
        "  \n",
        "# full_img_lst = evaluate(test_x, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pbuTQcYXCbvv"
      },
      "outputs": [],
      "source": [
        "# def evaluate_mask(path,target_size):\n",
        "#   mask_img_lst = []\n",
        "#   print(len(path))\n",
        "#   for imgpath in path:\n",
        "#     mask_img = loadMaskImg(imgpath, target_size)\n",
        "#     mask_img_lst.append(mask_img)\n",
        "#     #img = cv2.imread(imgpath, cv2.IMREAD_GRAYSCALE)\n",
        "#     #print(full_img.shape)\n",
        "#   return mask_img_lst\n",
        "  \n",
        "# mask_img_lst = evaluate(test_y, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_WCc1IIBIety"
      },
      "outputs": [],
      "source": [
        "# img = cv2.imread(test_x[0], cv2.IMREAD_GRAYSCALE)\n",
        "# print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VeQ8YyfqHgYW"
      },
      "outputs": [],
      "source": [
        "# actual_x, actual_y =tfParse(test_x, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "c1hGy4M6FyuV"
      },
      "outputs": [],
      "source": [
        "N_SPLIT = 6\n",
        "kfold = KFold(n_splits=N_SPLIT,shuffle=True,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " def makeTFDataset1( shuffle, augument, x_paths_list, y_paths_list, batch_size):\n",
        "        try:\n",
        "            ds = tf.data.Dataset.from_tensor_slices((x_paths_list, y_paths_list))\n",
        "            \n",
        "            if shuffle:\n",
        "                ds = ds.shuffle(buffer_size=len(x_paths_list))\n",
        "\n",
        "            ds = ds.map(tfParse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "            \n",
        "            if augument:\n",
        "                ds = ds.map(imgAugment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "            ds = ds.batch(batch_size=batch_size, drop_remainder=False)\n",
        "            #ds = ds.repeat()\n",
        "\n",
        "            return ds\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in make TFDataset {e}\")"
      ],
      "metadata": {
        "id": "Vx26wnV0k3Xo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agKhRncmBX39",
        "outputId": "3d5d4705-7e89-48f0-f96a-ed93db4fe0a6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "\n",
            "Size of training set = 1025\n",
            "Size of test set = 206\n",
            "Number of epochs = 50\n",
            "Batch size = 10\n",
            "Number of training steps per epoch = 103\n",
            "Number of test steps per epoch = 21\n",
            "\n",
            "Epoch 1/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9843 - iouMetric: 0.0024 - dice_coef: 0.0050\n",
            "Epoch 1: val_loss improved from -inf to 0.07160, saving model to /content/results/fit/20220822_220804/checkpoints/20220822_220804\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.07160, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 441s 4s/step - loss: 0.1121 - accuracy: 0.9843 - iouMetric: 0.0024 - dice_coef: 0.0050 - val_loss: 0.0716 - val_accuracy: 0.9957 - val_iouMetric: 0.0095 - val_dice_coef: 0.0191\n",
            "Epoch 2/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9961 - iouMetric: 0.0468 - dice_coef: 0.0880\n",
            "Epoch 2: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 2: val_loss improved from 0.07160 to 0.04645, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 216s 2s/step - loss: 0.0559 - accuracy: 0.9961 - iouMetric: 0.0468 - dice_coef: 0.0880 - val_loss: 0.0464 - val_accuracy: 0.9958 - val_iouMetric: 0.0986 - val_dice_coef: 0.1780\n",
            "Epoch 3/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9961 - iouMetric: 0.1051 - dice_coef: 0.1877\n",
            "Epoch 3: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 3: val_loss improved from 0.04645 to 0.03565, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 208s 2s/step - loss: 0.0398 - accuracy: 0.9961 - iouMetric: 0.1051 - dice_coef: 0.1877 - val_loss: 0.0356 - val_accuracy: 0.9959 - val_iouMetric: 0.1455 - val_dice_coef: 0.2510\n",
            "Epoch 4/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9962 - iouMetric: 0.1204 - dice_coef: 0.2129\n",
            "Epoch 4: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 4: val_loss improved from 0.03565 to 0.03131, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 218s 2s/step - loss: 0.0322 - accuracy: 0.9962 - iouMetric: 0.1204 - dice_coef: 0.2129 - val_loss: 0.0313 - val_accuracy: 0.9960 - val_iouMetric: 0.1101 - val_dice_coef: 0.1964\n",
            "Epoch 5/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9963 - iouMetric: 0.1258 - dice_coef: 0.2209\n",
            "Epoch 5: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 5: val_loss improved from 0.03131 to 0.02752, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 217s 2s/step - loss: 0.0283 - accuracy: 0.9963 - iouMetric: 0.1258 - dice_coef: 0.2209 - val_loss: 0.0275 - val_accuracy: 0.9960 - val_iouMetric: 0.1405 - val_dice_coef: 0.2441\n",
            "Epoch 6/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9964 - iouMetric: 0.1285 - dice_coef: 0.2239\n",
            "Epoch 6: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 6: val_loss improved from 0.02752 to 0.02589, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 218s 2s/step - loss: 0.0263 - accuracy: 0.9964 - iouMetric: 0.1285 - dice_coef: 0.2239 - val_loss: 0.0259 - val_accuracy: 0.9961 - val_iouMetric: 0.1603 - val_dice_coef: 0.2727\n",
            "Epoch 7/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9965 - iouMetric: 0.1459 - dice_coef: 0.2510\n",
            "Epoch 7: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 7: val_loss improved from 0.02589 to 0.02522, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 208s 2s/step - loss: 0.0246 - accuracy: 0.9965 - iouMetric: 0.1459 - dice_coef: 0.2510 - val_loss: 0.0252 - val_accuracy: 0.9963 - val_iouMetric: 0.1748 - val_dice_coef: 0.2930\n",
            "Epoch 8/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9965 - iouMetric: 0.1532 - dice_coef: 0.2618\n",
            "Epoch 8: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 8: val_loss improved from 0.02522 to 0.02418, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 209s 2s/step - loss: 0.0236 - accuracy: 0.9965 - iouMetric: 0.1532 - dice_coef: 0.2618 - val_loss: 0.0242 - val_accuracy: 0.9963 - val_iouMetric: 0.1712 - val_dice_coef: 0.2886\n",
            "Epoch 9/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9966 - iouMetric: 0.1649 - dice_coef: 0.2786\n",
            "Epoch 9: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 9: val_loss improved from 0.02418 to 0.02411, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 214s 2s/step - loss: 0.0228 - accuracy: 0.9966 - iouMetric: 0.1649 - dice_coef: 0.2786 - val_loss: 0.0241 - val_accuracy: 0.9962 - val_iouMetric: 0.1378 - val_dice_coef: 0.2395\n",
            "Epoch 10/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9966 - iouMetric: 0.1665 - dice_coef: 0.2813\n",
            "Epoch 10: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 10: val_loss improved from 0.02411 to 0.02340, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 210s 2s/step - loss: 0.0222 - accuracy: 0.9966 - iouMetric: 0.1665 - dice_coef: 0.2813 - val_loss: 0.0234 - val_accuracy: 0.9963 - val_iouMetric: 0.1927 - val_dice_coef: 0.3186\n",
            "Epoch 11/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9967 - iouMetric: 0.1794 - dice_coef: 0.2978\n",
            "Epoch 11: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 11: val_loss improved from 0.02340 to 0.02264, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 218s 2s/step - loss: 0.0217 - accuracy: 0.9967 - iouMetric: 0.1794 - dice_coef: 0.2978 - val_loss: 0.0226 - val_accuracy: 0.9963 - val_iouMetric: 0.2000 - val_dice_coef: 0.3282\n",
            "Epoch 12/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9967 - iouMetric: 0.1871 - dice_coef: 0.3104\n",
            "Epoch 12: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.02264\n",
            "103/103 [==============================] - 207s 2s/step - loss: 0.0209 - accuracy: 0.9967 - iouMetric: 0.1871 - dice_coef: 0.3104 - val_loss: 0.0228 - val_accuracy: 0.9964 - val_iouMetric: 0.1997 - val_dice_coef: 0.3277\n",
            "Epoch 13/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9967 - iouMetric: 0.1878 - dice_coef: 0.3104\n",
            "Epoch 13: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.02264\n",
            "103/103 [==============================] - 218s 2s/step - loss: 0.0208 - accuracy: 0.9967 - iouMetric: 0.1878 - dice_coef: 0.3104 - val_loss: 0.0244 - val_accuracy: 0.9951 - val_iouMetric: 0.1917 - val_dice_coef: 0.3174\n",
            "Epoch 14/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9968 - iouMetric: 0.1897 - dice_coef: 0.3130\n",
            "Epoch 14: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 14: val_loss improved from 0.02264 to 0.02213, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 220s 2s/step - loss: 0.0205 - accuracy: 0.9968 - iouMetric: 0.1897 - dice_coef: 0.3130 - val_loss: 0.0221 - val_accuracy: 0.9963 - val_iouMetric: 0.1901 - val_dice_coef: 0.3146\n",
            "Epoch 15/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9969 - iouMetric: 0.2001 - dice_coef: 0.3290\n",
            "Epoch 15: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 15: val_loss improved from 0.02213 to 0.02172, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 210s 2s/step - loss: 0.0196 - accuracy: 0.9969 - iouMetric: 0.2001 - dice_coef: 0.3290 - val_loss: 0.0217 - val_accuracy: 0.9963 - val_iouMetric: 0.1970 - val_dice_coef: 0.3229\n",
            "Epoch 16/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9969 - iouMetric: 0.2058 - dice_coef: 0.3356\n",
            "Epoch 16: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.02172\n",
            "103/103 [==============================] - 206s 2s/step - loss: 0.0193 - accuracy: 0.9969 - iouMetric: 0.2058 - dice_coef: 0.3356 - val_loss: 0.0222 - val_accuracy: 0.9962 - val_iouMetric: 0.2096 - val_dice_coef: 0.3403\n",
            "Epoch 17/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9969 - iouMetric: 0.2119 - dice_coef: 0.3435\n",
            "Epoch 17: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.02172\n",
            "103/103 [==============================] - 217s 2s/step - loss: 0.0190 - accuracy: 0.9969 - iouMetric: 0.2119 - dice_coef: 0.3435 - val_loss: 0.0219 - val_accuracy: 0.9962 - val_iouMetric: 0.2172 - val_dice_coef: 0.3513\n",
            "Epoch 18/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9970 - iouMetric: 0.2200 - dice_coef: 0.3553\n",
            "Epoch 18: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 18: val_loss improved from 0.02172 to 0.02156, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 208s 2s/step - loss: 0.0186 - accuracy: 0.9970 - iouMetric: 0.2200 - dice_coef: 0.3553 - val_loss: 0.0216 - val_accuracy: 0.9965 - val_iouMetric: 0.1877 - val_dice_coef: 0.3097\n",
            "Epoch 19/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9970 - iouMetric: 0.2254 - dice_coef: 0.3624\n",
            "Epoch 19: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 19: val_loss improved from 0.02156 to 0.02113, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 223s 2s/step - loss: 0.0182 - accuracy: 0.9970 - iouMetric: 0.2254 - dice_coef: 0.3624 - val_loss: 0.0211 - val_accuracy: 0.9964 - val_iouMetric: 0.2030 - val_dice_coef: 0.3328\n",
            "Epoch 20/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9970 - iouMetric: 0.2252 - dice_coef: 0.3613\n",
            "Epoch 20: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.02113\n",
            "103/103 [==============================] - 218s 2s/step - loss: 0.0179 - accuracy: 0.9970 - iouMetric: 0.2252 - dice_coef: 0.3613 - val_loss: 0.0216 - val_accuracy: 0.9962 - val_iouMetric: 0.2279 - val_dice_coef: 0.3643\n",
            "Epoch 21/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9972 - iouMetric: 0.2459 - dice_coef: 0.3892\n",
            "Epoch 21: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.02113\n",
            "103/103 [==============================] - 217s 2s/step - loss: 0.0173 - accuracy: 0.9972 - iouMetric: 0.2459 - dice_coef: 0.3892 - val_loss: 0.0215 - val_accuracy: 0.9963 - val_iouMetric: 0.2193 - val_dice_coef: 0.3532\n",
            "Epoch 22/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9972 - iouMetric: 0.2542 - dice_coef: 0.3974\n",
            "Epoch 22: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.02113\n",
            "103/103 [==============================] - 220s 2s/step - loss: 0.0170 - accuracy: 0.9972 - iouMetric: 0.2542 - dice_coef: 0.3974 - val_loss: 0.0212 - val_accuracy: 0.9964 - val_iouMetric: 0.2165 - val_dice_coef: 0.3507\n",
            "Epoch 23/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9972 - iouMetric: 0.2473 - dice_coef: 0.3896\n",
            "Epoch 23: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.02113\n",
            "103/103 [==============================] - 212s 2s/step - loss: 0.0168 - accuracy: 0.9972 - iouMetric: 0.2473 - dice_coef: 0.3896 - val_loss: 0.0212 - val_accuracy: 0.9964 - val_iouMetric: 0.2161 - val_dice_coef: 0.3486\n",
            "Epoch 24/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9972 - iouMetric: 0.2674 - dice_coef: 0.4163\n",
            "Epoch 24: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 24: val_loss improved from 0.02113 to 0.02065, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 213s 2s/step - loss: 0.0164 - accuracy: 0.9972 - iouMetric: 0.2674 - dice_coef: 0.4163 - val_loss: 0.0207 - val_accuracy: 0.9963 - val_iouMetric: 0.1912 - val_dice_coef: 0.3174\n",
            "Epoch 25/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9973 - iouMetric: 0.2772 - dice_coef: 0.4289\n",
            "Epoch 25: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 25: val_loss improved from 0.02065 to 0.02046, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 224s 2s/step - loss: 0.0160 - accuracy: 0.9973 - iouMetric: 0.2772 - dice_coef: 0.4289 - val_loss: 0.0205 - val_accuracy: 0.9964 - val_iouMetric: 0.1901 - val_dice_coef: 0.3144\n",
            "Epoch 26/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9973 - iouMetric: 0.2805 - dice_coef: 0.4318\n",
            "Epoch 26: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.02046\n",
            "103/103 [==============================] - 222s 2s/step - loss: 0.0157 - accuracy: 0.9973 - iouMetric: 0.2805 - dice_coef: 0.4318 - val_loss: 0.0206 - val_accuracy: 0.9964 - val_iouMetric: 0.2222 - val_dice_coef: 0.3570\n",
            "Epoch 27/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9973 - iouMetric: 0.2802 - dice_coef: 0.4310\n",
            "Epoch 27: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.02046\n",
            "103/103 [==============================] - 211s 2s/step - loss: 0.0154 - accuracy: 0.9973 - iouMetric: 0.2802 - dice_coef: 0.4310 - val_loss: 0.0205 - val_accuracy: 0.9964 - val_iouMetric: 0.2111 - val_dice_coef: 0.3426\n",
            "Epoch 28/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9974 - iouMetric: 0.3014 - dice_coef: 0.4577\n",
            "Epoch 28: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.02046\n",
            "103/103 [==============================] - 220s 2s/step - loss: 0.0151 - accuracy: 0.9974 - iouMetric: 0.3014 - dice_coef: 0.4577 - val_loss: 0.0206 - val_accuracy: 0.9962 - val_iouMetric: 0.2293 - val_dice_coef: 0.3679\n",
            "Epoch 29/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9974 - iouMetric: 0.2940 - dice_coef: 0.4476\n",
            "Epoch 29: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.02046\n",
            "103/103 [==============================] - 217s 2s/step - loss: 0.0149 - accuracy: 0.9974 - iouMetric: 0.2940 - dice_coef: 0.4476 - val_loss: 0.0209 - val_accuracy: 0.9963 - val_iouMetric: 0.2300 - val_dice_coef: 0.3672\n",
            "Epoch 30/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9975 - iouMetric: 0.3140 - dice_coef: 0.4711\n",
            "Epoch 30: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 30: val_loss improved from 0.02046 to 0.02025, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 219s 2s/step - loss: 0.0145 - accuracy: 0.9975 - iouMetric: 0.3140 - dice_coef: 0.4711 - val_loss: 0.0202 - val_accuracy: 0.9962 - val_iouMetric: 0.2144 - val_dice_coef: 0.3476\n",
            "Epoch 31/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9974 - iouMetric: 0.3020 - dice_coef: 0.4560\n",
            "Epoch 31: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.02025\n",
            "103/103 [==============================] - 218s 2s/step - loss: 0.0144 - accuracy: 0.9974 - iouMetric: 0.3020 - dice_coef: 0.4560 - val_loss: 0.0209 - val_accuracy: 0.9963 - val_iouMetric: 0.2172 - val_dice_coef: 0.3510\n",
            "Epoch 32/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9975 - iouMetric: 0.3073 - dice_coef: 0.4637\n",
            "Epoch 32: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 32: val_loss improved from 0.02025 to 0.01998, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 210s 2s/step - loss: 0.0143 - accuracy: 0.9975 - iouMetric: 0.3073 - dice_coef: 0.4637 - val_loss: 0.0200 - val_accuracy: 0.9959 - val_iouMetric: 0.2080 - val_dice_coef: 0.3400\n",
            "Epoch 33/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9975 - iouMetric: 0.3203 - dice_coef: 0.4791\n",
            "Epoch 33: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 33: val_loss improved from 0.01998 to 0.01997, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 221s 2s/step - loss: 0.0139 - accuracy: 0.9975 - iouMetric: 0.3203 - dice_coef: 0.4791 - val_loss: 0.0200 - val_accuracy: 0.9961 - val_iouMetric: 0.2158 - val_dice_coef: 0.3506\n",
            "Epoch 34/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9976 - iouMetric: 0.3240 - dice_coef: 0.4827\n",
            "Epoch 34: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 34: val_loss improved from 0.01997 to 0.01951, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 215s 2s/step - loss: 0.0138 - accuracy: 0.9976 - iouMetric: 0.3240 - dice_coef: 0.4827 - val_loss: 0.0195 - val_accuracy: 0.9964 - val_iouMetric: 0.2357 - val_dice_coef: 0.3741\n",
            "Epoch 35/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9976 - iouMetric: 0.3321 - dice_coef: 0.4938\n",
            "Epoch 35: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 208s 2s/step - loss: 0.0135 - accuracy: 0.9976 - iouMetric: 0.3321 - dice_coef: 0.4938 - val_loss: 0.0208 - val_accuracy: 0.9960 - val_iouMetric: 0.2290 - val_dice_coef: 0.3667\n",
            "Epoch 36/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9977 - iouMetric: 0.3437 - dice_coef: 0.5044\n",
            "Epoch 36: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 219s 2s/step - loss: 0.0131 - accuracy: 0.9977 - iouMetric: 0.3437 - dice_coef: 0.5044 - val_loss: 0.0208 - val_accuracy: 0.9964 - val_iouMetric: 0.2536 - val_dice_coef: 0.3976\n",
            "Epoch 37/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9977 - iouMetric: 0.3435 - dice_coef: 0.5044\n",
            "Epoch 37: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 217s 2s/step - loss: 0.0130 - accuracy: 0.9977 - iouMetric: 0.3435 - dice_coef: 0.5044 - val_loss: 0.0208 - val_accuracy: 0.9963 - val_iouMetric: 0.2407 - val_dice_coef: 0.3813\n",
            "Epoch 38/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9977 - iouMetric: 0.3568 - dice_coef: 0.5183\n",
            "Epoch 38: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 218s 2s/step - loss: 0.0127 - accuracy: 0.9977 - iouMetric: 0.3568 - dice_coef: 0.5183 - val_loss: 0.0202 - val_accuracy: 0.9965 - val_iouMetric: 0.2345 - val_dice_coef: 0.3737\n",
            "Epoch 39/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9977 - iouMetric: 0.3537 - dice_coef: 0.5160\n",
            "Epoch 39: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 213s 2s/step - loss: 0.0126 - accuracy: 0.9977 - iouMetric: 0.3537 - dice_coef: 0.5160 - val_loss: 0.0201 - val_accuracy: 0.9965 - val_iouMetric: 0.2212 - val_dice_coef: 0.3540\n",
            "Epoch 40/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9977 - iouMetric: 0.3554 - dice_coef: 0.5193\n",
            "Epoch 40: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 221s 2s/step - loss: 0.0123 - accuracy: 0.9977 - iouMetric: 0.3554 - dice_coef: 0.5193 - val_loss: 0.0226 - val_accuracy: 0.9964 - val_iouMetric: 0.2338 - val_dice_coef: 0.3699\n",
            "Epoch 41/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9978 - iouMetric: 0.3787 - dice_coef: 0.5441\n",
            "Epoch 41: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 224s 2s/step - loss: 0.0120 - accuracy: 0.9978 - iouMetric: 0.3787 - dice_coef: 0.5441 - val_loss: 0.0207 - val_accuracy: 0.9962 - val_iouMetric: 0.2314 - val_dice_coef: 0.3689\n",
            "Epoch 42/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9978 - iouMetric: 0.3810 - dice_coef: 0.5458\n",
            "Epoch 42: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 219s 2s/step - loss: 0.0117 - accuracy: 0.9978 - iouMetric: 0.3810 - dice_coef: 0.5458 - val_loss: 0.0203 - val_accuracy: 0.9962 - val_iouMetric: 0.2503 - val_dice_coef: 0.3949\n",
            "Epoch 43/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9978 - iouMetric: 0.3770 - dice_coef: 0.5420\n",
            "Epoch 43: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 224s 2s/step - loss: 0.0116 - accuracy: 0.9978 - iouMetric: 0.3770 - dice_coef: 0.5420 - val_loss: 0.0216 - val_accuracy: 0.9963 - val_iouMetric: 0.2575 - val_dice_coef: 0.4026\n",
            "Epoch 44/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9979 - iouMetric: 0.3950 - dice_coef: 0.5602\n",
            "Epoch 44: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 215s 2s/step - loss: 0.0114 - accuracy: 0.9979 - iouMetric: 0.3950 - dice_coef: 0.5602 - val_loss: 0.0198 - val_accuracy: 0.9963 - val_iouMetric: 0.2296 - val_dice_coef: 0.3674\n",
            "Epoch 45/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9978 - iouMetric: 0.3887 - dice_coef: 0.5537\n",
            "Epoch 45: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 220s 2s/step - loss: 0.0115 - accuracy: 0.9978 - iouMetric: 0.3887 - dice_coef: 0.5537 - val_loss: 0.0217 - val_accuracy: 0.9963 - val_iouMetric: 0.2469 - val_dice_coef: 0.3876\n",
            "Epoch 46/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9979 - iouMetric: 0.3981 - dice_coef: 0.5643\n",
            "Epoch 46: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 213s 2s/step - loss: 0.0111 - accuracy: 0.9979 - iouMetric: 0.3981 - dice_coef: 0.5643 - val_loss: 0.0209 - val_accuracy: 0.9964 - val_iouMetric: 0.2281 - val_dice_coef: 0.3646\n",
            "Epoch 47/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9979 - iouMetric: 0.4004 - dice_coef: 0.5668\n",
            "Epoch 47: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 216s 2s/step - loss: 0.0110 - accuracy: 0.9979 - iouMetric: 0.4004 - dice_coef: 0.5668 - val_loss: 0.0199 - val_accuracy: 0.9962 - val_iouMetric: 0.2596 - val_dice_coef: 0.4062\n",
            "Epoch 48/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9979 - iouMetric: 0.3981 - dice_coef: 0.5632\n",
            "Epoch 48: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 213s 2s/step - loss: 0.0110 - accuracy: 0.9979 - iouMetric: 0.3981 - dice_coef: 0.5632 - val_loss: 0.0197 - val_accuracy: 0.9962 - val_iouMetric: 0.2539 - val_dice_coef: 0.3982\n",
            "Epoch 49/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9980 - iouMetric: 0.4069 - dice_coef: 0.5722\n",
            "Epoch 49: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 219s 2s/step - loss: 0.0107 - accuracy: 0.9980 - iouMetric: 0.4069 - dice_coef: 0.5722 - val_loss: 0.0201 - val_accuracy: 0.9960 - val_iouMetric: 0.2426 - val_dice_coef: 0.3852\n",
            "Epoch 50/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9980 - iouMetric: 0.4103 - dice_coef: 0.5760\n",
            "Epoch 50: val_loss did not improve from 0.07160\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 220s 2s/step - loss: 0.0105 - accuracy: 0.9980 - iouMetric: 0.4103 - dice_coef: 0.5760 - val_loss: 0.0196 - val_accuracy: 0.9963 - val_iouMetric: 0.2355 - val_dice_coef: 0.3757\n",
            "Accuracy 0.9967522621154785\n",
            "IOU Metrics 0.20092196762561798\n",
            "dice_coef 0.32493072748184204\n",
            "-----------------------------------------------------\n",
            "\n",
            "Size of training set = 1026\n",
            "Size of test set = 205\n",
            "Number of epochs = 50\n",
            "Batch size = 10\n",
            "Number of training steps per epoch = 103\n",
            "Number of test steps per epoch = 21\n",
            "\n",
            "Epoch 1/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9959 - iouMetric: 0.0445 - dice_coef: 0.0830\n",
            "Epoch 1: val_loss improved from -inf to 0.05885, saving model to /content/results/fit/20220822_220804/checkpoints/20220822_220804\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 219s 2s/step - loss: 0.0752 - accuracy: 0.9959 - iouMetric: 0.0445 - dice_coef: 0.0830 - val_loss: 0.0588 - val_accuracy: 0.9964 - val_iouMetric: 0.0689 - val_dice_coef: 0.1282\n",
            "Epoch 2/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9961 - iouMetric: 0.1129 - dice_coef: 0.2004\n",
            "Epoch 2: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 220s 2s/step - loss: 0.0491 - accuracy: 0.9961 - iouMetric: 0.1129 - dice_coef: 0.2004 - val_loss: 0.0411 - val_accuracy: 0.9965 - val_iouMetric: 0.0953 - val_dice_coef: 0.1723\n",
            "Epoch 3/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9964 - iouMetric: 0.1406 - dice_coef: 0.2429\n",
            "Epoch 3: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 205s 2s/step - loss: 0.0354 - accuracy: 0.9964 - iouMetric: 0.1406 - dice_coef: 0.2429 - val_loss: 0.0308 - val_accuracy: 0.9965 - val_iouMetric: 0.1457 - val_dice_coef: 0.2524\n",
            "Epoch 4/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9963 - iouMetric: 0.1415 - dice_coef: 0.2443\n",
            "Epoch 4: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 223s 2s/step - loss: 0.0291 - accuracy: 0.9963 - iouMetric: 0.1415 - dice_coef: 0.2443 - val_loss: 0.0266 - val_accuracy: 0.9965 - val_iouMetric: 0.1483 - val_dice_coef: 0.2563\n",
            "Epoch 5/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9965 - iouMetric: 0.1534 - dice_coef: 0.2621\n",
            "Epoch 5: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 213s 2s/step - loss: 0.0252 - accuracy: 0.9965 - iouMetric: 0.1534 - dice_coef: 0.2621 - val_loss: 0.0240 - val_accuracy: 0.9966 - val_iouMetric: 0.1439 - val_dice_coef: 0.2487\n",
            "Epoch 6/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9965 - iouMetric: 0.1638 - dice_coef: 0.2775\n",
            "Epoch 6: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 223s 2s/step - loss: 0.0233 - accuracy: 0.9965 - iouMetric: 0.1638 - dice_coef: 0.2775 - val_loss: 0.0226 - val_accuracy: 0.9966 - val_iouMetric: 0.1479 - val_dice_coef: 0.2545\n",
            "Epoch 7/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9966 - iouMetric: 0.1682 - dice_coef: 0.2837\n",
            "Epoch 7: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 220s 2s/step - loss: 0.0220 - accuracy: 0.9966 - iouMetric: 0.1682 - dice_coef: 0.2837 - val_loss: 0.0220 - val_accuracy: 0.9967 - val_iouMetric: 0.1422 - val_dice_coef: 0.2463\n",
            "Epoch 8/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9966 - iouMetric: 0.1725 - dice_coef: 0.2900\n",
            "Epoch 8: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 219s 2s/step - loss: 0.0212 - accuracy: 0.9966 - iouMetric: 0.1725 - dice_coef: 0.2900 - val_loss: 0.0209 - val_accuracy: 0.9966 - val_iouMetric: 0.1310 - val_dice_coef: 0.2301\n",
            "Epoch 9/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9967 - iouMetric: 0.1803 - dice_coef: 0.3006\n",
            "Epoch 9: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 212s 2s/step - loss: 0.0204 - accuracy: 0.9967 - iouMetric: 0.1803 - dice_coef: 0.3006 - val_loss: 0.0202 - val_accuracy: 0.9967 - val_iouMetric: 0.1576 - val_dice_coef: 0.2697\n",
            "Epoch 10/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9967 - iouMetric: 0.1917 - dice_coef: 0.3167\n",
            "Epoch 10: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.01951\n",
            "103/103 [==============================] - 224s 2s/step - loss: 0.0196 - accuracy: 0.9967 - iouMetric: 0.1917 - dice_coef: 0.3167 - val_loss: 0.0200 - val_accuracy: 0.9966 - val_iouMetric: 0.1475 - val_dice_coef: 0.2549\n",
            "Epoch 11/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9967 - iouMetric: 0.1896 - dice_coef: 0.3139\n",
            "Epoch 11: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 11: val_loss improved from 0.01951 to 0.01921, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 208s 2s/step - loss: 0.0192 - accuracy: 0.9967 - iouMetric: 0.1896 - dice_coef: 0.3139 - val_loss: 0.0192 - val_accuracy: 0.9967 - val_iouMetric: 0.1676 - val_dice_coef: 0.2844\n",
            "Epoch 12/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9968 - iouMetric: 0.2083 - dice_coef: 0.3399\n",
            "Epoch 12: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.01921\n",
            "103/103 [==============================] - 214s 2s/step - loss: 0.0184 - accuracy: 0.9968 - iouMetric: 0.2083 - dice_coef: 0.3399 - val_loss: 0.0194 - val_accuracy: 0.9967 - val_iouMetric: 0.1711 - val_dice_coef: 0.2889\n",
            "Epoch 13/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9968 - iouMetric: 0.2054 - dice_coef: 0.3347\n",
            "Epoch 13: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 13: val_loss improved from 0.01921 to 0.01885, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 222s 2s/step - loss: 0.0180 - accuracy: 0.9968 - iouMetric: 0.2054 - dice_coef: 0.3347 - val_loss: 0.0188 - val_accuracy: 0.9968 - val_iouMetric: 0.1490 - val_dice_coef: 0.2570\n",
            "Epoch 14/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9969 - iouMetric: 0.2221 - dice_coef: 0.3588\n",
            "Epoch 14: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.01885\n",
            "103/103 [==============================] - 220s 2s/step - loss: 0.0173 - accuracy: 0.9969 - iouMetric: 0.2221 - dice_coef: 0.3588 - val_loss: 0.0193 - val_accuracy: 0.9967 - val_iouMetric: 0.1617 - val_dice_coef: 0.2756\n",
            "Epoch 15/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9969 - iouMetric: 0.2287 - dice_coef: 0.3661\n",
            "Epoch 15: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 15: val_loss improved from 0.01885 to 0.01878, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 218s 2s/step - loss: 0.0169 - accuracy: 0.9969 - iouMetric: 0.2287 - dice_coef: 0.3661 - val_loss: 0.0188 - val_accuracy: 0.9967 - val_iouMetric: 0.1476 - val_dice_coef: 0.2556\n",
            "Epoch 16/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9971 - iouMetric: 0.2366 - dice_coef: 0.3764\n",
            "Epoch 16: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 16: val_loss improved from 0.01878 to 0.01800, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 216s 2s/step - loss: 0.0165 - accuracy: 0.9971 - iouMetric: 0.2366 - dice_coef: 0.3764 - val_loss: 0.0180 - val_accuracy: 0.9966 - val_iouMetric: 0.1770 - val_dice_coef: 0.2981\n",
            "Epoch 17/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9971 - iouMetric: 0.2487 - dice_coef: 0.3919\n",
            "Epoch 17: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.01800\n",
            "103/103 [==============================] - 211s 2s/step - loss: 0.0161 - accuracy: 0.9971 - iouMetric: 0.2487 - dice_coef: 0.3919 - val_loss: 0.0185 - val_accuracy: 0.9965 - val_iouMetric: 0.1633 - val_dice_coef: 0.2782\n",
            "Epoch 18/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9971 - iouMetric: 0.2568 - dice_coef: 0.4024\n",
            "Epoch 18: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 18: val_loss improved from 0.01800 to 0.01777, saving model to model.weights.best.hdf5\n",
            "103/103 [==============================] - 222s 2s/step - loss: 0.0156 - accuracy: 0.9971 - iouMetric: 0.2568 - dice_coef: 0.4024 - val_loss: 0.0178 - val_accuracy: 0.9967 - val_iouMetric: 0.1513 - val_dice_coef: 0.2609\n",
            "Epoch 19/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9972 - iouMetric: 0.2596 - dice_coef: 0.4063\n",
            "Epoch 19: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 219s 2s/step - loss: 0.0153 - accuracy: 0.9972 - iouMetric: 0.2596 - dice_coef: 0.4063 - val_loss: 0.0184 - val_accuracy: 0.9967 - val_iouMetric: 0.1684 - val_dice_coef: 0.2854\n",
            "Epoch 20/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9972 - iouMetric: 0.2694 - dice_coef: 0.4181\n",
            "Epoch 20: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 217s 2s/step - loss: 0.0148 - accuracy: 0.9972 - iouMetric: 0.2694 - dice_coef: 0.4181 - val_loss: 0.0184 - val_accuracy: 0.9967 - val_iouMetric: 0.1779 - val_dice_coef: 0.2990\n",
            "Epoch 21/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9973 - iouMetric: 0.2893 - dice_coef: 0.4417\n",
            "Epoch 21: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 222s 2s/step - loss: 0.0144 - accuracy: 0.9973 - iouMetric: 0.2893 - dice_coef: 0.4417 - val_loss: 0.0190 - val_accuracy: 0.9960 - val_iouMetric: 0.1913 - val_dice_coef: 0.3185\n",
            "Epoch 22/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9973 - iouMetric: 0.2867 - dice_coef: 0.4393\n",
            "Epoch 22: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 212s 2s/step - loss: 0.0141 - accuracy: 0.9973 - iouMetric: 0.2867 - dice_coef: 0.4393 - val_loss: 0.0181 - val_accuracy: 0.9965 - val_iouMetric: 0.1910 - val_dice_coef: 0.3170\n",
            "Epoch 23/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9974 - iouMetric: 0.3141 - dice_coef: 0.4717\n",
            "Epoch 23: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 220s 2s/step - loss: 0.0136 - accuracy: 0.9974 - iouMetric: 0.3141 - dice_coef: 0.4717 - val_loss: 0.0182 - val_accuracy: 0.9966 - val_iouMetric: 0.1959 - val_dice_coef: 0.3234\n",
            "Epoch 24/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9974 - iouMetric: 0.3187 - dice_coef: 0.4777\n",
            "Epoch 24: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 220s 2s/step - loss: 0.0133 - accuracy: 0.9974 - iouMetric: 0.3187 - dice_coef: 0.4777 - val_loss: 0.0201 - val_accuracy: 0.9966 - val_iouMetric: 0.1750 - val_dice_coef: 0.2936\n",
            "Epoch 25/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9975 - iouMetric: 0.3234 - dice_coef: 0.4804\n",
            "Epoch 25: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 221s 2s/step - loss: 0.0130 - accuracy: 0.9975 - iouMetric: 0.3234 - dice_coef: 0.4804 - val_loss: 0.0180 - val_accuracy: 0.9962 - val_iouMetric: 0.1622 - val_dice_coef: 0.2768\n",
            "Epoch 26/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9976 - iouMetric: 0.3387 - dice_coef: 0.4982\n",
            "Epoch 26: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 218s 2s/step - loss: 0.0126 - accuracy: 0.9976 - iouMetric: 0.3387 - dice_coef: 0.4982 - val_loss: 0.0193 - val_accuracy: 0.9965 - val_iouMetric: 0.1652 - val_dice_coef: 0.2798\n",
            "Epoch 27/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9976 - iouMetric: 0.3399 - dice_coef: 0.5005\n",
            "Epoch 27: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 225s 2s/step - loss: 0.0124 - accuracy: 0.9976 - iouMetric: 0.3399 - dice_coef: 0.5005 - val_loss: 0.0193 - val_accuracy: 0.9966 - val_iouMetric: 0.1333 - val_dice_coef: 0.2317\n",
            "Epoch 28/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9977 - iouMetric: 0.3533 - dice_coef: 0.5139\n",
            "Epoch 28: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 220s 2s/step - loss: 0.0120 - accuracy: 0.9977 - iouMetric: 0.3533 - dice_coef: 0.5139 - val_loss: 0.0189 - val_accuracy: 0.9962 - val_iouMetric: 0.1868 - val_dice_coef: 0.3097\n",
            "Epoch 29/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9977 - iouMetric: 0.3581 - dice_coef: 0.5208\n",
            "Epoch 29: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 216s 2s/step - loss: 0.0119 - accuracy: 0.9977 - iouMetric: 0.3581 - dice_coef: 0.5208 - val_loss: 0.0178 - val_accuracy: 0.9965 - val_iouMetric: 0.1697 - val_dice_coef: 0.2875\n",
            "Epoch 30/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9977 - iouMetric: 0.3602 - dice_coef: 0.5226\n",
            "Epoch 30: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 219s 2s/step - loss: 0.0117 - accuracy: 0.9977 - iouMetric: 0.3602 - dice_coef: 0.5226 - val_loss: 0.0185 - val_accuracy: 0.9967 - val_iouMetric: 0.1623 - val_dice_coef: 0.2761\n",
            "Epoch 31/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9977 - iouMetric: 0.3653 - dice_coef: 0.5300\n",
            "Epoch 31: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 224s 2s/step - loss: 0.0116 - accuracy: 0.9977 - iouMetric: 0.3653 - dice_coef: 0.5300 - val_loss: 0.0192 - val_accuracy: 0.9965 - val_iouMetric: 0.1821 - val_dice_coef: 0.3039\n",
            "Epoch 32/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9978 - iouMetric: 0.3746 - dice_coef: 0.5394\n",
            "Epoch 32: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 215s 2s/step - loss: 0.0112 - accuracy: 0.9978 - iouMetric: 0.3746 - dice_coef: 0.5394 - val_loss: 0.0184 - val_accuracy: 0.9964 - val_iouMetric: 0.1773 - val_dice_coef: 0.2980\n",
            "Epoch 33/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9978 - iouMetric: 0.3862 - dice_coef: 0.5500\n",
            "Epoch 33: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 226s 2s/step - loss: 0.0109 - accuracy: 0.9978 - iouMetric: 0.3862 - dice_coef: 0.5500 - val_loss: 0.0197 - val_accuracy: 0.9963 - val_iouMetric: 0.1768 - val_dice_coef: 0.2972\n",
            "Epoch 34/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9979 - iouMetric: 0.3952 - dice_coef: 0.5603\n",
            "Epoch 34: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 217s 2s/step - loss: 0.0107 - accuracy: 0.9979 - iouMetric: 0.3952 - dice_coef: 0.5603 - val_loss: 0.0191 - val_accuracy: 0.9964 - val_iouMetric: 0.1680 - val_dice_coef: 0.2834\n",
            "Epoch 35/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9979 - iouMetric: 0.4064 - dice_coef: 0.5714\n",
            "Epoch 35: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 224s 2s/step - loss: 0.0105 - accuracy: 0.9979 - iouMetric: 0.4064 - dice_coef: 0.5714 - val_loss: 0.0194 - val_accuracy: 0.9965 - val_iouMetric: 0.1814 - val_dice_coef: 0.3013\n",
            "Epoch 36/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9979 - iouMetric: 0.4005 - dice_coef: 0.5665\n",
            "Epoch 36: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 216s 2s/step - loss: 0.0105 - accuracy: 0.9979 - iouMetric: 0.4005 - dice_coef: 0.5665 - val_loss: 0.0195 - val_accuracy: 0.9966 - val_iouMetric: 0.1876 - val_dice_coef: 0.3100\n",
            "Epoch 37/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9979 - iouMetric: 0.4077 - dice_coef: 0.5725\n",
            "Epoch 37: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 217s 2s/step - loss: 0.0104 - accuracy: 0.9979 - iouMetric: 0.4077 - dice_coef: 0.5725 - val_loss: 0.0213 - val_accuracy: 0.9964 - val_iouMetric: 0.1814 - val_dice_coef: 0.3030\n",
            "Epoch 38/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9980 - iouMetric: 0.4205 - dice_coef: 0.5873\n",
            "Epoch 38: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 225s 2s/step - loss: 0.0099 - accuracy: 0.9980 - iouMetric: 0.4205 - dice_coef: 0.5873 - val_loss: 0.0193 - val_accuracy: 0.9964 - val_iouMetric: 0.1710 - val_dice_coef: 0.2873\n",
            "Epoch 39/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9980 - iouMetric: 0.4227 - dice_coef: 0.5896\n",
            "Epoch 39: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 217s 2s/step - loss: 0.0099 - accuracy: 0.9980 - iouMetric: 0.4227 - dice_coef: 0.5896 - val_loss: 0.0197 - val_accuracy: 0.9965 - val_iouMetric: 0.1842 - val_dice_coef: 0.3044\n",
            "Epoch 40/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9980 - iouMetric: 0.4266 - dice_coef: 0.5924\n",
            "Epoch 40: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 224s 2s/step - loss: 0.0097 - accuracy: 0.9980 - iouMetric: 0.4266 - dice_coef: 0.5924 - val_loss: 0.0218 - val_accuracy: 0.9964 - val_iouMetric: 0.1906 - val_dice_coef: 0.3129\n",
            "Epoch 41/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9980 - iouMetric: 0.4288 - dice_coef: 0.5936\n",
            "Epoch 41: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 214s 2s/step - loss: 0.0096 - accuracy: 0.9980 - iouMetric: 0.4288 - dice_coef: 0.5936 - val_loss: 0.0189 - val_accuracy: 0.9964 - val_iouMetric: 0.1782 - val_dice_coef: 0.2990\n",
            "Epoch 42/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9980 - iouMetric: 0.4212 - dice_coef: 0.5872\n",
            "Epoch 42: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 225s 2s/step - loss: 0.0096 - accuracy: 0.9980 - iouMetric: 0.4212 - dice_coef: 0.5872 - val_loss: 0.0188 - val_accuracy: 0.9963 - val_iouMetric: 0.1928 - val_dice_coef: 0.3175\n",
            "Epoch 43/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9981 - iouMetric: 0.4402 - dice_coef: 0.6068\n",
            "Epoch 43: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 225s 2s/step - loss: 0.0093 - accuracy: 0.9981 - iouMetric: 0.4402 - dice_coef: 0.6068 - val_loss: 0.0195 - val_accuracy: 0.9963 - val_iouMetric: 0.1954 - val_dice_coef: 0.3213\n",
            "Epoch 44/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9981 - iouMetric: 0.4528 - dice_coef: 0.6187\n",
            "Epoch 44: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 218s 2s/step - loss: 0.0090 - accuracy: 0.9981 - iouMetric: 0.4528 - dice_coef: 0.6187 - val_loss: 0.0199 - val_accuracy: 0.9965 - val_iouMetric: 0.1882 - val_dice_coef: 0.3107\n",
            "Epoch 45/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9981 - iouMetric: 0.4529 - dice_coef: 0.6188\n",
            "Epoch 45: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 209s 2s/step - loss: 0.0089 - accuracy: 0.9981 - iouMetric: 0.4529 - dice_coef: 0.6188 - val_loss: 0.0192 - val_accuracy: 0.9965 - val_iouMetric: 0.1864 - val_dice_coef: 0.3102\n",
            "Epoch 46/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9982 - iouMetric: 0.4615 - dice_coef: 0.6263\n",
            "Epoch 46: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 211s 2s/step - loss: 0.0087 - accuracy: 0.9982 - iouMetric: 0.4615 - dice_coef: 0.6263 - val_loss: 0.0185 - val_accuracy: 0.9963 - val_iouMetric: 0.1852 - val_dice_coef: 0.3072\n",
            "Epoch 47/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9981 - iouMetric: 0.4646 - dice_coef: 0.6302\n",
            "Epoch 47: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 213s 2s/step - loss: 0.0087 - accuracy: 0.9981 - iouMetric: 0.4646 - dice_coef: 0.6302 - val_loss: 0.0188 - val_accuracy: 0.9967 - val_iouMetric: 0.1805 - val_dice_coef: 0.3010\n",
            "Epoch 48/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9981 - iouMetric: 0.4466 - dice_coef: 0.6132\n",
            "Epoch 48: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 217s 2s/step - loss: 0.0088 - accuracy: 0.9981 - iouMetric: 0.4466 - dice_coef: 0.6132 - val_loss: 0.0230 - val_accuracy: 0.9965 - val_iouMetric: 0.1630 - val_dice_coef: 0.2753\n",
            "Epoch 49/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9982 - iouMetric: 0.4647 - dice_coef: 0.6311\n",
            "Epoch 49: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 210s 2s/step - loss: 0.0086 - accuracy: 0.9982 - iouMetric: 0.4647 - dice_coef: 0.6311 - val_loss: 0.0185 - val_accuracy: 0.9963 - val_iouMetric: 0.1724 - val_dice_coef: 0.2897\n",
            "Epoch 50/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9982 - iouMetric: 0.4751 - dice_coef: 0.6405\n",
            "Epoch 50: val_loss did not improve from 0.05885\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 224s 2s/step - loss: 0.0084 - accuracy: 0.9982 - iouMetric: 0.4751 - dice_coef: 0.6405 - val_loss: 0.0208 - val_accuracy: 0.9962 - val_iouMetric: 0.1950 - val_dice_coef: 0.3223\n",
            "Accuracy 0.9963907599449158\n",
            "IOU Metrics 0.22159485518932343\n",
            "dice_coef 0.35135412216186523\n",
            "-----------------------------------------------------\n",
            "\n",
            "Size of training set = 1026\n",
            "Size of test set = 205\n",
            "Number of epochs = 50\n",
            "Batch size = 10\n",
            "Number of training steps per epoch = 103\n",
            "Number of test steps per epoch = 21\n",
            "\n",
            "Epoch 1/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9922 - iouMetric: 0.0048 - dice_coef: 0.0099\n",
            "Epoch 1: val_loss improved from -inf to 0.06704, saving model to /content/results/fit/20220822_220804/checkpoints/20220822_220804\n",
            "\n",
            "Epoch 1: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 211s 2s/step - loss: 0.0944 - accuracy: 0.9922 - iouMetric: 0.0048 - dice_coef: 0.0099 - val_loss: 0.0670 - val_accuracy: 0.9961 - val_iouMetric: 0.0179 - val_dice_coef: 0.0355\n",
            "Epoch 2/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9959 - iouMetric: 0.0648 - dice_coef: 0.1195\n",
            "Epoch 2: val_loss did not improve from 0.06704\n",
            "\n",
            "Epoch 2: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 221s 2s/step - loss: 0.0534 - accuracy: 0.9959 - iouMetric: 0.0648 - dice_coef: 0.1195 - val_loss: 0.0450 - val_accuracy: 0.9953 - val_iouMetric: 0.1170 - val_dice_coef: 0.2077\n",
            "Epoch 3/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9961 - iouMetric: 0.1176 - dice_coef: 0.2083\n",
            "Epoch 3: val_loss did not improve from 0.06704\n",
            "\n",
            "Epoch 3: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 207s 2s/step - loss: 0.0382 - accuracy: 0.9961 - iouMetric: 0.1176 - dice_coef: 0.2083 - val_loss: 0.0349 - val_accuracy: 0.9963 - val_iouMetric: 0.1188 - val_dice_coef: 0.2105\n",
            "Epoch 4/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9962 - iouMetric: 0.1335 - dice_coef: 0.2331\n",
            "Epoch 4: val_loss did not improve from 0.06704\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 222s 2s/step - loss: 0.0307 - accuracy: 0.9962 - iouMetric: 0.1335 - dice_coef: 0.2331 - val_loss: 0.0297 - val_accuracy: 0.9963 - val_iouMetric: 0.1184 - val_dice_coef: 0.2099\n",
            "Epoch 5/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9962 - iouMetric: 0.1325 - dice_coef: 0.2311\n",
            "Epoch 5: val_loss did not improve from 0.06704\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 214s 2s/step - loss: 0.0272 - accuracy: 0.9962 - iouMetric: 0.1325 - dice_coef: 0.2311 - val_loss: 0.0261 - val_accuracy: 0.9963 - val_iouMetric: 0.1616 - val_dice_coef: 0.2748\n",
            "Epoch 6/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9965 - iouMetric: 0.1549 - dice_coef: 0.2642\n",
            "Epoch 6: val_loss did not improve from 0.06704\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.01777\n",
            "103/103 [==============================] - 212s 2s/step - loss: 0.0247 - accuracy: 0.9965 - iouMetric: 0.1549 - dice_coef: 0.2642 - val_loss: 0.0251 - val_accuracy: 0.9963 - val_iouMetric: 0.1697 - val_dice_coef: 0.2858\n",
            "Epoch 7/50\n",
            "103/103 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9964 - iouMetric: 0.1566 - dice_coef: 0.2669"
          ]
        }
      ],
      "source": [
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)  \n",
        "model_time = dt.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_folder = os.path.join(results_dir, model_time)\n",
        "os.makedirs(model_folder)\n",
        "\n",
        "tensorboard_folder = os.path.join(model_folder, \"tensorlogs\")\n",
        "os.makedirs(tensorboard_folder)\n",
        "\n",
        "ckpt_folder = os.path.join(model_folder, \"checkpoints\")\n",
        "os.makedirs(ckpt_folder)\n",
        "\n",
        "csv_logger_folder = os.path.join(model_folder, \"csv_logger\")\n",
        "os.makedirs(csv_logger_folder)\n",
        "\n",
        "hist_folder = os.path.join(model_folder, \"model_history\")\n",
        "os.makedirs(hist_folder)\n",
        "\n",
        "saved_model_folder = os.path.join(model_folder, \"Saved_model\")\n",
        "os.makedirs(saved_model_folder)\n",
        "\n",
        "model_params_folder = os.path.join(model_folder, \"model_params\")\n",
        "os.makedirs(model_params_folder)\n",
        "\n",
        "train_x, train_y = datasetPaths(\n",
        "    full_img_dir=train_full_img_dir,\n",
        "    mask_img_dir=train_mask_img_dir \n",
        ")\n",
        "\n",
        "test_x, test_y = datasetPaths(\n",
        "    full_img_dir=test_full_img_dir,\n",
        "    mask_img_dir=test_mask_img_dir\n",
        ")\n",
        "\n",
        "df_x = train_x.copy()\n",
        "df_y = train_y.copy()\n",
        "\n",
        "for train_idx, val_idx in list(kfold.split(train_x, train_y )):      \n",
        "      train_x_list = list(itemgetter(*train_idx)(train_x))\n",
        "      val_x_list = list(itemgetter(*val_idx)(train_x)) \n",
        "      train_y_list = list(itemgetter(*train_idx)(train_y))\n",
        "      val_y_list = list(itemgetter(*val_idx)(train_y)) \n",
        "      \n",
        "      train_ds = makeTFDataset(shuffle=True, augument=True,\n",
        "          x_paths_list = train_x_list, y_paths_list=train_y_list, batch_size=batch_size)\n",
        "      \n",
        "      val_ds = makeTFDataset(shuffle=False, augument=False,\n",
        "         x_paths_list=val_x_list, y_paths_list=val_y_list, batch_size=batch_size)  \n",
        "      \n",
        "      unet = buildUnet()\n",
        "\n",
        "      unet = compile_(model=unet)\n",
        "\n",
        "      # ckpt_path = (ckpt_folder + f\"/{model_time}\" + \"_Epoch-{epoch:03d}\" + \"_IOU-{iouMetric:.8f\")\n",
        "      ckpt_path = (ckpt_folder + f\"/{model_time}\")\n",
        "\n",
        "      ckpt_callback = keras.callbacks.ModelCheckpoint(\n",
        "          filepath= ckpt_path,\n",
        "          monitors= callback_monitor,\n",
        "          mode= callback_mode,\n",
        "          save_weights_only= ckpt_save_weights_only,\n",
        "          save_best_only=ckpt_save_best_only,\n",
        "          verbose=1\n",
        "      )\n",
        "\n",
        "      es_callback = keras.callbacks.EarlyStopping(\n",
        "          patience= earlystop_patience,\n",
        "          monitor= callback_monitor,\n",
        "          mode= callback_mode,\n",
        "          restore_best_weights= restore_best_weights,\n",
        "      )\n",
        "\n",
        "      # TensorBoard\n",
        "      tb_callback = keras.callbacks.TensorBoard(\n",
        "          log_dir=tensorboard_folder, histogram_freq=1, profile_batch=0\n",
        "      )\n",
        "\n",
        "      # CSV Logger\n",
        "      csv_logger_path = os.path.join(csv_logger_folder, \"csv_logger.csv\")\n",
        "      csv_logger = keras.callbacks.CSVLogger(\n",
        "          filename=csv_logger_path, separator=\",\", append=True\n",
        "      )\n",
        "\n",
        "      # Putting them together\n",
        "      callbacks = [ckpt_callback, es_callback, tb_callback, csv_logger, checkpointer]\n",
        "\n",
        "      train_steps = len(train_x_list) // batch_size\n",
        "      val_steps = len(val_x_list) // batch_size\n",
        "\n",
        "      if len(train_x_list) % batch_size != 0:\n",
        "          train_steps += 1\n",
        "      if len(val_x_list) % batch_size != 0:\n",
        "          val_steps += 1\n",
        "\n",
        "      print()\n",
        "      print(f\"Size of training set = {len(train_x_list)}\")\n",
        "      print(f\"Size of test set = {len(val_x_list)}\")\n",
        "      print(f\"Number of epochs = {num_epochs}\")\n",
        "      print(f\"Batch size = {batch_size}\")\n",
        "      print(f\"Number of training steps per epoch = {train_steps}\")\n",
        "      print(f\"Number of test steps per epoch = {val_steps}\")\n",
        "      print()\n",
        "\n",
        "      if validate:\n",
        "              history = unet.fit(\n",
        "                  train_ds,\n",
        "                  validation_data=val_ds,\n",
        "                  epochs=num_epochs,\n",
        "                  steps_per_epoch=train_steps,\n",
        "                  validation_steps=val_steps,\n",
        "                  callbacks=callbacks,\n",
        "                  verbose=1,\n",
        "              )\n",
        "      elif not validate:\n",
        "          history = unet.fit(\n",
        "              train_ds,\n",
        "              epochs=num_epochs,\n",
        "              steps_per_epoch=train_steps,\n",
        "              callbacks=callbacks,\n",
        "              verbose=1\n",
        "          )\n",
        "\n",
        "      #y_hat = unet.evaluate(test_ds)\n",
        "\n",
        "      test_ds = makeTFDataset1(shuffle=False, augument=False, x_paths_list=test_x, y_paths_list=test_y, batch_size=batch_size)    \n",
        "      \n",
        "      score = unet.evaluate(test_ds, verbose=0)\n",
        "      print(f\"Accuracy {score[1]}\")\n",
        "      print(f\"IOU Metrics {score[2]}\")\n",
        "      print(f\"dice_coef {score[3]}\")\n",
        "      print(\"-----------------------------------------------------\")\n",
        "print(\"Completed\")     \n",
        "              "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBPWHo79s1Hz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCumD8yCBX3-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGkGHRtCIlcu"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_ds = makeTFDataset1(shuffle=True, augument=True,\n",
        "x_paths_list = train_x, y_paths_list=train_y, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRy91OTxNnym"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihfzEvA6NAS0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtht3dayvWSI"
      },
      "outputs": [],
      "source": [
        "i = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVeEZIevwLzg"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/results/fit.zip /content/results/fit "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms8fiADKwq6i"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/results/fit.zip\")\n",
        "# files.download('model.weights.best.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2Hu8b8_UMD2"
      },
      "outputs": [],
      "source": [
        "def loadFullImg_1(path, dsize):\n",
        "        try:\n",
        "             \n",
        "            print(path)\n",
        "            img = cv2.imread(\"/content/gdrive/MyDrive/cbisddsm/Test_output_full/Mass-Test_P_00016_LEFT_CC_FULL__PRE.png\", cv2.IMREAD_GRAYSCALE)\n",
        "            print(type(img))\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "      \n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "            print(f'After norm_img')\n",
        "            print(f'type {norm_img.shape}')\n",
        "            full_img = np.stack([norm_img, norm_img, norm_img], axis=-1)\n",
        "            print(f'After full_img')\n",
        "            print(f'type {full_img.shape}')\n",
        "            print(f'done for path {path} with shape {full_img.shape}')\n",
        "            return full_img\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"There is an error in loadFullImg {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN8ydZ_-UV74"
      },
      "outputs": [],
      "source": [
        "def loadMaskImg_1(path, dsize):\n",
        "        try:\n",
        "            # if not isinstance(path, str):\n",
        "            #     path=path.decode()\n",
        "            print(path)\n",
        "            img = cv2.imread(\"/content/gdrive/MyDrive/cbisddsm/Test_output_mask/Mass-Test_P_00016_LEFT_CC_MASK_1__PRE.png\", cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(src=img, dsize=dsize)\n",
        "\n",
        "            norm_img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "            mask_img = np.expand_dims(norm_img, axis=-1)\n",
        "            print(f'done for path {path} with shape {mask_img.shape}')\n",
        "            return mask_img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in loadMaskIMG {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb2fsrPDUMK1"
      },
      "outputs": [],
      "source": [
        "def tfParse_1(x_path, y_path):\n",
        "        try:\n",
        "            def _parse(x_path, y_path):\n",
        "                x = loadFullImg_1(path=x_path, dsize=target_size)\n",
        "                y = loadMaskImg_1(path=y_path, dsize=target_size)\n",
        "                return x,y\n",
        "\n",
        "            x, y = tf.numpy_function(_parse, [x_path, y_path], [tf.float64, tf.float64])\n",
        "              \n",
        "            x.set_shape([target_size[0], target_size[0], 3])\n",
        "            y.set_shape([target_size[0], target_size[1], 1])\n",
        "\n",
        "            return x,y\n",
        "            \n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in tfParse {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06CumsaLV6JC"
      },
      "outputs": [],
      "source": [
        " #model.load_weights('model.weights.best.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRVx-4W1T0jO"
      },
      "outputs": [],
      "source": [
        "res_x, res_y = tfParse_1(test_x[i], test_y[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMaOVHjUT6He"
      },
      "outputs": [],
      "source": [
        "print(res_x.shape)\n",
        "print(res_y.shape)\n",
        "print(type(res_y.numpy())) \n",
        "print(res_x.numpy().shape)\n",
        "print(res_y.numpy().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh-whdVrYM4j"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (50,8))\n",
        "plt.imshow(res_x.numpy(), cmap=\"gray\")\n",
        "plt.title(f\"Before cropping \", x=0.5, y=-0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVcmbNaQZDTX"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (50,8))\n",
        "plt.imshow(res_y.numpy()[:,:,0], cmap=\"gray\")\n",
        "plt.title(f\"Before cropping \", x=0.5, y=-0.1)\n",
        "print(res_x.numpy().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teGKIGb0IhFK"
      },
      "outputs": [],
      "source": [
        "# res_y.numpy()[:,:,0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qis1l2Zd_1a7"
      },
      "outputs": [],
      "source": [
        "# res_x.numpy().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjA1jjBgTnMf"
      },
      "outputs": [],
      "source": [
        "prediction = unet.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs8fB-GcJeq5"
      },
      "outputs": [],
      "source": [
        "# type(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U10ju5R8Jmxn"
      },
      "outputs": [],
      "source": [
        "# prediction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIMrBwBPJj24"
      },
      "outputs": [],
      "source": [
        "# prediction[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8GIuGP7Jq0I"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (50,8))\n",
        "plt.imshow(prediction[i][:,:,0], cmap=\"gray\")\n",
        "plt.title(f\"Before cropping \", x=0.5, y=-0.1)\n",
        "print(res_x.numpy().shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Cbisddsm_final_new_22.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "instance_type": "ml.m5.large",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}